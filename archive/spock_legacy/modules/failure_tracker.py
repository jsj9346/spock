#!/usr/bin/env python3
"""
Makenaide Phase 4: ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ

SQLite ê¸°ë°˜ ì‹¤íŒ¨ ì´ë ¥ ì¶”ì , íŒ¨í„´ ë¶„ì„, ì˜ˆì¸¡ì  ë¶„ì„ì„ ì œê³µí•˜ëŠ”
ì§€ëŠ¥í˜• ì‹¤íŒ¨ ê´€ë¦¬ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

ğŸ¯ ì£¼ìš” ê¸°ëŠ¥:
- ì‹¤ì‹œê°„ ì‹¤íŒ¨ ì´ë ¥ ì¶”ì  ë° ì €ì¥
- íŒ¨í„´ ë¶„ì„ì„ í†µí•œ ë°˜ë³µ ì‹¤íŒ¨ ê°ì§€
- ì‹œê°„ëŒ€ë³„/ìœ í˜•ë³„ ì‹¤íŒ¨ íŠ¸ë Œë“œ ë¶„ì„
- ì˜ˆì¸¡ì  ìœ„í—˜ë„ í‰ê°€
- ìë™ ë³µêµ¬ ì œì•ˆ ì‹œìŠ¤í…œ
- ì‹¤íŒ¨ ë°©ì§€ ê¶Œê³ ì‚¬í•­ ìƒì„±
"""

import sqlite3
import json
import hashlib
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, asdict
from collections import defaultdict, Counter
from pathlib import Path
import statistics
import logging

# Phase 1-3 ì—°ë™ì„ ìœ„í•œ import
from sns_notification_system import (
    FailureType, FailureSubType, FailureSeverity,
    NotificationMessage, NotificationLevel, NotificationCategory
)

logger = logging.getLogger(__name__)

@dataclass
class FailureRecord:
    """ì‹¤íŒ¨ ê¸°ë¡ ë°ì´í„° í´ë˜ìŠ¤"""
    timestamp: str
    execution_id: str
    failure_type: str
    sub_type: Optional[str]
    severity: str
    phase: Optional[str]
    error_message: str
    metadata: str = "{}"  # JSON ë¬¸ìì—´ë¡œ ë³€ê²½
    id: int = 0  # í…ŒìŠ¤íŠ¸ìš© ID í•„ë“œ ì¶”ê°€
    recovery_attempted: bool = False
    recovery_successful: bool = False
    resolution_time: Optional[int] = None  # í•´ê²°ê¹Œì§€ ê±¸ë¦° ì‹œê°„(ë¶„)
    similar_failure_count: int = 0
    failure_hash: Optional[str] = None

@dataclass
class FailurePattern:
    """ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ê²°ê³¼"""
    pattern_id: str
    failure_type: str
    sub_type: str
    occurrence_count: int  # frequency ëŒ€ì‹  occurrence_count ì‚¬ìš©
    first_occurrence: str  # ì¶”ê°€
    last_occurrence: str
    avg_resolution_time: float
    success_rate: float
    risk_score: float
    trend: str  # "increasing", "stable", "decreasing"
    recommendations: str  # JSON ë¬¸ìì—´ë¡œ ë³€ê²½
    metadata: str = "{}"  # ì¶”ê°€

@dataclass
class SystemHealthMetrics:
    """ì‹œìŠ¤í…œ ê±´ê°•ë„ ë©”íŠ¸ë¦­"""
    timestamp: str
    total_failures_24h: int = 0
    critical_failures_24h: int = 0
    avg_resolution_time: float = 0.0
    failure_rate_trend: str = "stable"
    most_common_failure: str = ""
    risk_level: str = "LOW"  # "LOW", "MEDIUM", "HIGH", "CRITICAL"
    health_score: float = 100.0  # 0-100
    metrics_json: str = "{}"
    # í…ŒìŠ¤íŠ¸ìš© ì¶”ê°€ í•„ë“œë“¤
    failure_rate: float = 0.0
    memory_usage: float = 0.0
    cpu_usage: float = 0.0
    error_count: int = 0
    success_rate: float = 1.0
    active_connections: int = 0

class FailureTracker:
    """Phase 4: ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ë° ì˜ˆë°© ì‹œìŠ¤í…œ"""

    def __init__(self, db_path: str = "./makenaide_failures.db"):
        """
        ì‹¤íŒ¨ ì¶”ì ê¸° ì´ˆê¸°í™”

        Args:
            db_path: SQLite ë°ì´í„°ë² ì´ìŠ¤ íŒŒì¼ ê²½ë¡œ
        """
        self.db_path = db_path
        self.init_database()
        logger.info(f"ğŸ” ì‹¤íŒ¨ ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ: {db_path}")

    def init_database(self):
        """SQLite ë°ì´í„°ë² ì´ìŠ¤ ë° í…Œì´ë¸” ì´ˆê¸°í™”"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ì‹¤íŒ¨ ê¸°ë¡ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS failure_records (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        execution_id TEXT NOT NULL,
                        failure_type TEXT NOT NULL,
                        sub_type TEXT,
                        severity TEXT NOT NULL,
                        phase TEXT,
                        error_message TEXT NOT NULL,
                        metadata TEXT,
                        recovery_attempted INTEGER DEFAULT 0,
                        recovery_successful INTEGER DEFAULT 0,
                        resolution_time INTEGER,
                        similar_failure_count INTEGER DEFAULT 0,
                        failure_hash TEXT,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # ì¸ë±ìŠ¤ ìƒì„±
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_records_timestamp ON failure_records(timestamp)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_records_type ON failure_records(failure_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_records_subtype ON failure_records(sub_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_records_severity ON failure_records(severity)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_records_hash ON failure_records(failure_hash)")

                # íŒ¨í„´ ë¶„ì„ ê²°ê³¼ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS failure_patterns (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        pattern_id TEXT UNIQUE NOT NULL,
                        failure_type TEXT NOT NULL,
                        sub_type TEXT,
                        frequency INTEGER DEFAULT 1,
                        first_occurrence TEXT NOT NULL,
                        last_occurrence TEXT NOT NULL,
                        avg_resolution_time REAL DEFAULT 0,
                        success_rate REAL DEFAULT 0,
                        risk_score REAL DEFAULT 0,
                        trend TEXT DEFAULT 'stable',
                        recommendations TEXT,
                        updated_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # íŒ¨í„´ í…Œì´ë¸” ì¸ë±ìŠ¤ ìƒì„±
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_patterns_id ON failure_patterns(pattern_id)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_patterns_type ON failure_patterns(failure_type)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_failure_patterns_risk ON failure_patterns(risk_score)")

                # ì‹œìŠ¤í…œ ê±´ê°•ë„ ë©”íŠ¸ë¦­ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS system_health_metrics (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        timestamp TEXT NOT NULL,
                        total_failures_24h INTEGER DEFAULT 0,
                        critical_failures_24h INTEGER DEFAULT 0,
                        avg_resolution_time REAL DEFAULT 0,
                        failure_rate_trend TEXT DEFAULT 'stable',
                        most_common_failure TEXT,
                        risk_level TEXT DEFAULT 'LOW',
                        health_score REAL DEFAULT 100,
                        metrics_json TEXT,
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP
                    )
                """)

                # ì‹œìŠ¤í…œ ê±´ê°•ë„ í…Œì´ë¸” ì¸ë±ìŠ¤ ìƒì„±
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_system_health_timestamp ON system_health_metrics(timestamp)")
                cursor.execute("CREATE INDEX IF NOT EXISTS idx_system_health_risk ON system_health_metrics(risk_level)")

                # ë³µêµ¬ ì‹œë„ ì´ë ¥ í…Œì´ë¸”
                cursor.execute("""
                    CREATE TABLE IF NOT EXISTS recovery_attempts (
                        id INTEGER PRIMARY KEY AUTOINCREMENT,
                        failure_record_id INTEGER,
                        recovery_method TEXT NOT NULL,
                        attempted_at TEXT NOT NULL,
                        successful INTEGER DEFAULT 0,
                        execution_time INTEGER,  -- ì‹¤í–‰ ì‹œê°„(ì´ˆ)
                        error_message TEXT,
                        metadata TEXT,  -- JSON
                        created_at TEXT DEFAULT CURRENT_TIMESTAMP,
                        FOREIGN KEY (failure_record_id) REFERENCES failure_records (id)
                    )
                """)

                conn.commit()
                logger.info("âœ… ì‹¤íŒ¨ ì¶”ì  ë°ì´í„°ë² ì´ìŠ¤ í…Œì´ë¸” ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.error(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            raise

    def generate_failure_hash(self, failure_type: str, sub_type: str, error_message: str) -> str:
        """ì‹¤íŒ¨ íŒ¨í„´ ì‹ë³„ì„ ìœ„í•œ í•´ì‹œ ìƒì„±"""
        # ì—ëŸ¬ ë©”ì‹œì§€ì—ì„œ ë™ì  ë¶€ë¶„ ì œê±° (íƒ€ì„ìŠ¤íƒ¬í”„, ID ë“±)
        cleaned_message = error_message

        # ì¼ë°˜ì ì¸ ë™ì  íŒ¨í„´ ì œê±°
        import re
        patterns_to_remove = [
            r'\d{4}-\d{2}-\d{2} \d{2}:\d{2}:\d{2}',  # íƒ€ì„ìŠ¤íƒ¬í”„
            r'\d{8}_\d{6}',  # execution_id íŒ¨í„´
            r'ID: \w+',  # ID íŒ¨í„´
            r'\d+\.\d+\.\d+\.\d+',  # IP ì£¼ì†Œ
            r'[0-9a-f]{8,}',  # ê¸´ 16ì§„ìˆ˜ í•´ì‹œ
        ]

        for pattern in patterns_to_remove:
            cleaned_message = re.sub(pattern, '[DYNAMIC]', cleaned_message)

        # í•´ì‹œ ìƒì„±
        hash_input = f"{failure_type}:{sub_type}:{cleaned_message[:200]}"
        return hashlib.md5(hash_input.encode()).hexdigest()[:12]

    def record_failure(self,
                      failure_type: str,
                      error_message: str,
                      execution_id: str,
                      sub_type: Optional[str] = None,
                      severity: str = "MEDIUM",
                      phase: Optional[str] = None,
                      metadata: Optional[Dict] = None) -> int:
        """
        ì‹¤íŒ¨ ê¸°ë¡ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥

        Args:
            failure_type: ì‹¤íŒ¨ ìœ í˜• (FailureType enum value)
            error_message: ì—ëŸ¬ ë©”ì‹œì§€
            execution_id: ì‹¤í–‰ ID
            sub_type: ìƒì„¸ ì‹¤íŒ¨ ìœ í˜• (FailureSubType enum value)
            severity: ì‹¬ê°ë„ (FailureSeverity enum value)
            phase: ì‹¤íŒ¨ ë°œìƒ ë‹¨ê³„
            metadata: ì¶”ê°€ ë©”íƒ€ë°ì´í„°

        Returns:
            int: ìƒì„±ëœ ì‹¤íŒ¨ ê¸°ë¡ ID
        """
        try:
            timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            metadata = metadata or {}
            failure_hash = self.generate_failure_hash(failure_type, sub_type or "", error_message)

            # ìœ ì‚¬í•œ ì‹¤íŒ¨ ê°œìˆ˜ ê³„ì‚°
            similar_count = self._count_similar_failures(failure_hash, hours=24)

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT INTO failure_records (
                        timestamp, execution_id, failure_type, sub_type, severity,
                        phase, error_message, metadata, similar_failure_count, failure_hash
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    timestamp, execution_id, failure_type, sub_type, severity,
                    phase, error_message, json.dumps(metadata), similar_count, failure_hash
                ))

                failure_id = cursor.lastrowid
                conn.commit()

                logger.info(f"ğŸ“ ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥ ì™„ë£Œ: ID={failure_id}, Type={failure_type}, Hash={failure_hash}")

                # íŒ¨í„´ ë¶„ì„ ì—…ë°ì´íŠ¸
                self._update_failure_patterns(failure_type, sub_type, failure_hash, timestamp)

                return failure_id

        except Exception as e:
            logger.error(f"âŒ ì‹¤íŒ¨ ê¸°ë¡ ì €ì¥ ì˜¤ë¥˜: {e}")
            raise

    def _count_similar_failures(self, failure_hash: str, hours: int = 24) -> int:
        """ì§€ì •ëœ ì‹œê°„ ë‚´ ìœ ì‚¬í•œ ì‹¤íŒ¨ ê°œìˆ˜ ê³„ì‚°"""
        try:
            cutoff_time = (datetime.now() - timedelta(hours=hours)).strftime('%Y-%m-%d %H:%M:%S')

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT COUNT(*) FROM failure_records
                    WHERE failure_hash = ? AND timestamp >= ?
                """, (failure_hash, cutoff_time))

                count = cursor.fetchone()[0]
                return count

        except Exception as e:
            logger.error(f"âŒ ìœ ì‚¬ ì‹¤íŒ¨ ê°œìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0

    def _update_failure_patterns(self, failure_type: str, sub_type: str, failure_hash: str, timestamp: str):
        """ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ì—…ë°ì´íŠ¸"""
        try:
            pattern_id = f"{failure_type}:{sub_type or 'NONE'}:{failure_hash}"

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ê¸°ì¡´ íŒ¨í„´ í™•ì¸
                cursor.execute("""
                    SELECT frequency, first_occurrence FROM failure_patterns
                    WHERE pattern_id = ?
                """, (pattern_id,))

                result = cursor.fetchone()

                if result:
                    # ê¸°ì¡´ íŒ¨í„´ ì—…ë°ì´íŠ¸
                    frequency, first_occurrence = result
                    new_frequency = frequency + 1

                    cursor.execute("""
                        UPDATE failure_patterns
                        SET frequency = ?, last_occurrence = ?, updated_at = CURRENT_TIMESTAMP
                        WHERE pattern_id = ?
                    """, (new_frequency, timestamp, pattern_id))

                else:
                    # ìƒˆ íŒ¨í„´ ìƒì„±
                    cursor.execute("""
                        INSERT INTO failure_patterns (
                            pattern_id, failure_type, sub_type, frequency,
                            first_occurrence, last_occurrence
                        ) VALUES (?, ?, ?, 1, ?, ?)
                    """, (pattern_id, failure_type, sub_type, timestamp, timestamp))

                conn.commit()
                logger.debug(f"ğŸ“Š íŒ¨í„´ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {pattern_id}")

        except Exception as e:
            logger.error(f"âŒ íŒ¨í„´ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")

    def get_failure_patterns(self, hours: int = 168) -> List[FailurePattern]:
        """
        ì§€ì •ëœ ì‹œê°„ ë‚´ ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ê²°ê³¼ ë°˜í™˜

        Args:
            hours: ë¶„ì„ ê¸°ê°„ (ê¸°ë³¸: 168ì‹œê°„ = 7ì¼)

        Returns:
            List[FailurePattern]: ì‹¤íŒ¨ íŒ¨í„´ ë¦¬ìŠ¤íŠ¸
        """
        try:
            cutoff_time = (datetime.now() - timedelta(hours=hours)).strftime('%Y-%m-%d %H:%M:%S')

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute("""
                    SELECT
                        p.pattern_id, p.failure_type, p.sub_type, p.frequency,
                        p.last_occurrence, p.avg_resolution_time, p.success_rate,
                        p.risk_score, p.trend, p.recommendations
                    FROM failure_patterns p
                    WHERE p.last_occurrence >= ?
                    ORDER BY p.frequency DESC, p.risk_score DESC
                """, (cutoff_time,))

                patterns = []
                for row in cursor.fetchall():
                    pattern_id, failure_type, sub_type, frequency, last_occurrence, \
                    avg_resolution_time, success_rate, risk_score, trend, recommendations = row

                    # ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚°
                    calculated_risk_score = self._calculate_risk_score(
                        frequency, avg_resolution_time, success_rate, last_occurrence
                    )

                    # ì¶”ì²œì‚¬í•­ íŒŒì‹±
                    try:
                        recommendations_list = json.loads(recommendations) if recommendations else []
                    except:
                        recommendations_list = []

                    pattern = FailurePattern(
                        pattern_id=pattern_id,
                        failure_type=failure_type,
                        sub_type=sub_type or "UNKNOWN",
                        frequency=frequency,
                        last_occurrence=last_occurrence,
                        avg_resolution_time=avg_resolution_time or 0,
                        success_rate=success_rate or 0,
                        risk_score=calculated_risk_score,
                        trend=trend or "stable",
                        recommendations=recommendations_list
                    )

                    patterns.append(pattern)

                logger.info(f"ğŸ“Š {len(patterns)}ê°œ ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ")
                return patterns

        except Exception as e:
            logger.error(f"âŒ ì‹¤íŒ¨ íŒ¨í„´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def _calculate_risk_score(self, frequency: int, avg_resolution_time: float,
                            success_rate: float, last_occurrence: str) -> float:
        """ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        try:
            # ë¹ˆë„ ì ìˆ˜ (0-40)
            frequency_score = min(frequency * 2, 40)

            # í•´ê²° ì‹œê°„ ì ìˆ˜ (0-30)
            resolution_score = min(avg_resolution_time / 10, 30)

            # ì‹¤íŒ¨ìœ¨ ì ìˆ˜ (0-20)
            failure_rate_score = (100 - success_rate) * 0.2

            # ìµœê·¼ì„± ì ìˆ˜ (0-10)
            try:
                last_time = datetime.strptime(last_occurrence, '%Y-%m-%d %H:%M:%S')
                hours_ago = (datetime.now() - last_time).total_seconds() / 3600
                recency_score = max(10 - hours_ago / 24, 0)
            except:
                recency_score = 0

            total_score = frequency_score + resolution_score + failure_rate_score + recency_score
            return min(total_score, 100)

        except Exception as e:
            logger.error(f"âŒ ìœ„í—˜ë„ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
            return 0

    def get_system_health(self) -> SystemHealthMetrics:
        """í˜„ì¬ ì‹œìŠ¤í…œ ê±´ê°•ë„ ë©”íŠ¸ë¦­ ë°˜í™˜"""
        try:
            now = datetime.now()
            yesterday = now - timedelta(days=1)
            yesterday_str = yesterday.strftime('%Y-%m-%d %H:%M:%S')

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # 24ì‹œê°„ ë‚´ ì‹¤íŒ¨ í†µê³„
                cursor.execute("""
                    SELECT
                        COUNT(*) as total_failures,
                        COUNT(CASE WHEN severity = 'CRITICAL' THEN 1 END) as critical_failures,
                        AVG(CASE WHEN resolution_time IS NOT NULL THEN resolution_time END) as avg_resolution
                    FROM failure_records
                    WHERE timestamp >= ?
                """, (yesterday_str,))

                stats = cursor.fetchone()
                total_failures, critical_failures, avg_resolution_time = stats
                avg_resolution_time = avg_resolution_time or 0

                # ê°€ì¥ ë¹ˆë²ˆí•œ ì‹¤íŒ¨ ìœ í˜•
                cursor.execute("""
                    SELECT failure_type, COUNT(*) as count
                    FROM failure_records
                    WHERE timestamp >= ?
                    GROUP BY failure_type
                    ORDER BY count DESC
                    LIMIT 1
                """, (yesterday_str,))

                most_common = cursor.fetchone()
                most_common_failure = most_common[0] if most_common else "NONE"

                # ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚°
                health_score = self._calculate_health_score(total_failures, critical_failures, avg_resolution_time)

                # ìœ„í—˜ ë ˆë²¨ ê²°ì •
                risk_level = self._determine_risk_level(health_score, critical_failures, total_failures)

                # íŠ¸ë Œë“œ ë¶„ì„ (ê°„ë‹¨í•œ 7ì¼ vs 1ì¼ ë¹„êµ)
                week_ago = (now - timedelta(days=7)).strftime('%Y-%m-%d %H:%M:%S')
                cursor.execute("""
                    SELECT COUNT(*) FROM failure_records
                    WHERE timestamp >= ?
                """, (week_ago,))

                week_failures = cursor.fetchone()[0]
                daily_avg = week_failures / 7 if week_failures > 0 else 0

                if total_failures > daily_avg * 1.5:
                    failure_rate_trend = "increasing"
                elif total_failures < daily_avg * 0.5:
                    failure_rate_trend = "decreasing"
                else:
                    failure_rate_trend = "stable"

                metrics = SystemHealthMetrics(
                    timestamp=now.strftime('%Y-%m-%d %H:%M:%S'),
                    total_failures_24h=total_failures,
                    critical_failures_24h=critical_failures,
                    avg_resolution_time=avg_resolution_time,
                    failure_rate_trend=failure_rate_trend,
                    most_common_failure=most_common_failure,
                    risk_level=risk_level,
                    health_score=health_score
                )

                logger.info(f"ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„ ë¶„ì„ ì™„ë£Œ: Score={health_score:.1f}, Risk={risk_level}")
                return metrics

        except Exception as e:
            logger.error(f"âŒ ì‹œìŠ¤í…œ ê±´ê°•ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return SystemHealthMetrics(
                timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                total_failures_24h=0,
                critical_failures_24h=0,
                avg_resolution_time=0,
                failure_rate_trend="unknown",
                most_common_failure="NONE",
                risk_level="UNKNOWN",
                health_score=0
            )

    def _calculate_health_score(self, total_failures: int, critical_failures: int, avg_resolution_time: float) -> float:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ì ìˆ˜ ê³„ì‚° (0-100)"""
        base_score = 100

        # ì´ ì‹¤íŒ¨ íšŸìˆ˜ì— ë”°ë¥¸ ê°ì 
        failure_penalty = min(total_failures * 5, 50)

        # ì¹˜ëª…ì  ì‹¤íŒ¨ì— ë”°ë¥¸ ì¶”ê°€ ê°ì 
        critical_penalty = critical_failures * 15

        # í‰ê·  í•´ê²° ì‹œê°„ì— ë”°ë¥¸ ê°ì 
        resolution_penalty = min(avg_resolution_time / 10, 20)

        health_score = base_score - failure_penalty - critical_penalty - resolution_penalty
        return max(health_score, 0)

    def _determine_risk_level(self, health_score: float, critical_failures: int, total_failures: int) -> str:
        """ìœ„í—˜ ë ˆë²¨ ê²°ì •"""
        if critical_failures >= 3 or health_score < 30:
            return "CRITICAL"
        elif critical_failures >= 1 or health_score < 50 or total_failures >= 10:
            return "HIGH"
        elif health_score < 70 or total_failures >= 5:
            return "MEDIUM"
        else:
            return "LOW"

    def generate_recommendations(self, pattern: FailurePattern) -> List[str]:
        """ì‹¤íŒ¨ íŒ¨í„´ì— ëŒ€í•œ ê¶Œê³ ì‚¬í•­ ìƒì„±"""
        recommendations = []

        # ë¹ˆë„ ê¸°ë°˜ ê¶Œê³ 
        if pattern.frequency >= 5:
            recommendations.append(f"ğŸ”„ {pattern.failure_type} ìœ í˜•ì˜ ë°˜ë³µì  ì‹¤íŒ¨ ê°ì§€ - ê·¼ë³¸ ì›ì¸ ë¶„ì„ í•„ìš”")

        # ì‹¬ê°ë„ ê¸°ë°˜ ê¶Œê³ 
        if pattern.sub_type and "CRITICAL" in pattern.sub_type:
            recommendations.append("ğŸš¨ ì¹˜ëª…ì  ì‹¤íŒ¨ íŒ¨í„´ - ì¦‰ì‹œ ì‹œìŠ¤í…œ ì ê²€ ë° ëª¨ë‹ˆí„°ë§ ê°•í™” ê¶Œì¥")

        # í•´ê²° ì‹œê°„ ê¸°ë°˜ ê¶Œê³ 
        if pattern.avg_resolution_time > 60:
            recommendations.append("â° í‰ê·  í•´ê²° ì‹œê°„ì´ ê¸¸ìŒ - ìë™í™”ëœ ë³µêµ¬ ì ˆì°¨ ë„ì… ê³ ë ¤")

        # ì„±ê³µë¥  ê¸°ë°˜ ê¶Œê³ 
        if pattern.success_rate < 50:
            recommendations.append("ğŸ“ˆ ë³µêµ¬ ì„±ê³µë¥ ì´ ë‚®ìŒ - ë³µêµ¬ ì ˆì°¨ ê°œì„  ë° ë¬¸ì„œí™” í•„ìš”")

        # íŠ¸ë Œë“œ ê¸°ë°˜ ê¶Œê³ 
        if pattern.trend == "increasing":
            recommendations.append("ğŸ“Š ì‹¤íŒ¨ ì¦ê°€ ì¶”ì„¸ - ì˜ˆë°©ì  ì¡°ì¹˜ ë° ì‹œìŠ¤í…œ ì—…ê·¸ë ˆì´ë“œ ê²€í† ")

        # íŠ¹ì • ì‹¤íŒ¨ ìœ í˜•ë³„ ê¶Œê³ 
        failure_specific_recommendations = {
            "API_KEY_MISSING": [
                "ğŸ”‘ API í‚¤ ê´€ë¦¬ ìë™í™” ë° ë§Œë£Œ ì•Œë¦¼ ì„¤ì •",
                "ğŸ”’ ë³´ì•ˆ ìê²© ì¦ëª… ë¡œí…Œì´ì…˜ ì •ì±… ìˆ˜ë¦½"
            ],
            "MEMORY_INSUFFICIENT": [
                "ğŸ’¾ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ëª¨ë‹ˆí„°ë§ ê°•í™”",
                "âš¡ EC2 ì¸ìŠ¤í„´ìŠ¤ ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤"
            ],
            "RATE_LIMIT_EXCEEDED": [
                "ğŸš¦ API í˜¸ì¶œ ì†ë„ ì œí•œ ë° ì¬ì‹œë„ ë¡œì§ ê°œì„ ",
                "ğŸ“Š API ì‚¬ìš©ëŸ‰ íŒ¨í„´ ë¶„ì„ ë° ìµœì í™”"
            ]
        }

        if pattern.failure_type in failure_specific_recommendations:
            recommendations.extend(failure_specific_recommendations[pattern.failure_type])

        return recommendations[:5]  # ìµœëŒ€ 5ê°œ ê¶Œê³ ì‚¬í•­

    def record_recovery_attempt(self, failure_record_id: int, recovery_method: str,
                              successful: bool, execution_time: int = 0,
                              error_message: str = "", metadata: Dict = None) -> int:
        """ë³µêµ¬ ì‹œë„ ê¸°ë¡"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                cursor.execute("""
                    INSERT INTO recovery_attempts (
                        failure_record_id, recovery_method, attempted_at, successful,
                        execution_time, error_message, metadata
                    ) VALUES (?, ?, ?, ?, ?, ?, ?)
                """, (
                    failure_record_id, recovery_method,
                    datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
                    1 if successful else 0, execution_time, error_message,
                    json.dumps(metadata or {})
                ))

                attempt_id = cursor.lastrowid

                # ì›ë³¸ ì‹¤íŒ¨ ê¸°ë¡ ì—…ë°ì´íŠ¸
                cursor.execute("""
                    UPDATE failure_records
                    SET recovery_attempted = 1, recovery_successful = ?
                    WHERE id = ?
                """, (1 if successful else 0, failure_record_id))

                conn.commit()

                logger.info(f"ğŸ”§ ë³µêµ¬ ì‹œë„ ê¸°ë¡: ID={attempt_id}, ì„±ê³µ={successful}")
                return attempt_id

        except Exception as e:
            logger.error(f"âŒ ë³µêµ¬ ì‹œë„ ê¸°ë¡ ì˜¤ë¥˜: {e}")
            raise

    def cleanup_old_records(self, days: int = 30):
        """ì˜¤ë˜ëœ ì‹¤íŒ¨ ê¸°ë¡ ì •ë¦¬"""
        try:
            cutoff_date = (datetime.now() - timedelta(days=days)).strftime('%Y-%m-%d %H:%M:%S')

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ì˜¤ë˜ëœ ê¸°ë¡ ì‚­ì œ
                cursor.execute("DELETE FROM failure_records WHERE timestamp < ?", (cutoff_date,))
                deleted_failures = cursor.rowcount

                cursor.execute("DELETE FROM recovery_attempts WHERE attempted_at < ?", (cutoff_date,))
                deleted_recoveries = cursor.rowcount

                cursor.execute("DELETE FROM system_health_metrics WHERE timestamp < ?", (cutoff_date,))
                deleted_metrics = cursor.rowcount

                conn.commit()

                logger.info(f"ğŸ§¹ ì˜¤ë˜ëœ ê¸°ë¡ ì •ë¦¬ ì™„ë£Œ: ì‹¤íŒ¨={deleted_failures}, ë³µêµ¬={deleted_recoveries}, ë©”íŠ¸ë¦­={deleted_metrics}")

        except Exception as e:
            logger.error(f"âŒ ê¸°ë¡ ì •ë¦¬ ì˜¤ë¥˜: {e}")

    def get_recent_patterns(self, since_date: str) -> List[FailurePattern]:
        """ìµœê·¼ íŒ¨í„´ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT pattern_id, failure_type, sub_type, frequency,
                           first_occurrence, last_occurrence, avg_resolution_time,
                           success_rate, risk_score, trend, recommendations
                    FROM failure_patterns
                    WHERE last_occurrence >= ?
                    ORDER BY last_occurrence DESC
                """, (since_date,))

                patterns = []
                for row in cursor.fetchall():
                    pattern = FailurePattern(
                        pattern_id=row[0],
                        failure_type=row[1],
                        sub_type=row[2],
                        occurrence_count=row[3],
                        first_occurrence=row[4] if len(row) > 4 else row[5],  # fallback
                        last_occurrence=row[5],
                        avg_resolution_time=row[6],
                        success_rate=row[7],
                        risk_score=row[8],
                        trend=row[9],
                        recommendations=row[10],
                        metadata="{}"
                    )
                    patterns.append(pattern)

                return patterns

        except Exception as e:
            logger.error(f"ìµœê·¼ íŒ¨í„´ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def get_recent_failures(self, hours: int = 24) -> List[FailureRecord]:
        """ìµœê·¼ ì‹¤íŒ¨ ê¸°ë¡ ì¡°íšŒ"""
        try:
            cutoff_time = (datetime.now() - timedelta(hours=hours)).isoformat()

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT id, timestamp, execution_id, failure_type, sub_type,
                           severity, phase, error_message, metadata
                    FROM failure_records
                    WHERE timestamp >= ?
                    ORDER BY timestamp DESC
                """, (cutoff_time,))

                failures = []
                for row in cursor.fetchall():
                    failure = FailureRecord(
                        id=row[0],
                        timestamp=row[1],
                        execution_id=row[2],
                        failure_type=row[3],
                        sub_type=row[4],
                        severity=row[5],
                        phase=row[6],
                        error_message=row[7],
                        metadata=row[8] or "{}"
                    )
                    failures.append(failure)

                return failures

        except Exception as e:
            logger.error(f"ìµœê·¼ ì‹¤íŒ¨ ê¸°ë¡ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def get_failure_statistics(self, days: int = 7) -> Dict:
        """ì‹¤íŒ¨ í†µê³„ ì¡°íšŒ"""
        try:
            cutoff_time = (datetime.now() - timedelta(days=days)).isoformat()

            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ì „ì²´ ì‹¤íŒ¨ ìˆ˜
                cursor.execute("""
                    SELECT COUNT(*) FROM failure_records
                    WHERE timestamp >= ?
                """, (cutoff_time,))
                total_failures = cursor.fetchone()[0]

                # ì‹¬ê°ë„ë³„ í†µê³„
                cursor.execute("""
                    SELECT severity, COUNT(*) FROM failure_records
                    WHERE timestamp >= ?
                    GROUP BY severity
                """, (cutoff_time,))
                severity_stats = dict(cursor.fetchall())

                # íƒ€ì…ë³„ í†µê³„
                cursor.execute("""
                    SELECT failure_type, COUNT(*) FROM failure_records
                    WHERE timestamp >= ?
                    GROUP BY failure_type
                """, (cutoff_time,))
                type_stats = dict(cursor.fetchall())

                return {
                    'total_failures': total_failures,
                    'severity_stats': severity_stats,
                    'type_stats': type_stats,
                    'period_days': days
                }

        except Exception as e:
            logger.error(f"ì‹¤íŒ¨ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return {'total_failures': 0, 'severity_stats': {}, 'type_stats': {}, 'period_days': days}

    def get_current_system_health(self) -> Optional[SystemHealthMetrics]:
        """í˜„ì¬ ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT timestamp, total_failures_24h, critical_failures_24h,
                           avg_resolution_time, failure_rate_trend, most_common_failure,
                           risk_level, health_score, metrics_json
                    FROM system_health_metrics
                    ORDER BY timestamp DESC
                    LIMIT 1
                """)

                row = cursor.fetchone()
                if row:
                    return SystemHealthMetrics(
                        timestamp=row[0],
                        total_failures_24h=row[1],
                        critical_failures_24h=row[2],
                        avg_resolution_time=row[3],
                        failure_rate_trend=row[4],
                        most_common_failure=row[5],
                        risk_level=row[6],
                        health_score=row[7],
                        metrics_json=row[8]
                    )

                return None

        except Exception as e:
            logger.error(f"í˜„ì¬ ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return None

    def get_system_health_history(self, start_date: str, end_date: str) -> List[SystemHealthMetrics]:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ì´ë ¥ ì¡°íšŒ"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    SELECT timestamp, total_failures_24h, critical_failures_24h,
                           avg_resolution_time, failure_rate_trend, most_common_failure,
                           risk_level, health_score, metrics_json
                    FROM system_health_metrics
                    WHERE timestamp BETWEEN ? AND ?
                    ORDER BY timestamp ASC
                """, (start_date, end_date))

                history = []
                for row in cursor.fetchall():
                    metrics = SystemHealthMetrics(
                        timestamp=row[0],
                        total_failures_24h=row[1],
                        critical_failures_24h=row[2],
                        avg_resolution_time=row[3],
                        failure_rate_trend=row[4],
                        most_common_failure=row[5],
                        risk_level=row[6],
                        health_score=row[7],
                        metrics_json=row[8]
                    )
                    history.append(metrics)

                return history

        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ê±´ê°•ë„ ì´ë ¥ ì¡°íšŒ ì˜¤ë¥˜: {e}")
            return []

    def record_system_health(self, metrics: SystemHealthMetrics) -> int:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ ë©”íŠ¸ë¦­ ê¸°ë¡"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO system_health_metrics (
                        timestamp, total_failures_24h, critical_failures_24h,
                        avg_resolution_time, failure_rate_trend, most_common_failure,
                        risk_level, health_score, metrics_json
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    metrics.timestamp,
                    metrics.total_failures_24h,
                    metrics.critical_failures_24h,
                    metrics.avg_resolution_time,
                    metrics.failure_rate_trend,
                    metrics.most_common_failure,
                    metrics.risk_level,
                    metrics.health_score,
                    metrics.metrics_json
                ))

                health_id = cursor.lastrowid
                conn.commit()
                return health_id

        except Exception as e:
            logger.error(f"ì‹œìŠ¤í…œ ê±´ê°•ë„ ê¸°ë¡ ì˜¤ë¥˜: {e}")
            return 0

if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì½”ë“œ
    tracker = FailureTracker()

    # ìƒ˜í”Œ ì‹¤íŒ¨ ê¸°ë¡
    failure_id = tracker.record_failure(
        failure_type="API_KEY_MISSING",
        sub_type="API_ACCESS_KEY_MISSING",
        error_message="UPBIT_ACCESS_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ",
        execution_id="20250918_test",
        severity="CRITICAL",
        phase="ì´ˆê¸°í™”",
        metadata={"config_file": ".env"}
    )

    print(f"âœ… ì‹¤íŒ¨ ê¸°ë¡ ìƒì„±: ID={failure_id}")

    # ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸
    health = tracker.get_system_health()
    print(f"ğŸ¥ ì‹œìŠ¤í…œ ê±´ê°•ë„: {health.health_score:.1f}/100, ìœ„í—˜ë„: {health.risk_level}")

    # íŒ¨í„´ ë¶„ì„
    patterns = tracker.get_failure_patterns()
    print(f"ğŸ“Š ì‹¤íŒ¨ íŒ¨í„´ {len(patterns)}ê°œ ê°ì§€")