#!/usr/bin/env python3
"""
Makenaide Phase 4 ì˜ˆì¸¡ì  ë¶„ì„ ì‹œìŠ¤í…œ (Predictive Analysis System)

Phase 4 í•µì‹¬ êµ¬ì„±ìš”ì†Œ:
- ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ ê±´ê°•ë„ ëª¨ë‹ˆí„°ë§
- ì¥ì•  íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜
- ì¡°ê¸° ê²½ê³  ì‹œìŠ¤í…œ (Early Warning System)
- ìë™ ìœ„í—˜ë„ ìŠ¤ì½”ì–´ë§
- ì˜ˆë°©ì  ì¡°ì¹˜ ì œì•ˆ

ê³ ê¸‰ ì˜ˆì¸¡ ê¸°ëŠ¥:
- ì‹œê³„ì—´ ë¶„ì„ ê¸°ë°˜ íŠ¸ë Œë“œ ì˜ˆì¸¡
- ì—°ì‡„ ì¥ì•  ì˜ˆì¸¡ (Cascading Failure Prediction)
- ì‹œìŠ¤í…œ ë¶€í•˜ ì˜ˆì¸¡
- ê³„ì ˆì„± ë° ì£¼ê¸°ì„± ë¶„ì„
"""

import os
import sys
import json
import sqlite3
import statistics
from datetime import datetime, timedelta
from typing import Dict, List, Tuple, Optional, NamedTuple
from dataclasses import dataclass
from enum import Enum
import logging

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from failure_tracker import FailureTracker, FailureRecord, FailurePattern, SystemHealthMetrics
from sns_notification_system import (
    FailureType, FailureSubType, FailureSeverity,
    NotificationLevel, NotificationCategory
)

class PredictionConfidence(Enum):
    """ì˜ˆì¸¡ ì‹ ë¢°ë„ ë ˆë²¨"""
    VERY_LOW = "VERY_LOW"      # 0-20%
    LOW = "LOW"                # 20-40%
    MEDIUM = "MEDIUM"          # 40-60%
    HIGH = "HIGH"              # 60-80%
    VERY_HIGH = "VERY_HIGH"    # 80-100%

class RiskLevel(Enum):
    """ìœ„í—˜ë„ ë ˆë²¨"""
    MINIMAL = "MINIMAL"        # 0-10%
    LOW = "LOW"               # 10-30%
    MODERATE = "MODERATE"     # 30-50%
    HIGH = "HIGH"             # 50-70%
    CRITICAL = "CRITICAL"     # 70-100%

@dataclass
class PredictionResult:
    """ì˜ˆì¸¡ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    prediction_id: str
    prediction_type: str
    risk_level: RiskLevel
    confidence: PredictionConfidence
    predicted_failure_time: Optional[datetime]
    failure_probability: float
    affected_components: List[str]
    recommended_actions: List[str]
    evidence: List[str]
    metadata: Dict
    created_at: datetime

@dataclass
class TrendAnalysis:
    """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼"""
    metric_name: str
    trend_direction: str  # "increasing", "decreasing", "stable", "volatile"
    trend_strength: float  # 0.0-1.0
    slope: float
    r_squared: float
    prediction_7d: float
    prediction_30d: float
    anomaly_score: float

class PredictiveAnalyzer:
    """Phase 4 ì˜ˆì¸¡ì  ë¶„ì„ ì—”ì§„"""

    def __init__(self, db_path: str = "./data/spock_local.db"):
        self.db_path = db_path
        self.logger = logging.getLogger(__name__)
        self.failure_tracker = FailureTracker(db_path)

        # ì˜ˆì¸¡ ëª¨ë¸ ì„¤ì •
        self.prediction_thresholds = {
            'failure_rate_threshold': 0.15,  # 15% ì´ìƒ ì‹¤íŒ¨ìœ¨
            'error_spike_threshold': 3.0,    # í‰ê·  ëŒ€ë¹„ 3ë°° ì´ìƒ ì—ëŸ¬
            'response_time_threshold': 2.0,  # í‰ê·  ëŒ€ë¹„ 2ë°° ì´ìƒ ì‘ë‹µì‹œê°„
            'memory_threshold': 0.85,        # 85% ì´ìƒ ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
            'cascade_risk_threshold': 0.6    # 60% ì´ìƒ ì—°ì‡„ ì¥ì•  ìœ„í—˜
        }

        # ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ ê°€ì¤‘ì¹˜
        self.algorithm_weights = {
            'historical_pattern': 0.3,
            'trend_analysis': 0.25,
            'seasonal_pattern': 0.2,
            'system_metrics': 0.15,
            'external_factors': 0.1
        }

        self._init_prediction_tables()

    def _init_prediction_tables(self):
        """ì˜ˆì¸¡ ë¶„ì„ í…Œì´ë¸” ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()

            # ì˜ˆì¸¡ ê²°ê³¼ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS prediction_results (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    prediction_id TEXT UNIQUE NOT NULL,
                    prediction_type TEXT NOT NULL,
                    risk_level TEXT NOT NULL,
                    confidence TEXT NOT NULL,
                    predicted_failure_time TEXT,
                    failure_probability REAL NOT NULL,
                    affected_components TEXT,
                    recommended_actions TEXT,
                    evidence TEXT,
                    metadata TEXT,
                    created_at TEXT NOT NULL,
                    validated_at TEXT,
                    actual_outcome TEXT,
                    accuracy_score REAL
                )
            """)

            # íŠ¸ë Œë“œ ë¶„ì„ í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS trend_analysis (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    metric_name TEXT NOT NULL,
                    analysis_date TEXT NOT NULL,
                    trend_direction TEXT NOT NULL,
                    trend_strength REAL NOT NULL,
                    slope REAL NOT NULL,
                    r_squared REAL NOT NULL,
                    prediction_7d REAL,
                    prediction_30d REAL,
                    anomaly_score REAL NOT NULL,
                    metadata TEXT,
                    created_at TEXT NOT NULL
                )
            """)

            # ì˜ˆì¸¡ ì •í™•ë„ ì¶”ì  í…Œì´ë¸”
            cursor.execute("""
                CREATE TABLE IF NOT EXISTS prediction_accuracy (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    prediction_id TEXT NOT NULL,
                    prediction_type TEXT NOT NULL,
                    predicted_time TEXT,
                    actual_time TEXT,
                    accuracy_score REAL NOT NULL,
                    confidence_level TEXT NOT NULL,
                    notes TEXT,
                    created_at TEXT NOT NULL,
                    FOREIGN KEY (prediction_id) REFERENCES prediction_results (prediction_id)
                )
            """)

            conn.commit()

    def analyze_system_health_trends(self, days: int = 30) -> List[TrendAnalysis]:
        """ì‹œìŠ¤í…œ ê±´ê°•ë„ íŠ¸ë Œë“œ ë¶„ì„"""
        end_date = datetime.now()
        start_date = end_date - timedelta(days=days)

        # ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ë°ì´í„° ìˆ˜ì§‘
        metrics_data = self.failure_tracker.get_system_health_history(
            start_date.isoformat(),
            end_date.isoformat()
        )

        trends = []

        if not metrics_data:
            self.logger.warning("ì‹œìŠ¤í…œ ê±´ê°•ë„ ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
            return trends

        # ë¶„ì„í•  ë©”íŠ¸ë¦­ë“¤
        metric_names = [
            'failure_rate', 'avg_response_time', 'memory_usage',
            'cpu_usage', 'error_count', 'success_rate'
        ]

        for metric_name in metric_names:
            try:
                trend = self._analyze_metric_trend(metrics_data, metric_name, days)
                if trend:
                    trends.append(trend)
                    self._save_trend_analysis(trend)
            except Exception as e:
                self.logger.error(f"ë©”íŠ¸ë¦­ {metric_name} íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")

        return trends

    def _analyze_metric_trend(self, metrics_data: List[SystemHealthMetrics],
                             metric_name: str, days: int) -> Optional[TrendAnalysis]:
        """ê°œë³„ ë©”íŠ¸ë¦­ì˜ íŠ¸ë Œë“œ ë¶„ì„"""
        try:
            # ë©”íŠ¸ë¦­ ê°’ ì¶”ì¶œ
            values = []
            timestamps = []

            for metric in metrics_data:
                if hasattr(metric, metric_name):
                    value = getattr(metric, metric_name)
                    if value is not None:
                        values.append(float(value))
                        timestamps.append(datetime.fromisoformat(metric.timestamp))

            if len(values) < 5:  # ìµœì†Œ 5ê°œ ë°ì´í„° í¬ì¸íŠ¸ í•„ìš”
                return None

            # ì„ í˜• íšŒê·€ ë¶„ì„ (ê°„ë‹¨í•œ êµ¬í˜„)
            n = len(values)
            x_values = list(range(n))

            # ê¸°ìš¸ê¸° ê³„ì‚°
            x_mean = statistics.mean(x_values)
            y_mean = statistics.mean(values)

            numerator = sum((x - x_mean) * (y - y_mean) for x, y in zip(x_values, values))
            denominator = sum((x - x_mean) ** 2 for x in x_values)

            if denominator == 0:
                slope = 0
            else:
                slope = numerator / denominator

            # RÂ² ê³„ì‚°
            y_pred = [slope * x + (y_mean - slope * x_mean) for x in x_values]
            ss_res = sum((y - yp) ** 2 for y, yp in zip(values, y_pred))
            ss_tot = sum((y - y_mean) ** 2 for y in values)

            r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0

            # íŠ¸ë Œë“œ ë°©í–¥ ê²°ì •
            if abs(slope) < 0.01:
                trend_direction = "stable"
            elif slope > 0:
                trend_direction = "increasing"
            else:
                trend_direction = "decreasing"

            # ë³€ë™ì„± í™•ì¸
            std_dev = statistics.stdev(values) if len(values) > 1 else 0
            mean_val = statistics.mean(values)
            coefficient_of_variation = std_dev / mean_val if mean_val != 0 else 0

            if coefficient_of_variation > 0.3:
                trend_direction = "volatile"

            # íŠ¸ë Œë“œ ê°•ë„ (0.0-1.0)
            trend_strength = min(abs(slope) * 10, 1.0)

            # ë¯¸ë˜ ì˜ˆì¸¡
            prediction_7d = slope * (n + 7) + (y_mean - slope * x_mean)
            prediction_30d = slope * (n + 30) + (y_mean - slope * x_mean)

            # ì´ìƒì¹˜ ìŠ¤ì½”ì–´ ê³„ì‚°
            recent_values = values[-7:] if len(values) >= 7 else values
            recent_mean = statistics.mean(recent_values)
            historical_mean = statistics.mean(values[:-7]) if len(values) > 7 else recent_mean

            anomaly_score = abs(recent_mean - historical_mean) / historical_mean if historical_mean != 0 else 0
            anomaly_score = min(anomaly_score, 1.0)

            return TrendAnalysis(
                metric_name=metric_name,
                trend_direction=trend_direction,
                trend_strength=trend_strength,
                slope=slope,
                r_squared=r_squared,
                prediction_7d=prediction_7d,
                prediction_30d=prediction_30d,
                anomaly_score=anomaly_score
            )

        except Exception as e:
            self.logger.error(f"ë©”íŠ¸ë¦­ {metric_name} íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
            return None

    def predict_failure_probability(self, time_window_hours: int = 24) -> PredictionResult:
        """ì§€ì •ëœ ì‹œê°„ ë‚´ ì¥ì•  ë°œìƒ í™•ë¥  ì˜ˆì¸¡"""
        try:
            prediction_id = f"failure_prob_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

            # ê³¼ê±° 30ì¼ ë°ì´í„° ë¶„ì„
            analysis_period = datetime.now() - timedelta(days=30)
            recent_patterns = self.failure_tracker.get_recent_patterns(analysis_period.isoformat())

            # ë‹¤ì–‘í•œ ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ ê²°ê³¼ ìˆ˜ì§‘
            predictions = {
                'historical_pattern': self._predict_from_historical_patterns(recent_patterns, time_window_hours),
                'trend_analysis': self._predict_from_trends(time_window_hours),
                'seasonal_pattern': self._predict_from_seasonal_patterns(time_window_hours),
                'system_metrics': self._predict_from_system_metrics(),
                'external_factors': self._predict_from_external_factors()
            }

            # ê°€ì¤‘ í‰ê· ìœ¼ë¡œ ìµœì¢… í™•ë¥  ê³„ì‚°
            weighted_probability = sum(
                predictions[algo] * self.algorithm_weights[algo]
                for algo in predictions
            )

            # ìœ„í—˜ë„ ë ˆë²¨ ê²°ì •
            risk_level = self._calculate_risk_level(weighted_probability)

            # ì‹ ë¢°ë„ ê³„ì‚°
            confidence = self._calculate_prediction_confidence(predictions, recent_patterns)

            # ì˜í–¥ë°›ì„ ìˆ˜ ìˆëŠ” ì»´í¬ë„ŒíŠ¸ ì‹ë³„
            affected_components = self._identify_affected_components(recent_patterns)

            # ê¶Œì¥ ì¡°ì¹˜ ìƒì„±
            recommended_actions = self._generate_recommended_actions(
                risk_level, affected_components, predictions
            )

            # ì¦ê±° ìˆ˜ì§‘
            evidence = self._collect_prediction_evidence(predictions, recent_patterns)

            # ì˜ˆì¸¡ëœ ì¥ì•  ì‹œê°„ ê³„ì‚°
            predicted_failure_time = None
            if weighted_probability > 0.5:
                predicted_failure_time = datetime.now() + timedelta(
                    hours=time_window_hours * (1 - weighted_probability)
                )

            result = PredictionResult(
                prediction_id=prediction_id,
                prediction_type="failure_probability",
                risk_level=risk_level,
                confidence=confidence,
                predicted_failure_time=predicted_failure_time,
                failure_probability=weighted_probability,
                affected_components=affected_components,
                recommended_actions=recommended_actions,
                evidence=evidence,
                metadata={
                    'time_window_hours': time_window_hours,
                    'algorithm_scores': predictions,
                    'analysis_period_days': 30
                },
                created_at=datetime.now()
            )

            # ê²°ê³¼ ì €ì¥
            self._save_prediction_result(result)

            return result

        except Exception as e:
            self.logger.error(f"ì¥ì•  í™•ë¥  ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            # ê¸°ë³¸ ì˜ˆì¸¡ ê²°ê³¼ ë°˜í™˜
            return PredictionResult(
                prediction_id=f"error_{datetime.now().strftime('%Y%m%d_%H%M%S')}",
                prediction_type="failure_probability",
                risk_level=RiskLevel.LOW,
                confidence=PredictionConfidence.VERY_LOW,
                predicted_failure_time=None,
                failure_probability=0.1,
                affected_components=[],
                recommended_actions=["ì‹œìŠ¤í…œ ëª¨ë‹ˆí„°ë§ ê°•í™”"],
                evidence=["ì˜ˆì¸¡ ë¶„ì„ ì˜¤ë¥˜ë¡œ ì¸í•œ ê¸°ë³¸ê°’"],
                metadata={'error': str(e)},
                created_at=datetime.now()
            )

    def _predict_from_historical_patterns(self, patterns: List[FailurePattern],
                                        time_window_hours: int) -> float:
        """ê³¼ê±° íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡"""
        if not patterns:
            return 0.1  # ê¸°ë³¸ ë‚®ì€ í™•ë¥ 

        # ìµœê·¼ íŒ¨í„´ë“¤ì˜ ë¹ˆë„ ë¶„ì„
        pattern_frequencies = {}
        for pattern in patterns:
            key = f"{pattern.failure_type}_{pattern.sub_type}"
            pattern_frequencies[key] = pattern_frequencies.get(key, 0) + pattern.occurrence_count

        # ì‹œê°„ ê°€ì¤‘ ë¹ˆë„ ê³„ì‚°
        total_frequency = sum(pattern_frequencies.values())
        if total_frequency == 0:
            return 0.1

        # ì‹œê°„ ìœˆë„ìš° ë‚´ ì˜ˆìƒ ì¥ì•  ìˆ˜
        daily_failure_rate = total_frequency / 30  # 30ì¼ í‰ê· 
        window_failure_rate = daily_failure_rate * (time_window_hours / 24)

        # í™•ë¥ ë¡œ ë³€í™˜ (0-1 ë²”ìœ„)
        probability = min(window_failure_rate / 5, 0.9)  # ìµœëŒ€ 90%

        return probability

    def _predict_from_trends(self, time_window_hours: int) -> float:
        """íŠ¸ë Œë“œ ë¶„ì„ ê¸°ë°˜ ì˜ˆì¸¡"""
        try:
            trends = self.analyze_system_health_trends(days=14)

            if not trends:
                return 0.1

            risk_score = 0.0
            weight_sum = 0.0

            for trend in trends:
                # ë©”íŠ¸ë¦­ë³„ ê°€ì¤‘ì¹˜
                metric_weights = {
                    'failure_rate': 0.3,
                    'error_count': 0.25,
                    'avg_response_time': 0.2,
                    'memory_usage': 0.15,
                    'cpu_usage': 0.1
                }

                weight = metric_weights.get(trend.metric_name, 0.1)

                # íŠ¸ë Œë“œê°€ ì•…í™”ë˜ëŠ” ê²½ìš° ìœ„í—˜ë„ ì¦ê°€
                if trend.trend_direction == "increasing" and trend.metric_name in ['failure_rate', 'error_count', 'avg_response_time']:
                    risk_score += trend.trend_strength * weight * trend.anomaly_score
                elif trend.trend_direction == "decreasing" and trend.metric_name in ['success_rate']:
                    risk_score += trend.trend_strength * weight * trend.anomaly_score
                elif trend.trend_direction == "volatile":
                    risk_score += 0.5 * weight * trend.anomaly_score

                weight_sum += weight

            if weight_sum > 0:
                normalized_risk = risk_score / weight_sum
                return min(normalized_risk, 0.8)

            return 0.1

        except Exception as e:
            self.logger.error(f"íŠ¸ë Œë“œ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return 0.1

    def _predict_from_seasonal_patterns(self, time_window_hours: int) -> float:
        """ê³„ì ˆì„±/ì£¼ê¸°ì„± íŒ¨í„´ ê¸°ë°˜ ì˜ˆì¸¡"""
        try:
            now = datetime.now()

            # ì‹œê°„ëŒ€ë³„ ì¥ì•  íŒ¨í„´ ë¶„ì„
            hour_risk = self._get_hourly_failure_risk(now.hour)

            # ìš”ì¼ë³„ ì¥ì•  íŒ¨í„´ ë¶„ì„
            weekday_risk = self._get_weekday_failure_risk(now.weekday())

            # ì›”ë³„ ì¥ì•  íŒ¨í„´ ë¶„ì„
            monthly_risk = self._get_monthly_failure_risk(now.month)

            # ê°€ì¤‘ í‰ê· 
            seasonal_probability = (hour_risk * 0.5 + weekday_risk * 0.3 + monthly_risk * 0.2)

            return min(seasonal_probability, 0.7)

        except Exception as e:
            self.logger.error(f"ê³„ì ˆì„± ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return 0.1

    def _predict_from_system_metrics(self) -> float:
        """í˜„ì¬ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ê¸°ë°˜ ì˜ˆì¸¡"""
        try:
            # ìµœê·¼ ì‹œìŠ¤í…œ ê±´ê°•ë„ ì¡°íšŒ
            recent_health = self.failure_tracker.get_current_system_health()

            if not recent_health:
                return 0.2

            risk_factors = []

            # ì‹¤íŒ¨ìœ¨ ì²´í¬
            if recent_health.failure_rate > self.prediction_thresholds['failure_rate_threshold']:
                risk_factors.append(recent_health.failure_rate * 0.3)

            # ì‘ë‹µì‹œê°„ ì²´í¬
            if recent_health.avg_response_time > 5.0:  # 5ì´ˆ ì´ìƒ
                risk_factors.append(0.2)

            # ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥  ì²´í¬
            if recent_health.memory_usage > self.prediction_thresholds['memory_threshold']:
                risk_factors.append((recent_health.memory_usage - 0.8) * 0.5)

            # ì—ëŸ¬ ì¹´ìš´íŠ¸ ì²´í¬
            if recent_health.error_count > 10:
                risk_factors.append(min(recent_health.error_count / 50, 0.3))

            total_risk = sum(risk_factors)
            return min(total_risk, 0.8)

        except Exception as e:
            self.logger.error(f"ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­ ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
            return 0.1

    def _predict_from_external_factors(self) -> float:
        """ì™¸ë¶€ ìš”ì¸ ê¸°ë°˜ ì˜ˆì¸¡"""
        # ì‹œê°„ëŒ€, ì‹œì¥ ìƒí™© ë“± ì™¸ë¶€ ìš”ì¸ ê³ ë ¤
        now = datetime.now()

        # ê±°ë˜ í™œì„± ì‹œê°„ëŒ€ (í•œêµ­ ì‹œê°„ ê¸°ì¤€)
        if 9 <= now.hour <= 18:
            return 0.2  # ê±°ë˜ ì‹œê°„ëŒ€ëŠ” ë¶€í•˜ê°€ ë†’ì•„ ìœ„í—˜ë„ ì¦ê°€
        elif 0 <= now.hour <= 6:
            return 0.1  # ìƒˆë²½ ì‹œê°„ëŒ€ëŠ” ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì „
        else:
            return 0.15  # ê¸°ë³¸ ìœ„í—˜ë„

    def _calculate_risk_level(self, probability: float) -> RiskLevel:
        """í™•ë¥  ê¸°ë°˜ ìœ„í—˜ë„ ë ˆë²¨ ê³„ì‚°"""
        if probability < 0.1:
            return RiskLevel.MINIMAL
        elif probability < 0.3:
            return RiskLevel.LOW
        elif probability < 0.5:
            return RiskLevel.MODERATE
        elif probability < 0.7:
            return RiskLevel.HIGH
        else:
            return RiskLevel.CRITICAL

    def _calculate_prediction_confidence(self, predictions: Dict[str, float],
                                       patterns: List[FailurePattern]) -> PredictionConfidence:
        """ì˜ˆì¸¡ ì‹ ë¢°ë„ ê³„ì‚°"""
        # ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ë“¤ì˜ ì¼ì¹˜ë„ í™•ì¸
        prediction_values = list(predictions.values())
        if len(prediction_values) < 2:
            return PredictionConfidence.LOW

        std_dev = statistics.stdev(prediction_values)
        mean_val = statistics.mean(prediction_values)

        # ë³€ë™ê³„ìˆ˜ ê³„ì‚°
        cv = std_dev / mean_val if mean_val != 0 else 1.0

        # ë°ì´í„° í’ˆì§ˆ í‰ê°€
        data_quality = len(patterns) / 10  # 10ê°œ íŒ¨í„´ë‹¹ 1ì 
        data_quality = min(data_quality, 1.0)

        # ì‹ ë¢°ë„ ì ìˆ˜ ê³„ì‚° (0-1)
        consistency_score = 1 - min(cv, 1.0)
        confidence_score = (consistency_score * 0.7 + data_quality * 0.3)

        if confidence_score < 0.2:
            return PredictionConfidence.VERY_LOW
        elif confidence_score < 0.4:
            return PredictionConfidence.LOW
        elif confidence_score < 0.6:
            return PredictionConfidence.MEDIUM
        elif confidence_score < 0.8:
            return PredictionConfidence.HIGH
        else:
            return PredictionConfidence.VERY_HIGH

    def _identify_affected_components(self, patterns: List[FailurePattern]) -> List[str]:
        """ì˜í–¥ë°›ì„ ìˆ˜ ìˆëŠ” ì»´í¬ë„ŒíŠ¸ ì‹ë³„"""
        components = set()

        for pattern in patterns:
            if pattern.metadata:
                try:
                    metadata = json.loads(pattern.metadata)
                    if 'phase' in metadata:
                        components.add(f"Phase {metadata['phase']}")
                    if 'component' in metadata:
                        components.add(metadata['component'])
                except:
                    pass

            # ì‹¤íŒ¨ ìœ í˜•ë³„ ì»´í¬ë„ŒíŠ¸ ë§¤í•‘
            failure_component_map = {
                'API_ERROR': ['ì—…ë¹„íŠ¸ API', 'ì™¸ë¶€ ì—°ë™'],
                'DATABASE_ERROR': ['SQLite DB', 'ë°ì´í„° ê´€ë¦¬'],
                'NETWORK_ERROR': ['ë„¤íŠ¸ì›Œí¬', 'ì™¸ë¶€ ì—°ë™'],
                'TRADING_ERROR': ['ê±°ë˜ ì—”ì§„', 'í¬íŠ¸í´ë¦¬ì˜¤ ê´€ë¦¬'],
                'DATA_ERROR': ['ë°ì´í„° ìˆ˜ì§‘', 'ê¸°ìˆ ì  ë¶„ì„']
            }

            if pattern.failure_type in failure_component_map:
                components.update(failure_component_map[pattern.failure_type])

        return list(components)

    def _generate_recommended_actions(self, risk_level: RiskLevel,
                                    affected_components: List[str],
                                    predictions: Dict[str, float]) -> List[str]:
        """ìœ„í—˜ë„ì— ë”°ë¥¸ ê¶Œì¥ ì¡°ì¹˜ ìƒì„±"""
        actions = []

        # ìœ„í—˜ë„ë³„ ê¸°ë³¸ ì¡°ì¹˜
        if risk_level == RiskLevel.CRITICAL:
            actions.extend([
                "ğŸš¨ ì¦‰ì‹œ ì‹œìŠ¤í…œ ì ê²€ ì‹¤ì‹œ",
                "ğŸ“ ìš´ì˜íŒ€ ê¸´ê¸‰ ì†Œì§‘",
                "ğŸ”„ ë°±ì—… ì‹œìŠ¤í…œ ì¤€ë¹„",
                "ğŸ“Š ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§ ê°•í™”"
            ])
        elif risk_level == RiskLevel.HIGH:
            actions.extend([
                "âš ï¸ ì‹œìŠ¤í…œ ìƒíƒœ ì§‘ì¤‘ ëª¨ë‹ˆí„°ë§",
                "ğŸ”§ ì˜ˆë°©ì  ìœ ì§€ë³´ìˆ˜ ì‹¤ì‹œ",
                "ğŸ“‹ ì¥ì•  ëŒ€ì‘ ê³„íš ì ê²€"
            ])
        elif risk_level == RiskLevel.MODERATE:
            actions.extend([
                "ğŸ“ˆ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ëª¨ë‹ˆí„°ë§ ì¦ê°€",
                "ğŸ” ë¡œê·¸ ë¶„ì„ ê°•í™”"
            ])

        # ì»´í¬ë„ŒíŠ¸ë³„ ë§ì¶¤ ì¡°ì¹˜
        for component in affected_components:
            if 'API' in component:
                actions.append("ğŸ”— API ì—°ê²° ìƒíƒœ ë° ì‘ë‹µì‹œê°„ ì ê²€")
            elif 'DB' in component:
                actions.append("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì„±ëŠ¥ ë° ë¬´ê²°ì„± ì ê²€")
            elif 'ê±°ë˜' in component:
                actions.append("ğŸ’° ê±°ë˜ ì‹œìŠ¤í…œ ë° í¬íŠ¸í´ë¦¬ì˜¤ ìƒíƒœ ì ê²€")

        # ì˜ˆì¸¡ ì•Œê³ ë¦¬ì¦˜ë³„ ì¡°ì¹˜
        if predictions.get('trend_analysis', 0) > 0.5:
            actions.append("ğŸ“Š ì„±ëŠ¥ íŠ¸ë Œë“œ ê°œì„  ì¡°ì¹˜ ì‹¤ì‹œ")

        if predictions.get('system_metrics', 0) > 0.5:
            actions.append("ğŸ–¥ï¸ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìµœì í™”")

        return list(set(actions))  # ì¤‘ë³µ ì œê±°

    def _collect_prediction_evidence(self, predictions: Dict[str, float],
                                   patterns: List[FailurePattern]) -> List[str]:
        """ì˜ˆì¸¡ ê·¼ê±° ìˆ˜ì§‘"""
        evidence = []

        # ì•Œê³ ë¦¬ì¦˜ë³„ ê·¼ê±°
        for algo, score in predictions.items():
            if score > 0.3:
                if algo == 'historical_pattern':
                    evidence.append(f"ğŸ“ˆ ê³¼ê±° íŒ¨í„´ ë¶„ì„: {score:.1%} ìœ„í—˜ë„")
                elif algo == 'trend_analysis':
                    evidence.append(f"ğŸ“Š íŠ¸ë Œë“œ ë¶„ì„: {score:.1%} ì•…í™” ê²½í–¥")
                elif algo == 'system_metrics':
                    evidence.append(f"ğŸ–¥ï¸ ì‹œìŠ¤í…œ ë©”íŠ¸ë¦­: {score:.1%} ì„ê³„ì¹˜ ê·¼ì ‘")

        # íŒ¨í„´ ê·¼ê±°
        if patterns:
            recent_failures = sum(1 for p in patterns if p.last_occurrence)
            evidence.append(f"ğŸ” ìµœê·¼ 30ì¼ {recent_failures}ê°œ ìœ ì‚¬ íŒ¨í„´ ê°ì§€")

        return evidence

    def _save_prediction_result(self, result: PredictionResult):
        """ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO prediction_results (
                        prediction_id, prediction_type, risk_level, confidence,
                        predicted_failure_time, failure_probability, affected_components,
                        recommended_actions, evidence, metadata, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    result.prediction_id,
                    result.prediction_type,
                    result.risk_level.value,
                    result.confidence.value,
                    result.predicted_failure_time.isoformat() if result.predicted_failure_time else None,
                    result.failure_probability,
                    json.dumps(result.affected_components),
                    json.dumps(result.recommended_actions),
                    json.dumps(result.evidence),
                    json.dumps(result.metadata),
                    result.created_at.isoformat()
                ))
                conn.commit()

        except Exception as e:
            self.logger.error(f"ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥ ì˜¤ë¥˜: {e}")

    def _save_trend_analysis(self, trend: TrendAnalysis):
        """íŠ¸ë Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()
                cursor.execute("""
                    INSERT INTO trend_analysis (
                        metric_name, analysis_date, trend_direction, trend_strength,
                        slope, r_squared, prediction_7d, prediction_30d,
                        anomaly_score, created_at
                    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    trend.metric_name,
                    datetime.now().date().isoformat(),
                    trend.trend_direction,
                    trend.trend_strength,
                    trend.slope,
                    trend.r_squared,
                    trend.prediction_7d,
                    trend.prediction_30d,
                    trend.anomaly_score,
                    datetime.now().isoformat()
                ))
                conn.commit()

        except Exception as e:
            self.logger.error(f"íŠ¸ë Œë“œ ë¶„ì„ ì €ì¥ ì˜¤ë¥˜: {e}")

    def _get_hourly_failure_risk(self, hour: int) -> float:
        """ì‹œê°„ëŒ€ë³„ ì¥ì•  ìœ„í—˜ë„ ì¡°íšŒ"""
        # ì‹¤ì œë¡œëŠ” DBì—ì„œ ì‹œê°„ëŒ€ë³„ í†µê³„ë¥¼ ì¡°íšŒí•´ì•¼ í•¨
        # ì—¬ê¸°ì„œëŠ” ì¼ë°˜ì ì¸ íŒ¨í„´ìœ¼ë¡œ ê·¼ì‚¬
        high_risk_hours = [9, 10, 15, 16, 21, 22]  # ê±°ë˜ í™œì„± ì‹œê°„
        if hour in high_risk_hours:
            return 0.3
        elif 0 <= hour <= 6:
            return 0.1  # ìƒˆë²½ì€ ìƒëŒ€ì ìœ¼ë¡œ ì•ˆì „
        else:
            return 0.2

    def _get_weekday_failure_risk(self, weekday: int) -> float:
        """ìš”ì¼ë³„ ì¥ì•  ìœ„í—˜ë„ ì¡°íšŒ"""
        # 0=ì›”ìš”ì¼, 6=ì¼ìš”ì¼
        if weekday < 5:  # í‰ì¼
            return 0.25
        else:  # ì£¼ë§
            return 0.15

    def _get_monthly_failure_risk(self, month: int) -> float:
        """ì›”ë³„ ì¥ì•  ìœ„í—˜ë„ ì¡°íšŒ"""
        # ì‹¤ì œë¡œëŠ” ê³„ì ˆì„± ë°ì´í„° ë¶„ì„ í•„ìš”
        return 0.2  # ê¸°ë³¸ê°’

    def generate_daily_prediction_report(self) -> Dict:
        """ì¼ì¼ ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„±"""
        try:
            # 24ì‹œê°„ ì˜ˆì¸¡
            prediction_24h = self.predict_failure_probability(24)

            # 7ì¼ ì˜ˆì¸¡
            prediction_7d = self.predict_failure_probability(24 * 7)

            # íŠ¸ë Œë“œ ë¶„ì„
            trends = self.analyze_system_health_trends(14)

            # ìœ„í—˜ ìš”ì†Œ ì‹ë³„
            risk_factors = self._identify_current_risk_factors()

            report = {
                'report_date': datetime.now().isoformat(),
                'predictions': {
                    '24_hours': {
                        'risk_level': prediction_24h.risk_level.value,
                        'probability': prediction_24h.failure_probability,
                        'confidence': prediction_24h.confidence.value,
                        'affected_components': prediction_24h.affected_components,
                        'recommended_actions': prediction_24h.recommended_actions
                    },
                    '7_days': {
                        'risk_level': prediction_7d.risk_level.value,
                        'probability': prediction_7d.failure_probability,
                        'confidence': prediction_7d.confidence.value
                    }
                },
                'trends': [
                    {
                        'metric': trend.metric_name,
                        'direction': trend.trend_direction,
                        'strength': trend.trend_strength,
                        'anomaly_score': trend.anomaly_score
                    }
                    for trend in trends
                ],
                'risk_factors': risk_factors,
                'summary': self._generate_prediction_summary(prediction_24h, trends)
            }

            return report

        except Exception as e:
            self.logger.error(f"ì¼ì¼ ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„± ì˜¤ë¥˜: {e}")
            return {
                'error': str(e),
                'report_date': datetime.now().isoformat()
            }

    def _identify_current_risk_factors(self) -> List[Dict]:
        """í˜„ì¬ ìœ„í—˜ ìš”ì†Œ ì‹ë³„"""
        risk_factors = []

        try:
            # ìµœê·¼ ì‹œìŠ¤í…œ ê±´ê°•ë„ í™•ì¸
            health = self.failure_tracker.get_current_system_health()

            if health:
                if health.failure_rate > 0.1:
                    risk_factors.append({
                        'type': 'high_failure_rate',
                        'value': health.failure_rate,
                        'description': f'ë†’ì€ ì‹¤íŒ¨ìœ¨: {health.failure_rate:.1%}'
                    })

                if health.avg_response_time > 3.0:
                    risk_factors.append({
                        'type': 'slow_response',
                        'value': health.avg_response_time,
                        'description': f'ëŠë¦° ì‘ë‹µì‹œê°„: {health.avg_response_time:.1f}ì´ˆ'
                    })

                if health.error_count > 5:
                    risk_factors.append({
                        'type': 'high_error_count',
                        'value': health.error_count,
                        'description': f'ë†’ì€ ì—ëŸ¬ ìˆ˜: {health.error_count}ê°œ'
                    })

        except Exception as e:
            self.logger.error(f"ìœ„í—˜ ìš”ì†Œ ì‹ë³„ ì˜¤ë¥˜: {e}")

        return risk_factors

    def _generate_prediction_summary(self, prediction: PredictionResult,
                                   trends: List[TrendAnalysis]) -> str:
        """ì˜ˆì¸¡ ìš”ì•½ ìƒì„±"""
        summary_parts = []

        # ìœ„í—˜ë„ ìš”ì•½
        if prediction.risk_level == RiskLevel.CRITICAL:
            summary_parts.append("ğŸš¨ ê¸´ê¸‰: ë†’ì€ ì¥ì•  ìœ„í—˜ë„ ê°ì§€")
        elif prediction.risk_level == RiskLevel.HIGH:
            summary_parts.append("âš ï¸ ì£¼ì˜: ì¤‘ê°„ ì¥ì•  ìœ„í—˜ë„")
        elif prediction.risk_level == RiskLevel.MODERATE:
            summary_parts.append("ğŸ“Š ëª¨ë‹ˆí„°ë§: ë³´í†µ ìœ„í—˜ë„")
        else:
            summary_parts.append("âœ… ì•ˆì •: ë‚®ì€ ìœ„í—˜ë„")

        # íŠ¸ë Œë“œ ìš”ì•½
        deteriorating_trends = [t for t in trends if t.trend_direction == "increasing" and t.anomaly_score > 0.3]
        if deteriorating_trends:
            summary_parts.append(f"ğŸ“ˆ {len(deteriorating_trends)}ê°œ ë©”íŠ¸ë¦­ ì•…í™” ì¤‘")

        # ì‹ ë¢°ë„ ìš”ì•½
        summary_parts.append(f"ì‹ ë¢°ë„: {prediction.confidence.value}")

        return " | ".join(summary_parts)

def main():
    """ë©”ì¸ í•¨ìˆ˜ - ì˜ˆì¸¡ ë¶„ì„ ì‹¤í–‰"""
    analyzer = PredictiveAnalyzer()

    print("ğŸ”® Makenaide Phase 4 ì˜ˆì¸¡ì  ë¶„ì„ ì‹œìŠ¤í…œ")
    print("=" * 50)

    # 24ì‹œê°„ ì¥ì•  í™•ë¥  ì˜ˆì¸¡
    prediction = analyzer.predict_failure_probability(24)

    print(f"\nğŸ“Š 24ì‹œê°„ ì¥ì•  ì˜ˆì¸¡ ê²°ê³¼:")
    print(f"   ìœ„í—˜ë„: {prediction.risk_level.value}")
    print(f"   í™•ë¥ : {prediction.failure_probability:.1%}")
    print(f"   ì‹ ë¢°ë„: {prediction.confidence.value}")

    if prediction.affected_components:
        print(f"   ì˜í–¥ ì»´í¬ë„ŒíŠ¸: {', '.join(prediction.affected_components)}")

    if prediction.recommended_actions:
        print(f"\nğŸ”§ ê¶Œì¥ ì¡°ì¹˜:")
        for action in prediction.recommended_actions:
            print(f"   - {action}")

    # íŠ¸ë Œë“œ ë¶„ì„
    trends = analyzer.analyze_system_health_trends(14)
    if trends:
        print(f"\nğŸ“ˆ ì‹œìŠ¤í…œ íŠ¸ë Œë“œ ë¶„ì„ (14ì¼):")
        for trend in trends:
            print(f"   {trend.metric_name}: {trend.trend_direction} (ê°•ë„: {trend.trend_strength:.2f})")

    # ì¼ì¼ ë³´ê³ ì„œ ìƒì„±
    report = analyzer.generate_daily_prediction_report()
    print(f"\nğŸ“‹ ì¼ì¼ ì˜ˆì¸¡ ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ")
    print(f"   ìš”ì•½: {report.get('summary', 'N/A')}")

if __name__ == "__main__":
    main()