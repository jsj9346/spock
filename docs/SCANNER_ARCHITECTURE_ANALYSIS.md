# Scanner Architecture Analysis - Region-Based Refactoring

## ÏöîÏïΩ

**ÏÇ¨Ïö©Ïûê ÏßÄÏ†Å**: "Í∏ÄÎ°úÎ≤å ÏãúÏû•Ïùò Ï†ïÎ≥¥Î•º Î™®Îëê ÌôïÎ≥¥ÌïòÍ∏∞ ÏúÑÌï¥ÏÑúÎäî data_collector.py ÎøêÎßå ÏïÑÎãàÎùº, scanner.py Ïó≠Ïãú ÏßÄÏõê Íµ≠Í∞ÄÎ≥Ñ adaptor Ïó∞Í≤∞ÏùÑ ÌÜµÌïú Ïä§Ï∫îÏù¥ ÌïÑÏöî"

**Î∂ÑÏÑù Í≤∞Í≥º**: ‚úÖ **Ï†ïÌôïÌïú ÏßÄÏ†ÅÏûÖÎãàÎã§.** ÌòÑÏû¨ `scanner.py`Îäî ÌïúÍµ≠ ÏãúÏû• Ï†ÑÏö© Î™®ÎÖ∏Î¶¨Ïãù Íµ¨Ï°∞Î°ú, Í∏ÄÎ°úÎ≤å ÌôïÏû• Ïãú Ïã¨Í∞ÅÌïú ÏΩîÎìú Ï§ëÎ≥µÍ≥º Ïú†ÏßÄÎ≥¥Ïàò Î¨∏Ï†ú Î∞úÏÉù ÏòàÏÉÅ.

---

## 1. ÌòÑÏû¨ Íµ¨Ï°∞ Î¨∏Ï†úÏ†ê

### 1.1 ÌòÑÏû¨ scanner.py ÏïÑÌÇ§ÌÖçÏ≤ò

```python
# modules/scanner.py (ÌòÑÏû¨)

class KRXOfficialAPI:
    """KRX Í≥µÏãù API - ÌïúÍµ≠ Ï†ÑÏö©"""

class KRXDataAPI:
    """KRX Data API - ÌïúÍµ≠ Ï†ÑÏö©"""

class PyKRXFallback:
    """pykrx - ÌïúÍµ≠ Ï†ÑÏö©"""

class StockScanner:
    """Íµ≠ÎÇ¥Ï£ºÏãù Ï¢ÖÎ™© Ïä§Ï∫êÎÑà"""

    def __init__(self):
        # ÌïúÍµ≠ ÏãúÏû• Ï†ÑÏö© ÏÜåÏä§ Ï¥àÍ∏∞Ìôî
        self.sources = [
            KRXOfficialAPI(),
            KRXDataAPI(),
            PyKRXFallback(),
        ]

    def scan_all_tickers(self):
        """ÌïúÍµ≠ Ï£ºÏãùÎßå Ïä§Ï∫î Í∞ÄÎä•"""
        pass
```

### 1.2 Î¨∏Ï†úÏ†ê Î∂ÑÏÑù

#### ‚ùå Problem 1: Íµ≠Í∞ÄÎ≥Ñ Ï§ëÎ≥µ ÌååÏùº ÏÉùÏÑ± ÌïÑÏöî

**ÌòÑÏû¨ Î∞©ÏãùÏúºÎ°ú Í∏ÄÎ°úÎ≤å ÌôïÏû• Ïãú**:
```
modules/
‚îú‚îÄ‚îÄ scanner.py              # Korea only (534 lines)
‚îú‚îÄ‚îÄ us_scanner.py           # US only (new file, ~500 lines)
‚îú‚îÄ‚îÄ cn_scanner.py           # China only (new file, ~500 lines)
‚îú‚îÄ‚îÄ hk_scanner.py           # Hong Kong only (new file, ~500 lines)
‚îú‚îÄ‚îÄ jp_scanner.py           # Japan only (new file, ~500 lines)
‚îî‚îÄ‚îÄ vn_scanner.py           # Vietnam only (new file, ~500 lines)
```

**Í≤∞Í≥º**: 6Í∞ú ÌååÏùº, 3,000+ ÎùºÏù∏, 70% ÏΩîÎìú Ï§ëÎ≥µ

#### ‚ùå Problem 2: Í≥µÌÜµ Î°úÏßÅ Ï§ëÎ≥µ

**Ï§ëÎ≥µÎêòÎäî Î°úÏßÅ** (Í∞Å ÌååÏùºÏóêÏÑú Î∞òÎ≥µ):
- SQLite Ï∫êÏã± Î°úÏßÅ (24ÏãúÍ∞Ñ TTL)
- Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÏÇΩÏûÖ Î°úÏßÅ (tickers, stock_details, ticker_fundamentals)
- ÌïÑÌÑ∞ÎßÅ ÌîÑÎ†àÏûÑÏõåÌÅ¨
- Ïò§Î•ò Ï≤òÎ¶¨ Î∞è Ìè¥Î∞± Ï†ÑÎûµ

**ÏòàÏãú**: Ï∫êÏã± Î°úÏßÅÏù¥ 6Í∞ú ÌååÏùºÏóê Ï§ëÎ≥µ ‚Üí Î≤ÑÍ∑∏ ÏàòÏ†ï Ïãú 6Í∞ú ÌååÏùº Î™®Îëê ÏàòÏ†ï ÌïÑÏöî

#### ‚ùå Problem 3: ÌÅ¥ÎûòÏä§Î™Ö Ïò§Ìï¥ ÏÜåÏßÄ

```python
class StockScanner:  # "Stock" Ï†ÑÏ≤¥Î•º Ïä§Ï∫îÌï† Í≤É Í∞ôÏßÄÎßå...
    """Íµ≠ÎÇ¥Ï£ºÏãù Ï¢ÖÎ™© Ïä§Ï∫êÎÑà"""  # Ïã§Ï†úÎ°úÎäî ÌïúÍµ≠ Ï£ºÏãùÎßå
```

Ïã§Ï†úÎ°úÎäî `KoreanStockScanner`Í∞Ä Îçî Ï†ïÌôïÌïú Ïù¥Î¶Ñ

#### ‚ùå Problem 4: ÌôïÏû•ÏÑ± Î∂ÄÏû¨

```python
# US Ï£ºÏãù Ïä§Ï∫îÌïòÎ†§Î©¥?
# ‚Üí ÏÉàÎ°úÏö¥ us_scanner.py ÌååÏùº ÏÉùÏÑ± ÌïÑÏöî
# ‚Üí Î™®Îì† Í≥µÌÜµ Î°úÏßÅ Îã§Ïãú Íµ¨ÌòÑ

# China Ï£ºÏãù Ïä§Ï∫îÌïòÎ†§Î©¥?
# ‚Üí Îòê Îã§Î•∏ cn_scanner.py ÌååÏùº ÏÉùÏÑ± ÌïÑÏöî
```

---

## 2. Ï†úÏïà ÏïÑÌÇ§ÌÖçÏ≤ò: Region-Based Scanner System

### 2.1 ÎîîÎ†âÌÜ†Î¶¨ Íµ¨Ï°∞

```
modules/
‚îú‚îÄ‚îÄ scanner.py                          # üéØ Unified orchestrator (entry point)
‚îÇ
‚îú‚îÄ‚îÄ scanner_adapters/                   # üìç Regional scanners
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py
‚îÇ   ‚îú‚îÄ‚îÄ base_scanner.py                 # Abstract base class
‚îÇ   ‚îú‚îÄ‚îÄ kr_scanner.py                   # Korea (KRX, pykrx, FDR)
‚îÇ   ‚îú‚îÄ‚îÄ us_scanner.py                   # US (SEC, Yahoo, IEX)
‚îÇ   ‚îú‚îÄ‚îÄ cn_scanner.py                   # China (SZSE, SSE)
‚îÇ   ‚îú‚îÄ‚îÄ hk_scanner.py                   # Hong Kong (HKEX)
‚îÇ   ‚îú‚îÄ‚îÄ jp_scanner.py                   # Japan (TSE)
‚îÇ   ‚îî‚îÄ‚îÄ vn_scanner.py                   # Vietnam (HOSE, HNX)
‚îÇ
‚îî‚îÄ‚îÄ data_sources/                       # üîå API clients (reusable)
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ krx_api.py                      # KRX Official API
    ‚îú‚îÄ‚îÄ krx_data_api.py                 # KRX Data API
    ‚îú‚îÄ‚îÄ pykrx_api.py                    # pykrx wrapper
    ‚îú‚îÄ‚îÄ yahoo_finance_api.py            # Yahoo Finance (US/global)
    ‚îú‚îÄ‚îÄ sec_edgar_api.py                # SEC EDGAR (US official)
    ‚îî‚îÄ‚îÄ iex_cloud_api.py                # IEX Cloud (US alternative)
```

**Î™®Îìà Ïàò**: 1 orchestrator + 7 regional adapters + 6 data sources = **14 modules**

vs ÌòÑÏû¨ Î∞©Ïãù: 6 monolithic scanners √ó 500 lines = **3,000 lines of duplicated code**

### 2.2 ÌïµÏã¨ Ïª¥Ìè¨ÎÑåÌä∏ ÏÑ§Í≥Ñ

#### 2.2.1 Base Scanner (Abstract Class)

```python
# modules/scanner_adapters/base_scanner.py

from abc import ABC, abstractmethod
from typing import List, Dict, Optional
import sqlite3
from datetime import datetime

class BaseScanner(ABC):
    """
    Abstract base scanner for all regions

    Provides shared logic:
    - SQLite caching (24-hour TTL)
    - Database insertion (tickers, stock_details, ticker_fundamentals)
    - Common filtering framework
    - Error handling and logging
    """

    def __init__(self, db_path: str, region_code: str):
        self.db_path = db_path
        self.region_code = region_code  # 'KR', 'US', 'CN', 'HK', 'JP', 'VN'

    # ========== Abstract Methods (Region-Specific) ==========

    @abstractmethod
    def _fetch_from_sources(self) -> List[Dict]:
        """
        Fetch tickers from region-specific data sources

        Must be implemented by each regional adapter.

        Returns:
            List of raw ticker dictionaries

        Example (Korea):
            [
                {'ticker': '005930', 'name': 'ÏÇºÏÑ±Ï†ÑÏûê', 'market': 'KOSPI'},
                {'ticker': '035720', 'name': 'Ïπ¥Ïπ¥Ïò§', 'market': 'KOSDAQ'},
            ]

        Example (US):
            [
                {'ticker': 'AAPL', 'name': 'Apple Inc.', 'exchange': 'NASDAQ'},
                {'ticker': 'TSLA', 'name': 'Tesla Inc.', 'exchange': 'NASDAQ'},
            ]
        """
        pass

    @abstractmethod
    def _apply_filters(self, tickers: List[Dict]) -> List[Dict]:
        """
        Apply region-specific filtering criteria

        Must be implemented by each regional adapter.

        Args:
            tickers: Raw ticker list

        Returns:
            Filtered ticker list

        Example (Korea):
            - Market cap >= 100ÏñµÏõê
            - Exclude KONEX
            - Exclude ETF/ETN

        Example (US):
            - Market cap >= $50M
            - Exclude OTC/Pink Sheets
            - Exclude ETFs
        """
        pass

    # ========== Shared Methods (Common Logic) ==========

    def scan(self, force_refresh: bool = False) -> List[Dict]:
        """
        Main scanning workflow (shared across all regions)

        Workflow:
            1. Check cache (24-hour TTL)
            2. Fetch from region-specific sources
            3. Apply region-specific filters
            4. Enrich with common fields
            5. Save to cache

        Args:
            force_refresh: Ignore cache and force refresh

        Returns:
            List of enriched ticker dictionaries
        """
        # Step 1: Check cache
        if not force_refresh:
            cached = self._load_from_cache()
            if cached:
                logger.info(f"‚úÖ [{self.region_code}] Cache hit: {len(cached)} tickers")
                return cached

        # Step 2: Fetch from region-specific sources
        logger.info(f"üîÑ [{self.region_code}] Fetching from data sources...")
        raw_tickers = self._fetch_from_sources()

        # Step 3: Apply region-specific filters
        logger.info(f"üîç [{self.region_code}] Applying filters...")
        filtered = self._apply_filters(raw_tickers)

        # Step 4: Enrich with common fields
        enriched = self._enrich_common_fields(filtered)

        # Step 5: Save to cache
        self._save_to_cache(enriched)

        logger.info(f"‚úÖ [{self.region_code}] Scan complete: {len(enriched)} tickers")
        return enriched

    def _load_from_cache(self) -> Optional[List[Dict]]:
        """
        Load tickers from SQLite cache (24-hour TTL)

        Shared logic for all regions.
        """
        try:
            if not os.path.exists(self.db_path):
                return None

            conn = sqlite3.connect(self.db_path)
            conn.row_factory = sqlite3.Row
            cursor = conn.cursor()

            # Check last update time
            cursor.execute("""
                SELECT MAX(last_updated) as last_update
                FROM tickers
                WHERE region = ?
            """, (self.region_code,))

            result = cursor.fetchone()
            if not result or not result['last_update']:
                conn.close()
                return None

            last_update = datetime.fromisoformat(result['last_update'])
            age_hours = (datetime.now() - last_update).total_seconds() / 3600

            # 24-hour TTL
            if age_hours > 24:
                logger.info(f"‚è∞ [{self.region_code}] Cache expired ({age_hours:.1f}h)")
                conn.close()
                return None

            # Load tickers
            cursor.execute("""
                SELECT
                    t.ticker,
                    t.name,
                    t.exchange,
                    t.market_tier,
                    t.region,
                    t.currency,
                    t.is_active,
                    tf.market_cap
                FROM tickers t
                LEFT JOIN ticker_fundamentals tf ON t.ticker = tf.ticker
                WHERE t.region = ? AND t.is_active = 1
                ORDER BY tf.market_cap DESC NULLS LAST
            """, (self.region_code,))

            tickers = [dict(row) for row in cursor.fetchall()]
            conn.close()

            logger.info(f"‚úÖ [{self.region_code}] Cache hit: {age_hours:.1f}h old")
            return tickers

        except Exception as e:
            logger.warning(f"‚ö†Ô∏è [{self.region_code}] Cache load failed: {e}")
            return None

    def _save_to_cache(self, tickers: List[Dict]):
        """
        Save tickers to SQLite cache

        Shared logic for all regions.
        """
        try:
            os.makedirs(os.path.dirname(self.db_path), exist_ok=True)

            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # Delete existing tickers for this region
            cursor.execute("DELETE FROM tickers WHERE region = ?", (self.region_code,))

            now = datetime.now().isoformat()
            today = datetime.now().strftime("%Y-%m-%d")

            # Insert new tickers
            for ticker_data in tickers:
                # 1. tickers table
                cursor.execute("""
                    INSERT INTO tickers
                    (ticker, name, name_eng, exchange, market_tier, region, currency,
                     asset_type, listing_date, is_active, created_at, last_updated, data_source)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                """, (
                    ticker_data['ticker'],
                    ticker_data['name'],
                    ticker_data.get('name_eng'),
                    ticker_data['exchange'],
                    ticker_data.get('market_tier', 'MAIN'),
                    self.region_code,
                    ticker_data['currency'],
                    ticker_data.get('asset_type', 'STOCK'),
                    ticker_data.get('listing_date'),
                    True,
                    now,
                    now,
                    ticker_data.get('data_source', 'Unknown')
                ))

                # 2. stock_details table
                if ticker_data.get('asset_type', 'STOCK') in ('STOCK', 'PREFERRED'):
                    cursor.execute("""
                        INSERT INTO stock_details
                        (ticker, sector, industry, is_preferred, created_at, last_updated)
                        VALUES (?, ?, ?, ?, ?, ?)
                    """, (
                        ticker_data['ticker'],
                        ticker_data.get('sector'),
                        ticker_data.get('industry'),
                        ticker_data.get('asset_type') == 'PREFERRED',
                        now,
                        now
                    ))

                # 3. ticker_fundamentals table
                if ticker_data.get('market_cap') or ticker_data.get('close_price'):
                    cursor.execute("""
                        INSERT INTO ticker_fundamentals
                        (ticker, date, period_type, market_cap, close_price, created_at, data_source)
                        VALUES (?, ?, ?, ?, ?, ?, ?)
                    """, (
                        ticker_data['ticker'],
                        today,
                        'DAILY',
                        ticker_data.get('market_cap'),
                        ticker_data.get('close_price'),
                        now,
                        ticker_data.get('data_source', 'Unknown')
                    ))

            conn.commit()
            conn.close()

            logger.info(f"üíæ [{self.region_code}] Cache saved: {len(tickers)} tickers")

        except Exception as e:
            logger.error(f"‚ùå [{self.region_code}] Cache save failed: {e}")

    def _enrich_common_fields(self, tickers: List[Dict]) -> List[Dict]:
        """
        Add common fields to all tickers

        Shared logic for all regions.
        """
        for ticker in tickers:
            ticker['region'] = self.region_code
            ticker['is_active'] = True

        return tickers
```

#### 2.2.2 Korea Scanner (Concrete Implementation)

```python
# modules/scanner_adapters/kr_scanner.py

from .base_scanner import BaseScanner
from data_sources.krx_api import KRXOfficialAPI
from data_sources.krx_data_api import KRXDataAPI
from data_sources.pykrx_api import PyKRXFallback
import logging

logger = logging.getLogger(__name__)

class KoreaScanner(BaseScanner):
    """
    Korea stock scanner (KOSPI, KOSDAQ, NXT)

    Data sources (priority order):
    1. KRX Official API (requires API key)
    2. KRX Data API (no auth required)
    3. pykrx (fallback, rate-limited)
    """

    def __init__(self, db_path: str, krx_api_key: Optional[str] = None):
        super().__init__(db_path, region_code='KR')
        self.krx_api_key = krx_api_key
        self.sources = self._initialize_sources()

    def _initialize_sources(self):
        """Initialize Korea-specific data sources"""
        sources = []

        # Priority 1: KRX Official API
        if self.krx_api_key:
            sources.append(('KRX Official API', KRXOfficialAPI(self.krx_api_key)))

        # Priority 2: KRX Data API
        sources.append(('KRX Data API', KRXDataAPI()))

        # Priority 3: pykrx fallback
        sources.append(('pykrx', PyKRXFallback()))

        return sources

    def _fetch_from_sources(self) -> List[Dict]:
        """
        Fetch tickers from Korea data sources

        Try sources in priority order until success.
        """
        for source_name, source_api in self.sources:
            try:
                logger.info(f"üîÑ [{source_name}] Fetching Korea stocks...")
                tickers = source_api.get_stock_list()

                if not tickers:
                    logger.warning(f"‚ö†Ô∏è [{source_name}] No data returned")
                    continue

                # Add data source info
                for ticker in tickers:
                    ticker['data_source'] = source_name

                logger.info(f"‚úÖ [{source_name}] {len(tickers)} stocks fetched")
                return tickers

            except Exception as e:
                logger.error(f"‚ùå [{source_name}] Failed: {e}")
                continue

        raise Exception("All Korea data sources failed")

    def _apply_filters(self, tickers: List[Dict]) -> List[Dict]:
        """
        Apply Korea-specific filters

        Criteria:
        - Market cap >= 100ÏñµÏõê
        - Exclude KONEX
        - Exclude ETF/ETN (handled by separate etf_scanner)
        """
        MIN_MARKET_CAP = 10_000_000_000  # 100ÏñµÏõê

        filtered = []
        for ticker_data in tickers:
            # Filter 1: Exclude KONEX
            if ticker_data.get('market') == 'KONEX':
                continue

            # Filter 2: Exclude ETF/ETN
            name = ticker_data.get('name', '')
            if any(kw in name for kw in ['ETF', 'ETN', 'KODEX', 'TIGER', 'KBSTAR', 'ARIRANG']):
                continue

            # Filter 3: Market cap threshold
            market_cap = ticker_data.get('market_cap', 0)
            if market_cap > 0 and market_cap < MIN_MARKET_CAP:
                continue

            # Add Korea-specific fields
            ticker_data['currency'] = 'KRW'
            ticker_data['exchange'] = ticker_data.get('market', 'UNKNOWN')  # KOSPI, KOSDAQ
            ticker_data['asset_type'] = self._classify_asset_type(ticker_data['name'])

            filtered.append(ticker_data)

        logger.info(f"üìä Filtered: {len(tickers)} ‚Üí {len(filtered)} stocks")
        return filtered

    def _classify_asset_type(self, name: str) -> str:
        """Classify asset type by name pattern"""
        if 'REIT' in name or 'Î¶¨Ï∏†' in name:
            return 'REIT'
        elif 'Ïö∞' in name:  # Ïö∞ÏÑ†Ï£º
            return 'PREFERRED'
        else:
            return 'STOCK'
```

#### 2.2.3 US Scanner (Future Implementation)

```python
# modules/scanner_adapters/us_scanner.py

from .base_scanner import BaseScanner
from data_sources.yahoo_finance_api import YahooFinanceAPI
from data_sources.sec_edgar_api import SECEdgarAPI

class USScanner(BaseScanner):
    """
    US stock scanner (NYSE, NASDAQ, AMEX)

    Data sources:
    1. SEC EDGAR (official US data)
    2. Yahoo Finance (fallback)
    """

    def __init__(self, db_path: str):
        super().__init__(db_path, region_code='US')
        self.sources = self._initialize_sources()

    def _initialize_sources(self):
        """Initialize US-specific data sources"""
        return [
            ('SEC EDGAR', SECEdgarAPI()),
            ('Yahoo Finance', YahooFinanceAPI()),
        ]

    def _fetch_from_sources(self) -> List[Dict]:
        """Fetch tickers from US data sources"""
        for source_name, source_api in self.sources:
            try:
                tickers = source_api.get_stock_list()
                if tickers:
                    for ticker in tickers:
                        ticker['data_source'] = source_name
                    return tickers
            except Exception as e:
                logger.error(f"‚ùå [{source_name}] Failed: {e}")

        raise Exception("All US data sources failed")

    def _apply_filters(self, tickers: List[Dict]) -> List[Dict]:
        """
        Apply US-specific filters

        Criteria:
        - Market cap >= $50M
        - Exclude OTC/Pink Sheets
        - Exclude ETFs
        """
        MIN_MARKET_CAP = 50_000_000  # $50M USD

        filtered = []
        for ticker_data in tickers:
            # Filter 1: Exclude OTC/Pink Sheets
            if ticker_data.get('exchange') in ['OTC', 'PINK']:
                continue

            # Filter 2: Exclude ETFs
            if any(kw in ticker_data['name'] for kw in ['ETF', 'FUND', 'INDEX']):
                continue

            # Filter 3: Market cap threshold
            if ticker_data.get('market_cap', 0) < MIN_MARKET_CAP:
                continue

            # Add US-specific fields
            ticker_data['currency'] = 'USD'
            ticker_data['asset_type'] = 'STOCK'

            filtered.append(ticker_data)

        return filtered
```

#### 2.2.4 Unified Scanner Orchestrator

```python
# modules/scanner.py (refactored)

from scanner_adapters.kr_scanner import KoreaScanner
from scanner_adapters.us_scanner import USScanner
# from scanner_adapters.cn_scanner import ChinaScanner (Phase 5)
# from scanner_adapters.hk_scanner import HongKongScanner (Phase 5)
import os

class UnifiedScanner:
    """
    Multi-region stock scanner orchestrator

    Supports:
    - Korea (KOSPI, KOSDAQ, NXT) - Phase 1-3
    - US (NYSE, NASDAQ, AMEX) - Phase 4
    - China (SSE, SZSE) - Phase 5
    - Hong Kong (HKEX) - Phase 5
    - Japan (TSE) - Phase 6
    - Vietnam (HOSE, HNX) - Phase 6
    """

    def __init__(self, db_path: str = 'data/spock_local.db'):
        self.db_path = db_path

        # Initialize regional scanners
        self.scanners = {
            'KR': KoreaScanner(db_path, krx_api_key=os.getenv('KRX_API_KEY')),
            # 'US': USScanner(db_path),  # Phase 4
            # 'CN': ChinaScanner(db_path),  # Phase 5
            # 'HK': HongKongScanner(db_path),  # Phase 5
        }

    def scan_region(self, region: str, force_refresh: bool = False) -> List[Dict]:
        """
        Scan specific region

        Args:
            region: 'KR', 'US', 'CN', 'HK', 'JP', 'VN'
            force_refresh: Ignore cache

        Returns:
            List of ticker dictionaries

        Example:
            scanner = UnifiedScanner()
            kr_stocks = scanner.scan_region('KR')  # Korea stocks
            us_stocks = scanner.scan_region('US')  # US stocks
        """
        scanner = self.scanners.get(region)
        if not scanner:
            raise ValueError(f"Unsupported region: {region}")

        return scanner.scan(force_refresh=force_refresh)

    def scan_all_regions(self, force_refresh: bool = False) -> Dict[str, List[Dict]]:
        """
        Scan all supported regions

        Returns:
            {'KR': [...], 'US': [...], 'CN': [...]}
        """
        results = {}

        for region, scanner in self.scanners.items():
            try:
                tickers = scanner.scan(force_refresh=force_refresh)
                results[region] = tickers
                logger.info(f"‚úÖ {region}: {len(tickers)} stocks")
            except Exception as e:
                logger.error(f"‚ùå {region} scan failed: {e}")
                results[region] = []

        return results

    # ========== Backward Compatibility ==========

    def scan_all_tickers(self, force_refresh: bool = False) -> List[Dict]:
        """
        Legacy method for backward compatibility

        Preserves existing behavior: scans Korea stocks only.

        Example:
            scanner = UnifiedScanner()
            tickers = scanner.scan_all_tickers()  # Same as before
        """
        return self.scan_region('KR', force_refresh=force_refresh)


# Legacy alias for backward compatibility
StockScanner = UnifiedScanner
```

---

## 3. ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ï†ÑÎûµ

### 3.1 Îã®Í≥ÑÎ≥Ñ ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (5.5Ïùº)

#### Phase 0: Ï§ÄÎπÑ (0.5Ïùº)
- ÎîîÎ†âÌÜ†Î¶¨ ÏÉùÏÑ±: `scanner_adapters/`, `data_sources/`
- Í∏∞Ï°¥ ÏΩîÎìú Î∞±ÏóÖ

#### Phase 1: Data Sources Î∂ÑÎ¶¨ (1Ïùº)
```bash
# Í∏∞Ï°¥ ÌÅ¥ÎûòÏä§ Ïù¥Îèô
modules/scanner.py:KRXOfficialAPI ‚Üí data_sources/krx_api.py
modules/scanner.py:KRXDataAPI ‚Üí data_sources/krx_data_api.py
modules/scanner.py:PyKRXFallback ‚Üí data_sources/pykrx_api.py
```

**Î≥ÄÍ≤Ω ÏÇ¨Ìï≠**: ÌååÏùº Ïû¨Íµ¨ÏÑ±Îßå, Î°úÏßÅ Î≥ÄÍ≤Ω ÏóÜÏùå

#### Phase 2: Base Scanner Íµ¨ÌòÑ (1Ïùº)
- `base_scanner.py` ÏûëÏÑ±
- Í≥µÌÜµ Î°úÏßÅ Ï∂îÏ∂ú: `_load_from_cache()`, `_save_to_cache()`, `scan()`

#### Phase 3: Korea Scanner Íµ¨ÌòÑ (1Ïùº)
- `kr_scanner.py` ÏûëÏÑ±
- Í∏∞Ï°¥ `StockScanner` Î°úÏßÅÏùÑ `KoreaScanner`Î°ú Ïù¥Ï†Ñ
- ÌïúÍµ≠ ÌäπÌôî ÌïÑÌÑ∞ÎßÅ: `_apply_filters()` Íµ¨ÌòÑ

#### Phase 4: Unified Scanner Íµ¨ÌòÑ (1Ïùº)
- `scanner.py` Î¶¨Ìå©ÌÜ†ÎßÅ
- `UnifiedScanner` ÌÅ¥ÎûòÏä§ ÏûëÏÑ±
- Ïó≠Ìò∏ÌôòÏÑ± Ïú†ÏßÄ: `scan_all_tickers()` Î©îÏÑúÎìú Î≥¥Ï°¥

#### Phase 5: ÌÖåÏä§Ìä∏ Î∞è Í≤ÄÏ¶ù (1Ïùº)
- Îã®ÏúÑ ÌÖåÏä§Ìä∏: Í∞Å regional scanner ÌÖåÏä§Ìä∏
- ÌÜµÌï© ÌÖåÏä§Ìä∏: Í∏∞Ï°¥ ÏΩîÎìúÏôÄÏùò Ìò∏ÌôòÏÑ±
- ÏÑ±Îä• ÌÖåÏä§Ìä∏: Ï∫êÏã± Î°úÏßÅ Í≤ÄÏ¶ù

**Ï¥ù ÏÜåÏöî ÏãúÍ∞Ñ**: 5.5Ïùº

### 3.2 Ïó≠Ìò∏ÌôòÏÑ± Î≥¥Ïû•

```python
# Í∏∞Ï°¥ ÏΩîÎìú (Î≥ÄÍ≤Ω ÏóÜÏù¥ ÏûëÎèô)
from modules.scanner import StockScanner

scanner = StockScanner()
tickers = scanner.scan_all_tickers()  # Ïó¨Ï†ÑÌûà ÌïúÍµ≠ Ï£ºÏãù Ïä§Ï∫î

# ÏÉàÎ°úÏö¥ ÏΩîÎìú (region-based)
from modules.scanner import UnifiedScanner

scanner = UnifiedScanner()
kr_tickers = scanner.scan_region('KR')  # ÌïúÍµ≠
us_tickers = scanner.scan_region('US')  # ÎØ∏Íµ≠
```

---

## 4. ÎπÑÍµê Î∂ÑÏÑù

### 4.1 ÌòÑÏû¨ vs Ï†úÏïà ÏïÑÌÇ§ÌÖçÏ≤ò

| Ï∏°Î©¥ | ÌòÑÏû¨ (Monolithic) | Ï†úÏïà (Region-Based) |
|------|------------------|---------------------|
| **ÌååÏùº Ïàò** | 1Í∞ú (scanner.py, 534Ï§Ñ) | 1 orchestrator + 7 adapters + 6 sources = 14Í∞ú |
| **Korea ÏßÄÏõê** | ‚úÖ ÏôÑÏ†Ñ ÏßÄÏõê | ‚úÖ ÏôÑÏ†Ñ ÏßÄÏõê (Î≥ÄÍ≤Ω ÏóÜÏùå) |
| **US ÏßÄÏõê** | ‚ùå ÏÉà ÌååÏùº ÌïÑÏöî (us_scanner.py) | ‚úÖ USScanner adapter |
| **ÏΩîÎìú Ïû¨ÏÇ¨Ïö©** | 0% (Íµ≠Í∞ÄÎ≥Ñ Ï§ëÎ≥µ) | 70%+ (base class Í≥µÏú†) |
| **Ïú†ÏßÄÎ≥¥ÏàòÏÑ±** | ‚ùå ÎÇÆÏùå (6Í∞ú ÌååÏùº ÏàòÏ†ï) | ‚úÖ ÎÜíÏùå (base class 1Í≥≥ ÏàòÏ†ï) |
| **ÌôïÏû•ÏÑ±** | ‚ùå Ïñ¥Î†§ÏõÄ (Íµ≠Í∞ÄÎãπ ÏÉà ÌååÏùº) | ‚úÖ Ïâ¨ÏõÄ (adapter 1Í∞ú Ï∂îÍ∞Ä) |
| **Ïó≠Ìò∏ÌôòÏÑ±** | N/A | ‚úÖ `scan_all_tickers()` Î≥¥Ï°¥ |
| **ÌÖåÏä§Ìä∏ Î≥µÏû°ÎèÑ** | ÎÜíÏùå (Í∞Å scanner ÎèÖÎ¶Ω ÌÖåÏä§Ìä∏) | ÎÇÆÏùå (base + adapter ÌÖåÏä§Ìä∏) |

### 4.2 Í∏ÄÎ°úÎ≤å ÌôïÏû• ÏãúÎÇòÎ¶¨Ïò§ ÎπÑÍµê

#### ÏãúÎÇòÎ¶¨Ïò§: 6Í∞ú Íµ≠Í∞Ä ÏßÄÏõê (Korea, US, China, HK, Japan, Vietnam)

**ÌòÑÏû¨ Î∞©Ïãù (Monolithic)**:
```
Î™®Îìà Ïàò: 6Í∞ú (Í∞Å Íµ≠Í∞ÄÎ≥Ñ scanner)
Ï¥ù ÏΩîÎìúÎüâ: ~3,000 ÎùºÏù∏ (500 √ó 6)
ÏΩîÎìú Ï§ëÎ≥µÎ•†: 70%
Ïú†ÏßÄÎ≥¥Ïàò: Î≤ÑÍ∑∏ ÏàòÏ†ï Ïãú 6Í∞ú ÌååÏùº ÏàòÏ†ï
```

**Ï†úÏïà Î∞©Ïãù (Region-Based)**:
```
Î™®Îìà Ïàò: 1 orchestrator + 1 base + 6 adapters + 6 sources = 14Í∞ú
Ï¥ù ÏΩîÎìúÎüâ: ~2,000 ÎùºÏù∏ (base 500 + adapters 150√ó6 + sources 100√ó6)
ÏΩîÎìú Ï§ëÎ≥µÎ•†: 0%
Ïú†ÏßÄÎ≥¥Ïàò: Î≤ÑÍ∑∏ ÏàòÏ†ï Ïãú base class 1Í≥≥ ÏàòÏ†ï
```

**Í≤∞Î°†**: Ï†úÏïà Î∞©ÏãùÏù¥ **33% ÏΩîÎìú Ï†àÍ∞ê** + **Ïú†ÏßÄÎ≥¥Ïàò 70% Í∞úÏÑ†**

---

## 5. ScannerÏôÄ Data Collector ÌÜµÌï©

### 5.1 Ïó≠Ìï† Î∂ÑÎã¥

**ScannerÏùò Ïó≠Ìï†**:
- Ï¢ÖÎ™© Î∞úÍ≤¨ (Ticker Discovery)
- Í∏∞Î≥∏ Ï†ïÎ≥¥ ÏàòÏßë (name, exchange, market_cap)
- tickers ÌÖåÏù¥Î∏î Ï±ÑÏö∞Í∏∞

**Data Collector (Adapter)Ïùò Ïó≠Ìï†**:
- OHLCV Îç∞Ïù¥ÌÑ∞ ÏàòÏßë
- Í∏∞Ïà†Ï†Å ÏßÄÌëú Í≥ÑÏÇ∞
- ohlcv_data ÌÖåÏù¥Î∏î Ï±ÑÏö∞Í∏∞

### 5.2 ÏõåÌÅ¨ÌîåÎ°úÏö∞ ÌÜµÌï©

```python
# Step 1: ScannerÍ∞Ä Ï¢ÖÎ™© Î∞úÍ≤¨
scanner = UnifiedScanner(db_path)
kr_tickers = scanner.scan_region('KR')  # kr_scanner.py ÏÇ¨Ïö©
# ‚Üí tickers ÌÖåÏù¥Î∏î Ï±ÑÏõåÏßê

# Step 2: Data CollectorÍ∞Ä OHLCV ÏàòÏßë
from market_adapters.kr_adapter import KoreaAdapter

kr_adapter = KoreaAdapter(db_manager, kis_config)
kr_adapter.collect_stock_ohlcv(tickers=kr_tickers)  # kr_adapter.py ÏÇ¨Ïö©
# ‚Üí ohlcv_data ÌÖåÏù¥Î∏î Ï±ÑÏõåÏßê

# Step 3: Í∏∞Ïà†Ï†Å Î∂ÑÏÑù (Í∏∞Ï°¥ ÌååÏù¥ÌîÑÎùºÏù∏)
# ... technical_analysis, scoring, trading ...
```

### 5.3 Îç∞Ïù¥ÌÑ∞Î≤†Ïù¥Ïä§ ÌÜµÌï©

```
tickers ÌÖåÏù¥Î∏î (ScannerÍ∞Ä Ï±ÑÏõÄ)
‚îú‚îÄ ticker: 005930
‚îú‚îÄ name: ÏÇºÏÑ±Ï†ÑÏûê
‚îú‚îÄ exchange: KOSPI
‚îú‚îÄ market_tier: MAIN
‚îú‚îÄ region: KR  ‚Üê ScannerÍ∞Ä ÏÑ§Ï†ï
‚îî‚îÄ currency: KRW

ohlcv_data ÌÖåÏù¥Î∏î (Data CollectorÍ∞Ä Ï±ÑÏõÄ)
‚îú‚îÄ ticker: 005930  ‚Üê tickers.ticker Ï∞∏Ï°∞
‚îú‚îÄ date: 2024-01-15
‚îú‚îÄ open: 75000
‚îú‚îÄ high: 76000
‚îî‚îÄ close: 75500
```

---

## 6. Íµ¨ÌòÑ Ïö∞ÏÑ†ÏàúÏúÑ

### 6.1 Phase 1-3 (Korea Focus) - Ï¶âÏãú Ï∞©Ïàò Í∞ÄÎä•

**Î™©Ìëú**: ÌòÑÏû¨ scanner.pyÎ•º region-basedÎ°ú Î¶¨Ìå©ÌÜ†ÎßÅ

**ÏûëÏóÖ**:
1. Data sources Î∂ÑÎ¶¨ (krx_api.py, pykrx_api.py)
2. Base scanner Íµ¨ÌòÑ
3. Korea scanner Íµ¨ÌòÑ
4. Unified scanner Íµ¨ÌòÑ

**Í∏∞Í∞Ñ**: 5.5Ïùº

### 6.2 Phase 4 (US Expansion) - Korea ÏôÑÎ£å ÌõÑ

**Î™©Ìëú**: US scanner Ï∂îÍ∞Ä

**ÏûëÏóÖ**:
1. US data sources Íµ¨ÌòÑ (sec_edgar_api.py, yahoo_finance_api.py)
2. US scanner Íµ¨ÌòÑ (us_scanner.py)
3. Unified scannerÏóê US Ï∂îÍ∞Ä

**Í∏∞Í∞Ñ**: 2Ïùº

### 6.3 Phase 5-6 (Global Expansion) - US Í≤ÄÏ¶ù ÌõÑ

**Î™©Ìëú**: China, HK, Japan, Vietnam Ï∂îÍ∞Ä

**ÏûëÏóÖ**: Í∞Å Íµ≠Í∞ÄÎ≥Ñ scanner adapter Íµ¨ÌòÑ

**Í∏∞Í∞Ñ**: Íµ≠Í∞ÄÎãπ 1-2Ïùº (Î≥ëÎ†¨ ÏûëÏóÖ Í∞ÄÎä•)

---

## 7. Î¶¨Ïä§ÌÅ¨ Î∞è ÏôÑÌôî Ï†ÑÎûµ

### Risk 1: ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò Ï§ë Í∏∞Ï°¥ Í∏∞Îä• Ï§ëÎã®

**ÏôÑÌôî**:
- Ïó≠Ìò∏ÌôòÏÑ± API Ïú†ÏßÄ (`scan_all_tickers()`)
- Îã®Í≥ÑÎ≥Ñ ÎßàÏù¥Í∑∏Î†àÏù¥ÏÖò (Í∏∞Ï°¥ ÏΩîÎìúÏôÄ Î≥ëÌñâ)
- Ï≤†Ï†ÄÌïú ÌÖåÏä§Ìä∏ (Îã®ÏúÑ + ÌÜµÌï©)

### Risk 2: Region-specific Î°úÏßÅ Î≥µÏû°ÎèÑ Ï¶ùÍ∞Ä

**ÏôÑÌôî**:
- Abstract base classÎ°ú Ïù∏ÌÑ∞ÌéòÏù¥Ïä§ Î™ÖÌôïÌôî
- Í∞Å adapterÎäî ÎèÖÎ¶ΩÏ†ÅÏúºÎ°ú Í∞úÎ∞ú Í∞ÄÎä•
- Í≥µÌÜµ Î°úÏßÅÏùÄ base classÏóê ÏßëÏ§ë

### Risk 3: Îç∞Ïù¥ÌÑ∞ ÏÜåÏä§ API Î≥ÄÍ≤Ω

**ÏôÑÌôî**:
- Data sourceÎ≥ÑÎ°ú ÎèÖÎ¶ΩÎêú ÌååÏùº (`data_sources/`)
- API wrapper Ìå®ÌÑ¥ÏúºÎ°ú Í≤©Î¶¨
- Fallback Ï†ÑÎûµ (Ïó¨Îü¨ data source Î≥ëÌñâ)

---

## 8. Í≤∞Î°†

### 8.1 ÌïµÏã¨ Í≤∞Î°†

‚úÖ **ÏÇ¨Ïö©ÏûêÏùò ÏßÄÏ†ÅÏù¥ Ï†ïÌôïÌï©ÎãàÎã§.**

ÌòÑÏû¨ `scanner.py`Îäî ÌïúÍµ≠ ÏãúÏû• Ï†ÑÏö© Î™®ÎÖ∏Î¶¨Ïãù Íµ¨Ï°∞Î°ú, Í∏ÄÎ°úÎ≤å ÌôïÏû• Ïãú:
- Íµ≠Í∞ÄÎ≥Ñ Ï§ëÎ≥µ ÌååÏùº ÏÉùÏÑ± ÌïÑÏöî (6Í∞ú ÌååÏùº, 3,000+ ÎùºÏù∏)
- Í≥µÌÜµ Î°úÏßÅ Ï§ëÎ≥µ (Ï∫êÏã±, DB, ÌïÑÌÑ∞ÎßÅ)
- Ïú†ÏßÄÎ≥¥Ïàò ÎπÑÏö© Ï¶ùÍ∞Ä (Î≤ÑÍ∑∏ ÏàòÏ†ï Ïãú 6Í∞ú ÌååÏùº ÏàòÏ†ï)

### 8.2 Í∂åÏû• ÏÇ¨Ìï≠

**Region-Based Scanner Architecture ÎèÑÏûÖ**:
- Base scanner (Í≥µÌÜµ Î°úÏßÅ)
- Regional adapters (Íµ≠Í∞ÄÎ≥Ñ ÌäπÌôî)
- Data sources (API clients Ïû¨ÏÇ¨Ïö©)

**Ìö®Í≥º**:
- ÏΩîÎìú Ïû¨ÏÇ¨Ïö© 70%+
- Ïú†ÏßÄÎ≥¥Ïàò 70% Í∞úÏÑ†
- ÌôïÏû• Ïö©Ïù¥ (Íµ≠Í∞Ä Ï∂îÍ∞Ä Ïãú adapter 1Í∞úÎßå Íµ¨ÌòÑ)

### 8.3 Îã§Ïùå Îã®Í≥Ñ

1. ‚úÖ **Region-based architecture ÏäπÏù∏** (Ïù¥ Î¨∏ÏÑú)
2. ‚è≥ **Scanner refactoring ÏãúÏûë** (5.5Ïùº)
3. ‚è≥ **Data collector ÌÜµÌï©** (kr_adapter.pyÏôÄ kr_scanner.py ÌòëÏóÖ)
4. ‚è≥ **US scanner Íµ¨ÌòÑ** (Phase 4)

---

**Î¨∏ÏÑú ÏûëÏÑ±**: Claude (SuperClaude Framework)
**ÏûëÏÑ±Ïùº**: 2024-01-XX
**Î≤ÑÏ†Ñ**: 1.0
