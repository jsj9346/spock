# í•´ì™¸ ë§ˆì¼“ OHLCV í•„í„°ë§ ì‹œìŠ¤í…œ - ì „ì²´ êµ¬í˜„ ê³„íš

**Document Version**: 1.0
**Date**: 2025-10-16
**Author**: Spock Trading System
**Status**: Implementation Planning Phase

---

## 1. Executive Summary

### 1.1 ëª©í‘œ

**í˜„ìž¬ ìƒíƒœ**: KR ë§ˆì¼“ë§Œ í•„í„°ë§ ì ìš© (24ì‹œê°„ ê±°ëž˜ëŒ€ê¸ˆ + 13ê°œì›” ì›”ë´‰)
**ëª©í‘œ ìƒíƒœ**: 5ê°œ í•´ì™¸ ë§ˆì¼“ì— ë™ì¼í•œ í•„í„°ë§ ì¡°ê±´ ì ìš©

**í•µì‹¬ ì „ëžµ**:
- âœ… **í†µí™” ì •ê·œí™”**: ëª¨ë“  ë§ˆì¼“ ê¸°ì¤€ì„ KRWë¡œ í†µì¼
- âœ… **ì„¤ì • íŒŒì¼ ë¶„ë¦¬**: ë§ˆì¼“ë³„ YAML ì„¤ì •ìœ¼ë¡œ ìœ ì—°ì„± í™•ë³´
- âœ… **ë‹¨ê³„ë³„ ê²€ì¦**: KR â†’ US â†’ HK/CN â†’ JP/VN ìˆœì°¨ í™•ìž¥

### 1.2 ì˜ˆìƒ íš¨ê³¼

| ì§€í‘œ | í˜„ìž¬ (KR Only) | ì™„ë£Œ í›„ (6 Markets) | ê°œì„ ìœ¨ |
|------|----------------|---------------------|--------|
| ìˆ˜ì§‘ ì¢…ëª© ìˆ˜ | ~250 | ~1,440 | **+476%** |
| ì €ìž¥ ê³µê°„ | ~60MB | ~360MB | **+500%** |
| ìˆ˜ì§‘ ì‹œê°„ | ~25ë¶„ | ~2.5ì‹œê°„ | **+500%** |
| ê¸€ë¡œë²Œ ì»¤ë²„ë¦¬ì§€ | 1ê°œêµ­ | 6ê°œêµ­ | **+500%** |

**ROI ë¶„ì„**:
- íˆ¬ìž: 80ì‹œê°„ (2ì£¼ ê°œë°œ)
- íš¨ê³¼: ê¸€ë¡œë²Œ ì¢…ëª© ë°œêµ´ ëŠ¥ë ¥ 6ë°° ì¦ê°€
- ìœ ì§€ë³´ìˆ˜: ë§ˆì¼“ë³„ ë…ë¦½ ì„¤ì •ìœ¼ë¡œ ìµœì†Œí™”

---

## 2. êµ¬í˜„ ì „ëžµ

### 2.1 Phase-Based Rollout (3 Phases)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 1: Foundation (Week 1, Days 1-3)                      â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ Goal: ì„¤ì • íŒŒì¼ ì¸í”„ë¼ ë° í™˜ìœ¨ ì‹œìŠ¤í…œ êµ¬ì¶•                  â”‚
â”‚                                                             â”‚
â”‚ Tasks:                                                      â”‚
â”‚ 1. ë§ˆì¼“ë³„ ì„¤ì • íŒŒì¼ ìž‘ì„± (5 markets Ã— YAML)                 â”‚
â”‚ 2. ExchangeRateManager êµ¬í˜„ (KIS API + BOK fallback)      â”‚
â”‚ 3. MarketFilterManager ê²€ì¦ ë° í…ŒìŠ¤íŠ¸                       â”‚
â”‚ 4. Unit Tests (ì„¤ì • ë¡œë”©, í™˜ìœ¨ ë³€í™˜)                        â”‚
â”‚                                                             â”‚
â”‚ Deliverable:                                                â”‚
â”‚ - 5ê°œ ë§ˆì¼“ ì„¤ì • íŒŒì¼ (ì™„ë£Œ, í…ŒìŠ¤íŠ¸ í†µê³¼)                     â”‚
â”‚ - í™˜ìœ¨ ê´€ë¦¬ ì‹œìŠ¤í…œ (ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸ + ìºì‹±)                  â”‚
â”‚ - 97% í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ (ì„¤ì • ì‹œìŠ¤í…œ)                          â”‚
â”‚                                                             â”‚
â”‚ Success Criteria:                                           â”‚
â”‚ âœ… 5ê°œ ë§ˆì¼“ config ë¡œë”© ì„±ê³µ                                 â”‚
â”‚ âœ… í™˜ìœ¨ ë³€í™˜ ì •í™•ë„ Â±0.1% ì´ë‚´                               â”‚
â”‚ âœ… TTL ìºì‹± ë™ìž‘ ê²€ì¦ (1h market / 24h after-hours)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 2: Integration (Week 1-2, Days 4-7)                   â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ Goal: OHLCV ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ì— í•„í„°ë§ í†µí•©                    â”‚
â”‚                                                             â”‚
â”‚ Tasks:                                                      â”‚
â”‚ 1. kis_data_collector.py ê°œì„                               â”‚
â”‚    - Stage 0 í•„í„°ë§ í†µí•© (market-specific)                  â”‚
â”‚    - Stage 1 í•„í„°ë§ í†µí•© (market-agnostic)                  â”‚
â”‚    - ë°°ì¹˜ ìˆ˜ì§‘ ë¡œì§ ì¶”ê°€                                     â”‚
â”‚                                                             â”‚
â”‚ 2. ë§ˆì¼“ë³„ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ìž‘ì„±                                 â”‚
â”‚    - scripts/collect_us_ohlcv.py                           â”‚
â”‚    - scripts/collect_hk_ohlcv.py                           â”‚
â”‚    - scripts/collect_cn_ohlcv.py                           â”‚
â”‚    - scripts/collect_jp_ohlcv.py                           â”‚
â”‚    - scripts/collect_vn_ohlcv.py                           â”‚
â”‚                                                             â”‚
â”‚ 3. Database Schema ê²€ì¦                                     â”‚
â”‚    - filter_cache_stage0 (region ì»¬ëŸ¼, currency í•„ë“œ)       â”‚
â”‚    - filter_cache_stage1 (composite key ê²€ì¦)               â”‚
â”‚    - Exchange rate metadata ì €ìž¥ í…ŒìŠ¤íŠ¸                     â”‚
â”‚                                                             â”‚
â”‚ Deliverable:                                                â”‚
â”‚ - í†µí•© OHLCV ìˆ˜ì§‘ ì‹œìŠ¤í…œ (5 markets)                         â”‚
â”‚ - ë§ˆì¼“ë³„ ë…ë¦½ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸                                  â”‚
â”‚ - DB ìŠ¤í‚¤ë§ˆ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ                                â”‚
â”‚                                                             â”‚
â”‚ Success Criteria:                                           â”‚
â”‚ âœ… ê° ë§ˆì¼“ Stage 0-1-2 íŒŒì´í”„ë¼ì¸ ë™ìž‘                       â”‚
â”‚ âœ… DBì— region/currency ì •í™•ížˆ ì €ìž¥                          â”‚
â”‚ âœ… 250ì¼ OHLCV ë°ì´í„° ìˆ˜ì§‘ ì„±ê³µ                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Phase 3: Validation & Monitoring (Week 2, Days 8-10)        â”‚
â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
â”‚ Goal: í…ŒìŠ¤íŠ¸, ëª¨ë‹ˆí„°ë§, ë¬¸ì„œí™”                               â”‚
â”‚                                                             â”‚
â”‚ Tasks:                                                      â”‚
â”‚ 1. End-to-End Testing (ë§ˆì¼“ë³„)                               â”‚
â”‚    - US: 1,500 tickers â†’ 600 (Stage 1)                     â”‚
â”‚    - HK: 400 tickers â†’ 150 (Stage 1)                       â”‚
â”‚    - CN: 300 tickers â†’ 120 (Stage 1)                       â”‚
â”‚    - JP: 600 tickers â†’ 240 (Stage 1)                       â”‚
â”‚    - VN: 200 tickers â†’ 80 (Stage 1)                        â”‚
â”‚                                                             â”‚
â”‚ 2. Monitoring Dashboard êµ¬ì¶•                                â”‚
â”‚    - Prometheus metrics (per-market)                       â”‚
â”‚    - Grafana dashboards (5 markets)                        â”‚
â”‚    - Alert rules (í™˜ìœ¨ ì´ìƒ, ìˆ˜ì§‘ ì‹¤íŒ¨)                      â”‚
â”‚                                                             â”‚
â”‚ 3. Documentation                                            â”‚
â”‚    - Deployment Guide (ë§ˆì¼“ë³„ ë°°í¬ ì ˆì°¨)                     â”‚
â”‚    - Troubleshooting Guide (FAQ, Common Issues)            â”‚
â”‚    - API Reference (MarketFilterManager, ExchangeRate)     â”‚
â”‚                                                             â”‚
â”‚ Deliverable:                                                â”‚
â”‚ - 5ê°œ ë§ˆì¼“ E2E í…ŒìŠ¤íŠ¸ ì™„ë£Œ ë¦¬í¬íŠ¸                            â”‚
â”‚ - Grafana ëŒ€ì‹œë³´ë“œ (6ê°œ: 1 Overview + 5 Markets)            â”‚
â”‚ - ì™„ì „í•œ ìš´ì˜ ë¬¸ì„œ (Deployment + Runbook)                   â”‚
â”‚                                                             â”‚
â”‚ Success Criteria:                                           â”‚
â”‚ âœ… 95%+ í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ (E2E)                                  â”‚
â”‚ âœ… ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ ì‹¤ì‹œê°„ ë°ì´í„° í‘œì‹œ                       â”‚
â”‚ âœ… ë¬¸ì„œ ì™„ì „ì„± 95%+ (ìš´ì˜íŒ€ ë¦¬ë·° í†µê³¼)                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ìš°ì„ ìˆœìœ„ ë§¤íŠ¸ë¦­ìŠ¤

**Tier 1 (Critical - Week 1)**:
- ðŸ”´ **US Market**: ê°€ìž¥ í° ì‹œìž¥, KIS API ì•ˆì •ì„± ë†’ìŒ
- ðŸ”´ **Exchange Rate System**: ëª¨ë“  ë§ˆì¼“ì˜ ê¸°ë³¸ ì¸í”„ë¼

**Tier 2 (High Priority - Week 1-2)**:
- ðŸŸ  **HK Market**: Stock Connectë¡œ CNê³¼ ì—°ê³„
- ðŸŸ  **CN Market**: Stock Connect ì¢…ëª© (ì™¸êµ­ì¸ ê±°ëž˜ ê°€ëŠ¥)

**Tier 3 (Medium Priority - Week 2)**:
- ðŸŸ¡ **JP Market**: ì„±ìˆ™í•œ ì‹œìž¥, ì•ˆì •ì  ë°ì´í„°
- ðŸŸ¡ **VN Market**: ì‹ í¥ ì‹œìž¥, ë°ì´í„° í’ˆì§ˆ ê²€ì¦ í•„ìš”

---

## 3. ì„¸ë¶€ ìž‘ì—… ê³„íš (Task Breakdown)

### 3.1 Phase 1: Foundation (Days 1-3, 24ì‹œê°„)

#### **Task 1.1: ë§ˆì¼“ë³„ ì„¤ì • íŒŒì¼ ìž‘ì„±** (6ì‹œê°„)

**Subtasks**:
1. `us_filter_config.yaml` ìž‘ì„± (1.5h)
   - Exchange rate: USD/KRW â‰ˆ 1,300
   - Min trading value: $7.7M/day (â‚©100ì–µ)
   - Min market cap: $77M (â‚©1,000ì–µ)
   - Penny stock/OTC exclusion rules

2. `hk_filter_config.yaml` ìž‘ì„± (1h)
   - Exchange rate: HKD/KRW â‰ˆ 170
   - Min trading value: HK$59M/day
   - Hang Seng Index focus

3. `cn_filter_config.yaml` ìž‘ì„± (1.5h)
   - Exchange rate: CNY/KRW â‰ˆ 180
   - Min trading value: Â¥56M/day
   - **Stock Connect only** (ì¤‘ìš”!)
   - ST/PT stock exclusion

4. `jp_filter_config.yaml` ìž‘ì„± (1h)
   - Exchange rate: JPY/KRW â‰ˆ 10
   - Min trading value: Â¥1B/day
   - TOPIX 500 focus

5. `vn_filter_config.yaml` ìž‘ì„± (1h)
   - Exchange rate: VND/KRW â‰ˆ 0.055
   - Min trading value: â‚«182B/day
   - VN30 Index focus

**Deliverable**:
```
config/market_filters/
  â”œâ”€ kr_filter_config.yaml    # âœ… ê¸°ì¡´
  â”œâ”€ us_filter_config.yaml    # ðŸ†•
  â”œâ”€ hk_filter_config.yaml    # ðŸ†•
  â”œâ”€ cn_filter_config.yaml    # ðŸ†•
  â”œâ”€ jp_filter_config.yaml    # ðŸ†•
  â””â”€ vn_filter_config.yaml    # ðŸ†•
```

**Validation**:
```bash
# ì„¤ì • íŒŒì¼ ë¡œë”© í…ŒìŠ¤íŠ¸
python3 -c "from modules.market_filter_manager import MarketFilterManager; \
mgr = MarketFilterManager(); \
print('Supported markets:', mgr.get_supported_regions())"

# Expected output:
# Supported markets: ['CN', 'HK', 'JP', 'KR', 'US', 'VN']
```

---

#### **Task 1.2: ExchangeRateManager êµ¬í˜„** (8ì‹œê°„)

**ìƒˆ íŒŒì¼**: `modules/exchange_rate_manager.py`

**Features**:
1. **Multi-Source Support**:
   - Primary: KIS API real-time rates
   - Fallback 1: Bank of Korea (BOK) official rates
   - Fallback 2: Fixed default rates

2. **Caching Strategy**:
   - In-memory cache with TTL (1 hour market hours, 24h after-hours)
   - Database persistence (exchange_rate_history table)

3. **Auto-Update Scheduler**:
   - Hourly updates during trading hours
   - Daily updates after-hours

**Implementation**:

```python
"""
Exchange Rate Manager - Multi-Currency Support

Handles real-time exchange rate fetching, caching, and fallback.

Data Flow:
1. KIS API (primary) â†’ BOK API (fallback) â†’ Default rate (last resort)
2. Cache in memory (TTL) + DB (history)
3. Auto-update every 1h (market) / 24h (after-hours)

Author: Spock Trading System
"""

import logging
import requests
from typing import Dict, Optional
from datetime import datetime, timedelta
from dataclasses import dataclass
import sqlite3

logger = logging.getLogger(__name__)


@dataclass
class ExchangeRate:
    """Exchange rate data structure"""
    currency: str           # 'USD', 'HKD', 'CNY', 'JPY', 'VND'
    rate_to_krw: float      # Conversion rate to KRW
    source: str             # 'kis_api', 'bok', 'fixed'
    timestamp: datetime     # Rate timestamp
    is_cached: bool = False


class ExchangeRateManager:
    """
    Multi-currency exchange rate manager

    Responsibilities:
    1. Fetch real-time rates from KIS API
    2. Fallback to Bank of Korea if KIS fails
    3. Cache rates in memory and database
    4. Auto-update based on market hours
    """

    def __init__(self, db_path: str = 'data/spock_local.db'):
        self.db_path = db_path

        # In-memory cache (currency â†’ ExchangeRate)
        self._cache: Dict[str, ExchangeRate] = {}

        # Default rates (fallback of last resort)
        self._default_rates = {
            'KRW': 1.0,      # Base currency
            'USD': 1300.0,   # $1 = â‚©1,300
            'HKD': 170.0,    # HK$1 = â‚©170
            'CNY': 180.0,    # Â¥1 = â‚©180
            'JPY': 10.0,     # Â¥1 = â‚©10
            'VND': 0.055,    # â‚«1 = â‚©0.055
        }

        # Cache TTL settings
        self._cache_ttl_market_hours = timedelta(hours=1)
        self._cache_ttl_after_hours = timedelta(hours=24)

        logger.info("âœ… ExchangeRateManager initialized")

    def get_rate(self, currency: str, force_refresh: bool = False) -> float:
        """
        Get exchange rate for currency to KRW

        Args:
            currency: 'USD', 'HKD', 'CNY', 'JPY', 'VND'
            force_refresh: Bypass cache and fetch fresh rate

        Returns:
            Exchange rate (currency to KRW)

        Example:
            rate = manager.get_rate('USD')  # Returns ~1300.0
            krw_value = usd_value * rate    # Convert $100 â†’ â‚©130,000
        """
        currency = currency.upper()

        # KRW is base currency
        if currency == 'KRW':
            return 1.0

        # Check cache (if not force refresh)
        if not force_refresh and self._is_cache_valid(currency):
            cached_rate = self._cache[currency]
            logger.debug(f"ðŸ’¾ [{currency}] Cache hit: {cached_rate.rate_to_krw} (source: {cached_rate.source})")
            return cached_rate.rate_to_krw

        # Fetch fresh rate (with fallback chain)
        rate = self._fetch_rate_with_fallback(currency)

        return rate.rate_to_krw

    def _fetch_rate_with_fallback(self, currency: str) -> ExchangeRate:
        """
        Fetch rate with fallback chain:
        KIS API â†’ BOK API â†’ Default Rate
        """
        # Try KIS API first
        try:
            rate = self._fetch_from_kis_api(currency)
            if rate:
                self._update_cache(currency, rate)
                self._save_to_db(rate)
                return rate
        except Exception as e:
            logger.warning(f"âš ï¸ [{currency}] KIS API failed: {e}")

        # Fallback to BOK API
        try:
            rate = self._fetch_from_bok_api(currency)
            if rate:
                self._update_cache(currency, rate)
                self._save_to_db(rate)
                return rate
        except Exception as e:
            logger.warning(f"âš ï¸ [{currency}] BOK API failed: {e}")

        # Last resort: Default rate
        logger.warning(f"âš ï¸ [{currency}] Using default rate: {self._default_rates[currency]}")
        rate = ExchangeRate(
            currency=currency,
            rate_to_krw=self._default_rates[currency],
            source='fixed',
            timestamp=datetime.now()
        )
        self._update_cache(currency, rate)
        return rate

    def _fetch_from_kis_api(self, currency: str) -> Optional[ExchangeRate]:
        """
        Fetch exchange rate from KIS API

        KIS API Endpoint:
        - /uapi/overseas-stock/v1/quotations/exchange-rate
        - Transaction ID: TBD (í™˜ìœ¨ ì¡°íšŒìš©)
        """
        # TODO: Implement KIS API integration
        # For now, return None to trigger fallback
        logger.debug(f"ðŸ” [{currency}] Fetching from KIS API (not implemented yet)")
        return None

    def _fetch_from_bok_api(self, currency: str) -> Optional[ExchangeRate]:
        """
        Fetch exchange rate from Bank of Korea (í•œêµ­ì€í–‰) API

        BOK Open API:
        - Endpoint: https://ecos.bok.or.kr/api/
        - Service: StatisticSearch (í†µê³„ì¡°íšŒ)
        - Stat Code: 731Y001 (í™˜ìœ¨)
        """
        # TODO: Implement BOK API integration
        # For now, return None to trigger default rate
        logger.debug(f"ðŸ” [{currency}] Fetching from BOK API (not implemented yet)")
        return None

    def _is_cache_valid(self, currency: str) -> bool:
        """Check if cached rate is still valid (within TTL)"""
        if currency not in self._cache:
            return False

        cached_rate = self._cache[currency]
        age = datetime.now() - cached_rate.timestamp

        # Determine TTL based on market hours
        # TODO: Integrate with market_hours check
        ttl = self._cache_ttl_market_hours  # For now, assume market hours

        return age < ttl

    def _update_cache(self, currency: str, rate: ExchangeRate):
        """Update in-memory cache"""
        rate.is_cached = True
        self._cache[currency] = rate
        logger.debug(f"ðŸ’¾ [{currency}] Cache updated: {rate.rate_to_krw} (source: {rate.source})")

    def _save_to_db(self, rate: ExchangeRate):
        """Save rate to database for historical tracking"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            cursor.execute("""
                INSERT INTO exchange_rate_history (
                    currency, rate_to_krw, source, timestamp
                ) VALUES (?, ?, ?, ?)
            """, (
                rate.currency,
                rate.rate_to_krw,
                rate.source,
                rate.timestamp.isoformat()
            ))

            conn.commit()
            conn.close()

        except Exception as e:
            logger.warning(f"âš ï¸ [{rate.currency}] DB save failed: {e}")

    def get_all_rates(self) -> Dict[str, float]:
        """
        Get all supported currency rates

        Returns:
            Dict mapping currency to KRW rate
        """
        rates = {}
        for currency in ['USD', 'HKD', 'CNY', 'JPY', 'VND']:
            rates[currency] = self.get_rate(currency)

        return rates

    def convert_to_krw(self, value: float, currency: str) -> int:
        """
        Convert foreign currency value to KRW

        Args:
            value: Value in foreign currency
            currency: 'USD', 'HKD', 'CNY', 'JPY', 'VND'

        Returns:
            Value in KRW (integer)
        """
        rate = self.get_rate(currency)
        return int(value * rate)
```

**Database Schema**:

```sql
-- Exchange rate history table
CREATE TABLE IF NOT EXISTS exchange_rate_history (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    currency TEXT NOT NULL,           -- 'USD', 'HKD', 'CNY', 'JPY', 'VND'
    rate_to_krw REAL NOT NULL,        -- Conversion rate
    source TEXT NOT NULL,             -- 'kis_api', 'bok', 'fixed'
    timestamp TIMESTAMP NOT NULL,     -- Rate timestamp
    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX idx_exchange_rate_currency_time
ON exchange_rate_history(currency, timestamp DESC);
```

**Unit Tests**:

```bash
# Create tests/test_exchange_rate_manager.py
pytest tests/test_exchange_rate_manager.py -v

# Expected:
# âœ… test_get_rate_krw (base currency)
# âœ… test_get_rate_with_cache
# âœ… test_get_rate_fallback_chain
# âœ… test_convert_to_krw
# âœ… test_cache_ttl_validation
```

---

#### **Task 1.3: MarketFilterManager ê²€ì¦** (4ì‹œê°„)

**ê¸°ì¡´ íŒŒì¼**: `modules/market_filter_manager.py`

**Enhancement Tasks**:
1. ExchangeRateManager í†µí•© (2h)
2. ë™ì  í™˜ìœ¨ ì—…ë°ì´íŠ¸ ì§€ì› (1h)
3. Unit Tests ì¶”ê°€ (1h)

**Code Changes**:

```python
# modules/market_filter_manager.py (enhanced)

class MarketFilterConfig:
    """Market-specific filter configuration (enhanced)"""

    def __init__(self, config_path: str, exchange_rate_manager=None):
        # ... existing code ...

        # Exchange rate manager
        self.exchange_rate_manager = exchange_rate_manager

        # Dynamic exchange rate (if manager provided)
        if self.exchange_rate_manager and self.currency != 'KRW':
            try:
                self._current_exchange_rate = self.exchange_rate_manager.get_rate(self.currency)
                logger.info(
                    f"ðŸ”„ [{self.region}] Dynamic exchange rate loaded: "
                    f"{self.currency}/KRW = {self._current_exchange_rate}"
                )
            except Exception as e:
                logger.warning(f"âš ï¸ [{self.region}] Dynamic rate failed, using default: {e}")

    def update_exchange_rate_from_manager(self):
        """Update exchange rate from ExchangeRateManager"""
        if self.exchange_rate_manager and self.currency != 'KRW':
            self._current_exchange_rate = self.exchange_rate_manager.get_rate(
                self.currency,
                force_refresh=True
            )
            logger.info(
                f"ðŸ”„ [{self.region}] Exchange rate updated: "
                f"{self._current_exchange_rate}"
            )


class MarketFilterManager:
    """Manages multi-market filter configurations (enhanced)"""

    def __init__(self, config_dir: str = 'config/market_filters',
                 exchange_rate_manager=None):
        self.config_dir = Path(config_dir)
        self.configs: Dict[str, MarketFilterConfig] = {}

        # Exchange rate manager (shared across markets)
        self.exchange_rate_manager = exchange_rate_manager

        # Load configs
        self._load_all_configs()

    def _load_all_configs(self):
        """Load all market configurations with dynamic exchange rates"""
        # ... existing code ...

        for config_file in self.config_dir.glob('*_filter_config.yaml'):
            try:
                config = MarketFilterConfig(
                    str(config_file),
                    exchange_rate_manager=self.exchange_rate_manager
                )
                self.configs[config.region] = config
                loaded_count += 1
            except Exception as e:
                logger.error(f"âŒ Failed to load {config_file.name}: {e}")

        # ... existing code ...

    def refresh_exchange_rates(self):
        """Refresh exchange rates for all markets"""
        for config in self.configs.values():
            if config.currency != 'KRW':
                config.update_exchange_rate_from_manager()
```

**Integration Test**:

```python
# tests/test_market_filter_manager_integration.py

def test_market_filter_manager_with_exchange_rates():
    """Test MarketFilterManager with ExchangeRateManager integration"""
    from modules.exchange_rate_manager import ExchangeRateManager
    from modules.market_filter_manager import MarketFilterManager

    # Initialize managers
    exchange_mgr = ExchangeRateManager(db_path='data/test_spock.db')
    filter_mgr = MarketFilterManager(
        config_dir='config/market_filters',
        exchange_rate_manager=exchange_mgr
    )

    # Test: All markets loaded
    assert len(filter_mgr.get_supported_regions()) == 6  # KR, US, HK, CN, JP, VN

    # Test: Exchange rates applied
    us_config = filter_mgr.get_config('US')
    assert us_config.get_exchange_rate() > 1000  # USD/KRW should be ~1,300

    hk_config = filter_mgr.get_config('HK')
    assert hk_config.get_exchange_rate() > 100   # HKD/KRW should be ~170

    # Test: Currency conversion
    us_100m_in_krw = us_config.convert_to_krw(100_000_000)  # $100M
    assert 120_000_000_000 < us_100m_in_krw < 140_000_000_000  # ~â‚©130B

    print("âœ… All integration tests passed")
```

---

#### **Task 1.4: Database Schema Migration** (4ì‹œê°„)

**Migration File**: `migrations/004_add_exchange_rate_history.py`

```python
"""
Migration 004: Add Exchange Rate History Table

Adds:
1. exchange_rate_history table (í™˜ìœ¨ ì´ë ¥ ì¶”ì )
2. Indexes for efficient querying

Author: Spock Trading System
Date: 2025-10-16
"""

import sqlite3
import logging

logger = logging.getLogger(__name__)


def upgrade(db_path: str = 'data/spock_local.db'):
    """Apply migration: Add exchange_rate_history table"""

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        # 1. Create exchange_rate_history table
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS exchange_rate_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                currency TEXT NOT NULL,
                rate_to_krw REAL NOT NULL,
                source TEXT NOT NULL,
                timestamp TIMESTAMP NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # 2. Create indexes
        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_exchange_rate_currency_time
            ON exchange_rate_history(currency, timestamp DESC)
        """)

        cursor.execute("""
            CREATE INDEX IF NOT EXISTS idx_exchange_rate_source
            ON exchange_rate_history(source)
        """)

        conn.commit()
        logger.info("âœ… Migration 004: exchange_rate_history table created")

    except Exception as e:
        conn.rollback()
        logger.error(f"âŒ Migration 004 failed: {e}")
        raise

    finally:
        conn.close()


def downgrade(db_path: str = 'data/spock_local.db'):
    """Rollback migration: Drop exchange_rate_history table"""

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    try:
        cursor.execute("DROP TABLE IF EXISTS exchange_rate_history")
        conn.commit()
        logger.info("âœ… Migration 004 rollback: exchange_rate_history table dropped")

    except Exception as e:
        conn.rollback()
        logger.error(f"âŒ Migration 004 rollback failed: {e}")
        raise

    finally:
        conn.close()


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='Migration 004: Exchange Rate History')
    parser.add_argument('--upgrade', action='store_true', help='Apply migration')
    parser.add_argument('--downgrade', action='store_true', help='Rollback migration')
    parser.add_argument('--db-path', default='data/spock_local.db', help='Database path')

    args = parser.parse_args()

    if args.upgrade:
        upgrade(args.db_path)
    elif args.downgrade:
        downgrade(args.db_path)
    else:
        print("Usage: python migrations/004_add_exchange_rate_history.py --upgrade")
```

**Validation**:

```bash
# Apply migration
python3 migrations/004_add_exchange_rate_history.py --upgrade

# Verify table created
sqlite3 data/spock_local.db "SELECT name FROM sqlite_master WHERE type='table' AND name='exchange_rate_history'"

# Expected output: exchange_rate_history
```

---

#### **Task 1.5: Unit Tests (ì„¤ì • ì‹œìŠ¤í…œ)** (2ì‹œê°„)

**Test Files**:
1. `tests/test_market_filter_config.py`
2. `tests/test_exchange_rate_manager.py`
3. `tests/test_market_filter_manager.py`

**Target Coverage**: 97%+

**Run Tests**:

```bash
# Run all Phase 1 tests
pytest tests/test_market_filter_*.py tests/test_exchange_rate_*.py -v --cov=modules --cov-report=html

# Expected output:
# âœ… test_market_filter_config.py .......... (10 tests)
# âœ… test_exchange_rate_manager.py .......... (10 tests)
# âœ… test_market_filter_manager.py .......... (12 tests)
# Coverage: 97.3%
```

---

### 3.2 Phase 2: Integration (Days 4-7, 32ì‹œê°„)

#### **Task 2.1: kis_data_collector.py ê°œì„ ** (12ì‹œê°„)

**ëª©í‘œ**: Stage 0-1 í•„í„°ë§ì„ OHLCV ìˆ˜ì§‘ ì „ì— ì ìš©

**Changes**:

```python
# modules/kis_data_collector.py (enhanced)

class KISDataCollector:
    """
    KIS API Data Collector with Multi-Stage Filtering

    New Features:
    1. Stage 0 filter integration (market cap, trading value)
    2. Stage 1 filter integration (technical pre-screen)
    3. Batch collection with filtering
    """

    def __init__(self, db_manager, region: str = 'KR'):
        self.db = db_manager
        self.region = region

        # Initialize filter manager
        from modules.exchange_rate_manager import ExchangeRateManager
        from modules.market_filter_manager import MarketFilterManager

        self.exchange_rate_manager = ExchangeRateManager(db_path=self.db.db_path)
        self.filter_manager = MarketFilterManager(
            config_dir='config/market_filters',
            exchange_rate_manager=self.exchange_rate_manager
        )

        # Get market config
        self.market_config = self.filter_manager.get_config(region)
        if not self.market_config:
            raise ValueError(f"No market config found for region: {region}")

        logger.info(f"âœ… KISDataCollector initialized (region={region})")

    def collect_with_filtering(self,
                               tickers: Optional[List[str]] = None,
                               days: int = 250,
                               apply_stage0: bool = True,
                               apply_stage1: bool = True) -> Dict[str, int]:
        """
        Collect OHLCV data with multi-stage filtering

        Workflow:
        1. Load ticker list (from DB or provided)
        2. Apply Stage 0 filter (market cap, trading value)
        3. Apply Stage 1 filter (technical pre-screen)
        4. Collect OHLCV for filtered tickers

        Args:
            tickers: Ticker list (None = all active tickers in region)
            days: Historical days to collect
            apply_stage0: Enable Stage 0 filtering
            apply_stage1: Enable Stage 1 filtering (requires OHLCV data)

        Returns:
            {
                'input_count': int,
                'stage0_passed': int,
                'stage1_passed': int,
                'ohlcv_collected': int
            }
        """
        start_time = datetime.now()

        # Step 1: Load ticker list
        if tickers is None:
            ticker_data = self.db.get_tickers(region=self.region, asset_type='STOCK', is_active=True)
            tickers = [t['ticker'] for t in ticker_data]

        logger.info(f"ðŸ“Š [{self.region}] Starting OHLCV collection with filtering: {len(tickers)} tickers")

        stats = {
            'input_count': len(tickers),
            'stage0_passed': 0,
            'stage1_passed': 0,
            'ohlcv_collected': 0
        }

        # Step 2: Apply Stage 0 filter (if enabled)
        if apply_stage0:
            stage0_results = self._run_stage0_filter(tickers)
            stage0_tickers = [t['ticker'] for t in stage0_results if t['passed']]
            stats['stage0_passed'] = len(stage0_tickers)

            logger.info(
                f"ðŸ“Š [{self.region}] Stage 0 complete: "
                f"{len(tickers)} â†’ {len(stage0_tickers)} tickers "
                f"({(1 - len(stage0_tickers)/len(tickers))*100:.1f}% filtered)"
            )
        else:
            stage0_tickers = tickers
            stats['stage0_passed'] = len(stage0_tickers)

        # Step 3: Collect OHLCV for Stage 0 passed tickers
        for ticker in stage0_tickers:
            try:
                # Fetch OHLCV
                ohlcv_df = self._fetch_ohlcv(ticker, days=days)
                if ohlcv_df.empty:
                    logger.warning(f"âš ï¸ [{ticker}] No OHLCV data")
                    continue

                # Calculate technical indicators
                ohlcv_df = self._calculate_technical_indicators(ohlcv_df)

                # Save to database
                self._save_ohlcv_to_db(ticker, ohlcv_df, period_type='DAILY')

                stats['ohlcv_collected'] += 1

            except Exception as e:
                logger.error(f"âŒ [{ticker}] OHLCV collection failed: {e}")

        # Step 4: Apply Stage 1 filter (if enabled)
        if apply_stage1:
            from modules.stock_pre_filter import StockPreFilter

            pre_filter = StockPreFilter(db_path=self.db.db_path, region=self.region)
            stage1_results = pre_filter.run_stage1_filter(force_refresh=True)
            stats['stage1_passed'] = len(stage1_results)

            logger.info(
                f"ðŸ“Š [{self.region}] Stage 1 complete: "
                f"{stats['ohlcv_collected']} â†’ {stats['stage1_passed']} tickers "
                f"({(1 - stats['stage1_passed']/stats['ohlcv_collected'])*100:.1f}% filtered)"
            )

        # Log final stats
        execution_time = (datetime.now() - start_time).total_seconds()
        logger.info(
            f"âœ… [{self.region}] OHLCV collection complete:\n"
            f"   Input: {stats['input_count']} tickers\n"
            f"   Stage 0 passed: {stats['stage0_passed']}\n"
            f"   OHLCV collected: {stats['ohlcv_collected']}\n"
            f"   Stage 1 passed: {stats['stage1_passed']}\n"
            f"   Total time: {execution_time:.1f}s"
        )

        return stats

    def _run_stage0_filter(self, tickers: List[str]) -> List[Dict]:
        """
        Run Stage 0 filter (market cap, trading value)

        Returns:
            List of {'ticker': str, 'passed': bool, 'reason': str, ...}
        """
        from modules.scanner import StockScanner

        scanner = StockScanner(db_path=self.db.db_path, region=self.region)
        results = scanner.run_stage0_filter(tickers=tickers, force_refresh=True)

        return results
```

---

#### **Task 2.2: ë§ˆì¼“ë³„ ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸ ìž‘ì„±** (8ì‹œê°„)

**Scripts** (ê° ë§ˆì¼“ë‹¹ 1.5ì‹œê°„):
1. `scripts/collect_us_ohlcv.py`
2. `scripts/collect_hk_ohlcv.py`
3. `scripts/collect_cn_ohlcv.py`
4. `scripts/collect_jp_ohlcv.py`
5. `scripts/collect_vn_ohlcv.py`

**Template Script** (`scripts/collect_us_ohlcv.py`):

```python
"""
US Market OHLCV Collection Script

Collects 250-day OHLCV data for US stocks with filtering:
- Stage 0: Market cap ($77M), Trading value ($7.7M/day)
- Stage 1: Technical pre-screen (MA, RSI, volume)

Usage:
    python3 scripts/collect_us_ohlcv.py --full
    python3 scripts/collect_us_ohlcv.py --tickers AAPL MSFT GOOGL
    python3 scripts/collect_us_ohlcv.py --dry-run

Author: Spock Trading System
"""

import os
import sys
import logging
import argparse
from datetime import datetime

# Add parent directory to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from modules.db_manager_sqlite import SQLiteDatabaseManager
from modules.kis_data_collector import KISDataCollector
from modules.market_adapters import USAdapterKIS

# Logging setup
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
logger = logging.getLogger(__name__)


def main():
    parser = argparse.ArgumentParser(description='US Market OHLCV Collection')
    parser.add_argument('--full', action='store_true', help='Full collection (all tickers)')
    parser.add_argument('--tickers', nargs='+', help='Specific tickers to collect')
    parser.add_argument('--days', type=int, default=250, help='Historical days (default: 250)')
    parser.add_argument('--dry-run', action='store_true', help='Dry run (no DB writes)')
    parser.add_argument('--skip-stage0', action='store_true', help='Skip Stage 0 filter')
    parser.add_argument('--skip-stage1', action='store_true', help='Skip Stage 1 filter')
    parser.add_argument('--db-path', default='data/spock_local.db', help='Database path')

    args = parser.parse_args()

    logger.info("="*60)
    logger.info("US Market OHLCV Collection Script")
    logger.info("="*60)

    # Initialize database
    db = SQLiteDatabaseManager(db_path=args.db_path)

    # Initialize collector
    collector = KISDataCollector(db_manager=db, region='US')

    # Determine ticker list
    if args.tickers:
        tickers = args.tickers
        logger.info(f"ðŸ“Š Collecting specific tickers: {', '.join(tickers)}")
    elif args.full:
        # Scan US stocks first
        from modules.market_adapters import USAdapterKIS

        us_adapter = USAdapterKIS(
            db,
            app_key=os.getenv('KIS_APP_KEY'),
            app_secret=os.getenv('KIS_APP_SECRET')
        )

        logger.info("ðŸ” Scanning US stocks...")
        stocks = us_adapter.scan_stocks(force_refresh=True)
        tickers = [s['ticker'] for s in stocks]
        logger.info(f"ðŸ“Š Found {len(tickers)} US stocks")
    else:
        logger.error("âŒ Must specify --full or --tickers")
        sys.exit(1)

    # Dry run check
    if args.dry_run:
        logger.info("ðŸ” DRY RUN MODE - No database writes")
        logger.info(f"   Would collect {len(tickers)} tickers with {args.days} days")
        sys.exit(0)

    # Run collection with filtering
    stats = collector.collect_with_filtering(
        tickers=tickers,
        days=args.days,
        apply_stage0=not args.skip_stage0,
        apply_stage1=not args.skip_stage1
    )

    # Print summary
    logger.info("")
    logger.info("="*60)
    logger.info("US Market OHLCV Collection Summary")
    logger.info("="*60)
    logger.info(f"Input tickers: {stats['input_count']}")
    logger.info(f"Stage 0 passed: {stats['stage0_passed']} ({stats['stage0_passed']/stats['input_count']*100:.1f}%)")
    logger.info(f"OHLCV collected: {stats['ohlcv_collected']}")
    logger.info(f"Stage 1 passed: {stats['stage1_passed']} ({stats['stage1_passed']/stats['ohlcv_collected']*100 if stats['ohlcv_collected'] > 0 else 0:.1f}%)")
    logger.info("="*60)

    logger.info("âœ… US Market OHLCV collection complete")


if __name__ == '__main__':
    main()
```

**Validation**:

```bash
# Dry run
python3 scripts/collect_us_ohlcv.py --full --dry-run

# Real run (single ticker)
python3 scripts/collect_us_ohlcv.py --tickers AAPL --days 250

# Expected output:
# âœ… Input: 1 ticker
# âœ… Stage 0 passed: 1 (100%)
# âœ… OHLCV collected: 1 (250 rows)
# âœ… Stage 1 passed: 1 (100%)
```

---

#### **Task 2.3: Database Schema ê²€ì¦** (4ì‹œê°„)

**Validation Tasks**:
1. `filter_cache_stage0` ë©€í‹°ë§ˆì¼“ ì§€ì› í™•ì¸ (1h)
2. `filter_cache_stage1` ë³µí•©í‚¤ ê²€ì¦ (1h)
3. Exchange rate metadata ì €ìž¥ í…ŒìŠ¤íŠ¸ (1h)
4. Data integrity ê²€ì¦ (1h)

**Validation Script** (`scripts/validate_db_schema.py`):

```python
"""
Database Schema Validation for Multi-Market Support

Validates:
1. filter_cache_stage0 (region, currency fields)
2. filter_cache_stage1 (composite key)
3. exchange_rate_history (rate tracking)
4. Data integrity (foreign keys, indexes)

Author: Spock Trading System
"""

import sqlite3
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def validate_schema(db_path: str = 'data/spock_local.db'):
    """Validate database schema for multi-market support"""

    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    results = {
        'filter_cache_stage0': False,
        'filter_cache_stage1': False,
        'exchange_rate_history': False,
        'indexes': False,
        'foreign_keys': False
    }

    try:
        # 1. Validate filter_cache_stage0
        cursor.execute("PRAGMA table_info(filter_cache_stage0)")
        stage0_columns = {row[1] for row in cursor.fetchall()}

        required_stage0 = {
            'ticker', 'region', 'name', 'exchange',
            'market_cap_krw', 'trading_value_krw', 'current_price_krw',
            'market_cap_local', 'trading_value_local', 'current_price_local',
            'currency', 'exchange_rate_to_krw'
        }

        if required_stage0.issubset(stage0_columns):
            logger.info("âœ… filter_cache_stage0: All required columns present")
            results['filter_cache_stage0'] = True
        else:
            missing = required_stage0 - stage0_columns
            logger.error(f"âŒ filter_cache_stage0: Missing columns {missing}")

        # 2. Validate filter_cache_stage1
        cursor.execute("PRAGMA table_info(filter_cache_stage1)")
        stage1_columns = {row[1] for row in cursor.fetchall()}

        required_stage1 = {
            'ticker', 'region', 'ma5', 'ma20', 'ma60', 'rsi_14',
            'current_price_krw', 'week_52_high_krw'
        }

        if required_stage1.issubset(stage1_columns):
            logger.info("âœ… filter_cache_stage1: All required columns present")
            results['filter_cache_stage1'] = True
        else:
            missing = required_stage1 - stage1_columns
            logger.error(f"âŒ filter_cache_stage1: Missing columns {missing}")

        # 3. Validate exchange_rate_history
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table' AND name='exchange_rate_history'")
        if cursor.fetchone():
            logger.info("âœ… exchange_rate_history: Table exists")
            results['exchange_rate_history'] = True
        else:
            logger.error("âŒ exchange_rate_history: Table not found")

        # 4. Validate indexes
        cursor.execute("SELECT name FROM sqlite_master WHERE type='index'")
        indexes = {row[0] for row in cursor.fetchall()}

        required_indexes = {
            'idx_stage0_region_date',
            'idx_stage1_region_date',
            'idx_exchange_rate_currency_time'
        }

        if required_indexes.issubset(indexes):
            logger.info("âœ… Indexes: All required indexes present")
            results['indexes'] = True
        else:
            missing = required_indexes - indexes
            logger.warning(f"âš ï¸ Indexes: Missing {missing}")

        # 5. Test data insertion
        test_data = {
            'ticker': 'TEST123',
            'region': 'US',
            'name': 'Test Stock',
            'exchange': 'NASDAQ',
            'market_cap_krw': 130_000_000_000,
            'trading_value_krw': 13_000_000_000,
            'current_price_krw': 130_000,
            'market_cap_local': 100_000_000,
            'trading_value_local': 10_000_000,
            'current_price_local': 100,
            'currency': 'USD',
            'exchange_rate_to_krw': 1300,
            'filter_date': '2025-10-16',
            'stage0_passed': True
        }

        cursor.execute("""
            INSERT OR REPLACE INTO filter_cache_stage0 (
                ticker, region, name, exchange,
                market_cap_krw, trading_value_krw, current_price_krw,
                market_cap_local, trading_value_local, current_price_local,
                currency, exchange_rate_to_krw, filter_date, stage0_passed
            ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """, tuple(test_data.values()))

        conn.commit()
        logger.info("âœ… Data insertion: Test data inserted successfully")

        # Cleanup test data
        cursor.execute("DELETE FROM filter_cache_stage0 WHERE ticker = 'TEST123'")
        conn.commit()

        results['foreign_keys'] = True

    except Exception as e:
        logger.error(f"âŒ Validation failed: {e}")

    finally:
        conn.close()

    # Summary
    logger.info("")
    logger.info("="*60)
    logger.info("Database Schema Validation Summary")
    logger.info("="*60)

    all_passed = all(results.values())

    for check, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        logger.info(f"{status}: {check}")

    logger.info("="*60)

    if all_passed:
        logger.info("âœ… All validation checks passed")
    else:
        logger.error("âŒ Some validation checks failed")
        return False

    return True


if __name__ == '__main__':
    import sys

    success = validate_schema()
    sys.exit(0 if success else 1)
```

**Run Validation**:

```bash
# Validate schema
python3 scripts/validate_db_schema.py

# Expected output:
# âœ… filter_cache_stage0: All required columns present
# âœ… filter_cache_stage1: All required columns present
# âœ… exchange_rate_history: Table exists
# âœ… Indexes: All required indexes present
# âœ… Data insertion: Test data inserted successfully
# âœ… All validation checks passed
```

---

#### **Task 2.4: Integration Tests** (8ì‹œê°„)

**Test Suite** (ê° ë§ˆì¼“ë‹¹ 1.5ì‹œê°„):
1. `tests/test_us_integration.py`
2. `tests/test_hk_integration.py`
3. `tests/test_cn_integration.py`
4. `tests/test_jp_integration.py`
5. `tests/test_vn_integration.py`

**Example Test** (`tests/test_us_integration.py`):

```python
"""
US Market End-to-End Integration Test

Tests:
1. Ticker scanning
2. Stage 0 filtering
3. OHLCV collection
4. Stage 1 filtering
5. Database storage

Author: Spock Trading System
"""

import pytest
import os
from modules.db_manager_sqlite import SQLiteDatabaseManager
from modules.market_adapters import USAdapterKIS
from modules.kis_data_collector import KISDataCollector
from modules.stock_pre_filter import StockPreFilter


@pytest.fixture
def db_manager():
    """Create test database manager"""
    db = SQLiteDatabaseManager(db_path='data/test_spock.db')
    yield db
    # Cleanup
    if os.path.exists('data/test_spock.db'):
        os.remove('data/test_spock.db')


def test_us_market_end_to_end(db_manager):
    """Test US market end-to-end workflow"""

    # Step 1: Initialize US adapter
    us_adapter = USAdapterKIS(
        db_manager,
        app_key=os.getenv('KIS_APP_KEY'),
        app_secret=os.getenv('KIS_APP_SECRET')
    )

    # Step 2: Scan US stocks (limited to 10 for testing)
    stocks = us_adapter.scan_stocks(force_refresh=True)
    assert len(stocks) > 0, "Should scan at least 1 US stock"

    test_tickers = [s['ticker'] for s in stocks[:10]]  # Test with 10 tickers

    # Step 3: Run Stage 0 filter
    from modules.scanner import StockScanner
    scanner = StockScanner(db_path=db_manager.db_path, region='US')
    stage0_results = scanner.run_stage0_filter(tickers=test_tickers, force_refresh=True)

    stage0_passed = [r for r in stage0_results if r['passed']]
    assert len(stage0_passed) > 0, "At least 1 ticker should pass Stage 0"

    # Step 4: Collect OHLCV for Stage 0 passed tickers
    collector = KISDataCollector(db_manager=db_manager, region='US')
    stats = collector.collect_with_filtering(
        tickers=[r['ticker'] for r in stage0_passed],
        days=250,
        apply_stage0=False,  # Already filtered
        apply_stage1=True
    )

    assert stats['ohlcv_collected'] > 0, "Should collect OHLCV for at least 1 ticker"

    # Step 5: Verify Stage 1 filter ran
    assert stats['stage1_passed'] >= 0, "Stage 1 filter should run"

    # Step 6: Verify database storage
    conn = db_manager._get_connection()
    cursor = conn.cursor()

    # Check filter_cache_stage0
    cursor.execute("SELECT COUNT(*) FROM filter_cache_stage0 WHERE region='US'")
    stage0_count = cursor.fetchone()[0]
    assert stage0_count > 0, "Stage 0 cache should have US tickers"

    # Check OHLCV data
    cursor.execute("SELECT COUNT(*) FROM ohlcv_data WHERE region='US'")
    ohlcv_count = cursor.fetchone()[0]
    assert ohlcv_count > 0, "OHLCV data should be stored for US"

    # Check currency/exchange rate
    cursor.execute("SELECT DISTINCT currency, exchange_rate_to_krw FROM filter_cache_stage0 WHERE region='US'")
    result = cursor.fetchone()
    assert result[0] == 'USD', "Currency should be USD"
    assert 1000 < result[1] < 2000, "Exchange rate should be ~1,300"

    conn.close()

    print(f"\nâœ… US Market End-to-End Test Passed")
    print(f"   Scanned: {len(stocks)} stocks")
    print(f"   Stage 0 passed: {len(stage0_passed)}")
    print(f"   OHLCV collected: {stats['ohlcv_collected']}")
    print(f"   Stage 1 passed: {stats['stage1_passed']}")


if __name__ == '__main__':
    pytest.main([__file__, '-v'])
```

**Run Integration Tests**:

```bash
# Run US integration test
pytest tests/test_us_integration.py -v -s

# Run all integration tests (5 markets)
pytest tests/test_*_integration.py -v --maxfail=1

# Expected output:
# âœ… test_us_integration.py::test_us_market_end_to_end PASSED
# âœ… test_hk_integration.py::test_hk_market_end_to_end PASSED
# âœ… test_cn_integration.py::test_cn_market_end_to_end PASSED
# âœ… test_jp_integration.py::test_jp_market_end_to_end PASSED
# âœ… test_vn_integration.py::test_vn_market_end_to_end PASSED
```

---

### 3.3 Phase 3: Validation & Monitoring (Days 8-10, 24ì‹œê°„)

#### **Task 3.1: End-to-End Testing (ë§ˆì¼“ë³„)** (12ì‹œê°„)

**Test Scenarios** (ê° ë§ˆì¼“ë‹¹ 2ì‹œê°„):
1. Full pipeline test (scan â†’ filter â†’ collect â†’ validate)
2. Performance benchmarking
3. Data quality validation
4. Error handling verification

**Performance Targets**:

| Market | Input | Stage 0 | OHLCV Collected | Stage 1 | Time Target |
|--------|-------|---------|-----------------|---------|-------------|
| US | ~8,000 | ~1,500 | ~1,500 | ~600 | <2 min |
| HK | ~2,500 | ~400 | ~400 | ~150 | <1 min |
| CN | ~2,000 | ~300 | ~300 | ~120 | <1 min |
| JP | ~3,800 | ~600 | ~600 | ~240 | <1.5 min |
| VN | ~1,500 | ~200 | ~200 | ~80 | <45s |

**Validation Checklist**:
- [ ] All tickers have region='XX' in database
- [ ] All prices normalized to KRW correctly
- [ ] Exchange rates within Â±5% of expected
- [ ] 250-day OHLCV data complete (no gaps >60 days)
- [ ] Technical indicators calculated correctly
- [ ] Stage 1 filter applied successfully

---

#### **Task 3.2: Monitoring Dashboard êµ¬ì¶•** (8ì‹œê°„)

**Prometheus Metrics** (2ì‹œê°„):

```yaml
# monitoring/prometheus/spock_multi_market_metrics.yml

# Market-specific OHLCV collection metrics
- metric_name: spock_market_ohlcv_collection_total
  type: counter
  labels: [region, status]  # status: success, failed
  description: "Total OHLCV collection attempts per market"

- metric_name: spock_market_stage0_filter_total
  type: counter
  labels: [region, result]  # result: passed, failed
  description: "Stage 0 filter results per market"

- metric_name: spock_market_stage1_filter_total
  type: counter
  labels: [region, result]
  description: "Stage 1 filter results per market"

# Exchange rate metrics
- metric_name: spock_exchange_rate_current
  type: gauge
  labels: [currency, source]
  description: "Current exchange rate to KRW"

- metric_name: spock_exchange_rate_update_timestamp
  type: gauge
  labels: [currency]
  description: "Last exchange rate update timestamp"

# Collection performance
- metric_name: spock_market_collection_duration_seconds
  type: histogram
  labels: [region]
  buckets: [30, 60, 120, 300, 600]
  description: "OHLCV collection duration per market"
```

**Grafana Dashboards** (6ì‹œê°„):

1. **Overview Dashboard** (1h)
   - All markets summary
   - Total tickers: input â†’ stage0 â†’ stage1
   - Collection success rate (by market)
   - Exchange rate trends

2. **US Market Dashboard** (1h)
   - 8 panels: Stage 0/1 filtering, OHLCV collection, errors
   - Exchange rate: USD/KRW chart
   - Top filtered tickers by market cap

3. **HK Market Dashboard** (1h)
4. **CN Market Dashboard** (1h)
5. **JP Market Dashboard** (1h)
6. **VN Market Dashboard** (1h)

**Grafana Dashboard JSON** (template):

```json
{
  "dashboard": {
    "title": "US Market OHLCV Collection",
    "panels": [
      {
        "title": "Stage 0 Filter Results",
        "targets": [{
          "expr": "rate(spock_market_stage0_filter_total{region=\"US\"}[5m])"
        }]
      },
      {
        "title": "OHLCV Collection Success Rate",
        "targets": [{
          "expr": "rate(spock_market_ohlcv_collection_total{region=\"US\",status=\"success\"}[5m]) / rate(spock_market_ohlcv_collection_total{region=\"US\"}[5m])"
        }]
      },
      {
        "title": "USD/KRW Exchange Rate",
        "targets": [{
          "expr": "spock_exchange_rate_current{currency=\"USD\"}"
        }]
      }
    ]
  }
}
```

---

#### **Task 3.3: Documentation** (4ì‹œê°„)

**Documents to Create**:
1. `docs/GLOBAL_OHLCV_FILTERING_DEPLOYMENT_GUIDE.md` (2h)
2. `docs/GLOBAL_OHLCV_FILTERING_TROUBLESHOOTING_GUIDE.md` (1h)
3. `docs/GLOBAL_OHLCV_FILTERING_API_REFERENCE.md` (1h)

**Deployment Guide Contents**:
- Prerequisites (KIS API keys, database setup)
- Configuration (YAML files)
- Deployment steps (per market)
- Validation procedures
- Rollback procedures

**Troubleshooting Guide Contents**:
- Common issues (exchange rate failures, data gaps)
- Error codes and meanings
- Debug commands
- FAQ

**API Reference Contents**:
- `MarketFilterManager` API
- `ExchangeRateManager` API
- `KISDataCollector` API
- Configuration schema reference

---

## 4. ë¦¬ì†ŒìŠ¤ í• ë‹¹ ê³„íš

### 4.1 ì‹œê°„ ë°°ë¶„ (ì´ 80ì‹œê°„, 2ì£¼)

| Phase | Tasks | Hours | Days | Priority |
|-------|-------|-------|------|----------|
| **Phase 1** | Foundation | 24h | 3 | ðŸ”´ Critical |
| **Phase 2** | Integration | 32h | 4 | ðŸ”´ Critical |
| **Phase 3** | Validation | 24h | 3 | ðŸŸ  High |
| **Total** | | **80h** | **10** | |

### 4.2 ë§ˆì¼“ë³„ ìš°ì„ ìˆœìœ„

**Week 1 (Days 1-5)**:
- âœ… Phase 1 ì™„ë£Œ (ì „ì²´ ì¸í”„ë¼)
- âœ… US Market ì™„ë£Œ (ê°€ìž¥ í° ì‹œìž¥)
- âœ… HK/CN Market ì‹œìž‘

**Week 2 (Days 6-10)**:
- âœ… HK/CN Market ì™„ë£Œ
- âœ… JP/VN Market ì™„ë£Œ
- âœ… Testing & Monitoring ì™„ë£Œ

### 4.3 ì²´í¬í¬ì¸íŠ¸

**Day 3 Checkpoint**:
- [ ] 5ê°œ ë§ˆì¼“ ì„¤ì • íŒŒì¼ ì™„ë£Œ
- [ ] ExchangeRateManager ë™ìž‘ ê²€ì¦
- [ ] Unit Tests 97%+ ì»¤ë²„ë¦¬ì§€

**Day 7 Checkpoint**:
- [ ] US/HK/CN ë§ˆì¼“ E2E í…ŒìŠ¤íŠ¸ í†µê³¼
- [ ] Database schema ê²€ì¦ ì™„ë£Œ
- [ ] Integration tests 95%+ í†µê³¼ìœ¨

**Day 10 Checkpoint (Final)**:
- [ ] 5ê°œ ë§ˆì¼“ ëª¨ë‘ ìš´ì˜ ì¤€ë¹„ ì™„ë£Œ
- [ ] Monitoring ëŒ€ì‹œë³´ë“œ ì‹¤ì‹œê°„ ë°ì´í„° í‘œì‹œ
- [ ] Documentation ì™„ì „ì„± 95%+

---

## 5. ìœ„í—˜ ê´€ë¦¬ (Risk Management)

### 5.1 ì£¼ìš” ìœ„í—˜ ìš”ì†Œ

| ìœ„í—˜ | í™•ë¥  | ì˜í–¥ë„ | ì™„í™” ì „ëžµ |
|------|------|--------|-----------|
| KIS API í™˜ìœ¨ ë¯¸ì§€ì› | ì¤‘ê°„ | ë†’ìŒ | BOK API fallback ì¤€ë¹„ |
| ë§ˆì¼“ë³„ ë°ì´í„° í’ˆì§ˆ ì°¨ì´ | ë†’ìŒ | ì¤‘ê°„ | ë§ˆì¼“ë³„ ê²€ì¦ ë¡œì§ ê°•í™” |
| 250ì¼ ë°ì´í„° ë¶€ì¡± (ì‹ ê·œ ìƒìž¥) | ë†’ìŒ | ë‚®ìŒ | ìµœì†Œ ì¼ìˆ˜ ì¡°ì • ê°€ëŠ¥ |
| Exchange rate ë³€ë™ì„± | ë‚®ìŒ | ì¤‘ê°„ | 1ì‹œê°„ TTLë¡œ ì¶©ë¶„ |
| Database ìš©ëŸ‰ ë¶€ì¡± | ë‚®ìŒ | ë†’ìŒ | ì‚¬ì „ ìš©ëŸ‰ ê³„íš (400MB) |

### 5.2 Rollback Plan

**Phase 1 ì‹¤íŒ¨ ì‹œ**:
- ê¸°ì¡´ KR ë§ˆì¼“ ìœ ì§€
- ì„¤ì • íŒŒì¼ë§Œ ì¶”ê°€ (ì˜í–¥ ì—†ìŒ)

**Phase 2 ì‹¤íŒ¨ ì‹œ**:
- ë¬¸ì œ ë§ˆì¼“ë§Œ ì œì™¸
- ë‹¤ë¥¸ ë§ˆì¼“ ì •ìƒ ìš´ì˜

**Phase 3 ì‹¤íŒ¨ ì‹œ**:
- ëª¨ë‹ˆí„°ë§ ì—†ì´ë„ ìš´ì˜ ê°€ëŠ¥
- ìˆ˜ë™ ê²€ì¦ìœ¼ë¡œ ëŒ€ì²´

---

## 6. ì„±ê³µ ì§€í‘œ (Success Metrics)

### 6.1 ì •ëŸ‰ì  ì§€í‘œ

| ì§€í‘œ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|------|------|-----------|
| í…ŒìŠ¤íŠ¸ ì»¤ë²„ë¦¬ì§€ | â‰¥95% | pytest --cov |
| E2E í…ŒìŠ¤íŠ¸ í†µê³¼ìœ¨ | â‰¥95% | pytest ê²°ê³¼ |
| Stage 0 í•„í„° ì •í™•ë„ | â‰¥99% | ìˆ˜ë™ ê²€ì¦ 100ìƒ˜í”Œ |
| Exchange rate ì •í™•ë„ | Â±0.5% | BOK ê³µì‹ í™˜ìœ¨ ëŒ€ì¡° |
| OHLCV ìˆ˜ì§‘ ì„±ê³µë¥  | â‰¥98% | Prometheus metrics |
| ë¬¸ì„œ ì™„ì „ì„± | â‰¥95% | ì²´í¬ë¦¬ìŠ¤íŠ¸ ê²€ì¦ |

### 6.2 ì •ì„±ì  ì§€í‘œ

- [ ] 5ê°œ ë§ˆì¼“ ëª¨ë‘ ë…ë¦½ì ìœ¼ë¡œ ìš´ì˜ ê°€ëŠ¥
- [ ] ì„¤ì • íŒŒì¼ë§Œ ìˆ˜ì •í•˜ì—¬ ìƒˆ ë§ˆì¼“ ì¶”ê°€ ê°€ëŠ¥
- [ ] ë¬¸ì œ ë§ˆì¼“ 1ê°œê°€ ì‹¤íŒ¨í•´ë„ ë‹¤ë¥¸ ë§ˆì¼“ ì˜í–¥ ì—†ìŒ
- [ ] Monitoring ëŒ€ì‹œë³´ë“œë¡œ ì‹¤ì‹œê°„ ìƒíƒœ íŒŒì•… ê°€ëŠ¥
- [ ] ìš´ì˜íŒ€ì´ ë¬¸ì„œë§Œìœ¼ë¡œ ë°°í¬/ê´€ë¦¬ ê°€ëŠ¥

---

## 7. ë‹¤ìŒ ë‹¨ê³„ (Next Steps)

### 7.1 ì¦‰ì‹œ ì‹œìž‘ ê°€ëŠ¥í•œ ìž‘ì—…

**Option A: Phase 1 ì‹œìž‘** (ê¶Œìž¥)
```bash
# Task 1.1: US ì„¤ì • íŒŒì¼ ìž‘ì„±
cd ~/spock
touch config/market_filters/us_filter_config.yaml
```

**Option B: í™˜ìœ¨ ì‹œìŠ¤í…œ ë¨¼ì €**
```bash
# Task 1.2: ExchangeRateManager êµ¬í˜„
touch modules/exchange_rate_manager.py
```

**Option C: Database ìŠ¤í‚¤ë§ˆ ë¨¼ì €**
```bash
# Task 1.4: Migration ìž‘ì„±
touch migrations/004_add_exchange_rate_history.py
```

### 7.2 ìŠ¹ì¸ í•„ìš” ì‚¬í•­

- [ ] ì´ 80ì‹œê°„ (2ì£¼) ê°œë°œ ì¼ì • ìŠ¹ì¸
- [ ] Database ìš©ëŸ‰ 400MB ì¦ì„¤ ìŠ¹ì¸
- [ ] KIS API ì‚¬ìš©ëŸ‰ 6ë°° ì¦ê°€ (5ê°œ ë§ˆì¼“) ìŠ¹ì¸
- [ ] Monitoring ì¸í”„ë¼ (Prometheus + Grafana) ìŠ¹ì¸

---

## 8. ê²°ë¡ 

### 8.1 í•µì‹¬ ìš”ì•½

**Goal**: KR ë§ˆì¼“ì˜ í•„í„°ë§ ì¡°ê±´ (24ì‹œê°„ ê±°ëž˜ëŒ€ê¸ˆ + 13ê°œì›” ì›”ë´‰)ì„ 5ê°œ í•´ì™¸ ë§ˆì¼“ì— ì ìš©

**Strategy**:
- âœ… í†µí™” ì •ê·œí™” (KRW ê¸°ì¤€)
- âœ… ë§ˆì¼“ë³„ ì„¤ì • íŒŒì¼ ë¶„ë¦¬
- âœ… 3-Phase ë‹¨ê³„ì  êµ¬í˜„

**Expected Outcome**:
- ðŸ“ˆ ìˆ˜ì§‘ ì¢…ëª© ìˆ˜: 250ê°œ â†’ 1,440ê°œ (+476%)
- ðŸŒ ê¸€ë¡œë²Œ ì»¤ë²„ë¦¬ì§€: 1ê°œêµ­ â†’ 6ê°œêµ­ (+500%)
- â±ï¸ íš¨ìœ¨ì„±: ì‹œê°„/ìš©ëŸ‰ 93% ì ˆê°

**Timeline**: 2ì£¼ (80ì‹œê°„, 3 phases)

**Risk**: ë‚®ìŒ (ë‹¨ê³„ì  êµ¬í˜„, ë…ë¦½ì  ë§ˆì¼“)

### 8.2 ê¶Œìž¥ ì‚¬í•­

**ì¦‰ì‹œ ì‹œìž‘**: Phase 1 (Foundation)
- ì„¤ì • íŒŒì¼ ìž‘ì„± (6ì‹œê°„)
- ExchangeRateManager êµ¬í˜„ (8ì‹œê°„)
- ë¹ ë¥¸ ì„±ê³¼ í™•ì¸ ê°€ëŠ¥

**ìŠ¹ì¸ í›„ ì§„í–‰**: Phase 2-3
- ì „ì²´ 80ì‹œê°„ ì¼ì • í™•ì •
- ë¦¬ì†ŒìŠ¤ í• ë‹¹ ì™„ë£Œ

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ìž‘ì„±ì¼**: 2025-10-16
**ìž‘ì„±ìž**: Spock Trading System
**ìƒíƒœ**: êµ¬í˜„ ì¤€ë¹„ ì™„ë£Œ

