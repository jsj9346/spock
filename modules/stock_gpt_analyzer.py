#!/usr/bin/env python3
"""
stock_gpt_analyzer.py - Phase 3 GPT ê¸°ë°˜ ì°¨íŠ¸ íŒ¨í„´ ë¶„ì„ê¸° (Spock - Global Stock Version)

ğŸ¯ í•µì‹¬ ê¸°ëŠ¥:
- VCP (Volatility Contraction Pattern) ê°ì§€ - ë§ˆí¬ ë¯¸ë„ˆë¹„ë‹ˆ ì „ëµ
- Cup & Handle íŒ¨í„´ ê°ì§€ - ìœŒë¦¬ì—„ ì˜¤ë‹ ì „ëµ
- Stage 2 Breakout ê²€ì¦ - ìŠ¤íƒ  ì™€ì¸ìŠ¤íƒ€ì¸ ì „ëµ (NEW for Spock)
- OpenAI GPT-5-mini API ì—°ë™ - ë¹„ìš© ìµœì í™” ($0.00015/1K tokens)
- ì§€ëŠ¥ì  ì„ íƒ ì‹¤í–‰ - LayeredScoringEngine 70ì  ì´ìƒë§Œ GPT ë¶„ì„
- 3ë‹¨ê³„ ìºì‹± ì‹œìŠ¤í…œ - ë©”ëª¨ë¦¬ â†’ DB(72ì‹œê°„) â†’ API í˜¸ì¶œ

ğŸ’° ë¹„ìš© ìµœì í™”:
- GPT-5-mini ì‚¬ìš©: ìµœì‹  ëª¨ë¸ë¡œ ë†’ì€ ë¶„ì„ í’ˆì§ˆ í™•ë³´
- ì¼ì¼ ì˜ˆì‚° $0.50 ì œí•œ: ì›” $15 ì´í•˜ ìš´ì˜
- ì§€ëŠ¥ì  í•„í„°ë§: ê³ í’ˆì§ˆ í›„ë³´ë§Œ ì„ ë³„ (LayeredScoringEngine â‰¥70)
- ìºì‹± ì „ëµ: ì¤‘ë³µ ë¶„ì„ ë°©ì§€

ğŸŒ Global Stock Support:
- Markets: KR (KOSPI/KOSDAQ), US (NYSE/NASDAQ/AMEX), CN (SSE/SZSE), HK (HKEX), JP (TSE), VN (HOSE/HNX)
- Unified database: data/spock_local.db
- Region-aware analysis with Stage 2 validation

ğŸ“Š Phase 3 ìœ„ì¹˜:
Phase 2 (LayeredScoringEngine) â†’ Phase 3 (StockGPTAnalyzer) â†’ Phase 4 (kelly_calculator)
"""

import os
import sys
import sqlite3
import pandas as pd
import numpy as np
import json
import time
from datetime import datetime, timedelta
from typing import Optional, Dict, List, Any, Tuple
from dataclasses import dataclass, asdict
from enum import Enum
import logging
import openai
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class PatternType(Enum):
    """ì°¨íŠ¸ íŒ¨í„´ íƒ€ì…"""
    VCP = "vcp"
    CUP_HANDLE = "cup_handle"
    BOTH = "both"
    NONE = "none"

class GPTRecommendation(Enum):
    """GPT ì¶”ì²œ ë“±ê¸‰"""
    STRONG_BUY = "STRONG_BUY"
    BUY = "BUY"
    HOLD = "HOLD"
    AVOID = "AVOID"

@dataclass
class VCPAnalysis:
    """VCP íŒ¨í„´ ë¶„ì„ ê²°ê³¼"""
    detected: bool
    confidence: float  # 0.0-1.0
    stage: int  # 1-4 ìˆ˜ì¶• ë‹¨ê³„
    volatility_ratio: float  # ë³€ë™ì„± ìˆ˜ì¶• ë¹„ìœ¨
    reasoning: str

@dataclass
class CupHandleAnalysis:
    """Cup & Handle íŒ¨í„´ ë¶„ì„ ê²°ê³¼"""
    detected: bool
    confidence: float  # 0.0-1.0
    cup_depth_ratio: float  # ì»µ ê¹Šì´ ë¹„ìœ¨
    handle_duration_days: int  # í•¸ë“¤ ì§€ì† ì¼ìˆ˜
    reasoning: str

@dataclass
class Stage2Analysis:
    """Stage 2 Breakout Validation Result (Weinstein Theory)

    Stage 2 characteristics:
    - MA alignment: MA5 > MA20 > MA60 > MA120 > MA200
    - Volume surge: Current volume > 1.5Ã— average
    - Price position: Within 10% of 52-week high
    - Trend confirmation: Price above all major MAs

    Reference: Stan Weinstein's "Secrets for Profiting in Bull and Bear Markets"
    """
    confirmed: bool
    confidence: float  # 0.0-1.0
    ma_alignment: bool  # MA5 > MA20 > MA60 > MA120
    volume_surge: bool  # Volume > 1.5x average (20-day)
    reasoning: str

@dataclass
class GPTAnalysisResult:
    """GPT ë¶„ì„ ì¢…í•© ê²°ê³¼ (Spock - Global Stock Version)

    New fields for stock trading:
    - stage2_analysis: Weinstein Stage 2 breakout validation
    - position_adjustment: Kelly Calculator multiplier (0.5-1.5)
    """
    ticker: str
    analysis_date: str
    vcp_analysis: VCPAnalysis
    cup_handle_analysis: CupHandleAnalysis
    stage2_analysis: Stage2Analysis  # NEW: Stage 2 Breakout validation
    recommendation: GPTRecommendation
    confidence: float
    reasoning: str
    position_adjustment: float  # NEW: 0.5-1.5 Kelly multiplier
    api_cost_usd: float
    processing_time_ms: int

class CostManager:
    """GPT API ë¹„ìš© ê´€ë¦¬"""

    def __init__(self, daily_limit: float = 0.50, db_path: str = "./data/spock_local.db"):
        self.daily_limit = daily_limit  # $0.50/ì¼ ì œí•œ
        self.db_path = db_path
        self.gpt_5_mini_cost_per_1k = 0.00015  # GPT-5-mini: $0.00015/1K tokens

    def estimate_cost(self, text_length: int) -> float:
        """ë¶„ì„ ë¹„ìš© ì¶”ì •"""
        # ì˜ì–´/í•œê¸€ í˜¼í•© í…ìŠ¤íŠ¸, í‰ê·  2.5 tokensë¡œ ê³„ì‚°
        tokens = text_length * 2.5
        input_cost = (tokens / 1000) * self.gpt_5_mini_cost_per_1k

        # ì‘ë‹µ í† í°ë„ ê³ ë ¤ (ë³´í†µ ì…ë ¥ì˜ 20% ì •ë„)
        output_tokens = tokens * 0.2
        output_cost = (output_tokens / 1000) * self.gpt_5_mini_cost_per_1k

        total_cost = input_cost + output_cost
        logger.debug(f"ğŸ’° ë¹„ìš© ì¶”ì •: {tokens}í† í° â†’ ${total_cost:.6f}")
        return total_cost

    def get_daily_usage(self) -> float:
        """ì˜¤ëŠ˜ ì‚¬ìš©í•œ ë¹„ìš© ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            today = datetime.now().strftime('%Y-%m-%d')
            cursor.execute("""
                SELECT COALESCE(SUM(api_cost_usd), 0)
                FROM gpt_analysis
                WHERE DATE(created_at) = ?
            """, (today,))

            daily_usage = cursor.fetchone()[0]
            conn.close()

            logger.info(f"ğŸ’° ì˜¤ëŠ˜ GPT ì‚¬ìš© ë¹„ìš©: ${daily_usage:.4f} / ${self.daily_limit:.2f}")
            return daily_usage

        except Exception as e:
            logger.error(f"âŒ ì¼ì¼ ì‚¬ìš©ëŸ‰ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return 0.0

    def check_daily_budget(self, estimated_cost: float = 0.0) -> bool:
        """ì¼ì¼ ì˜ˆì‚° í™•ì¸"""
        daily_usage = self.get_daily_usage()
        remaining = self.daily_limit - daily_usage

        if estimated_cost > remaining:
            logger.warning(f"âš ï¸ ì˜ˆì‚° ì´ˆê³¼: í•„ìš” ${estimated_cost:.4f} > ë‚¨ì€ ì˜ˆì‚° ${remaining:.4f}")
            return False

        return True

    def should_use_gpt(self, ticker: str, technical_score: float, text_length: int = 2000) -> bool:
        """GPT ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        # 1. ê¸°ìˆ ì  ì ìˆ˜ í™•ì¸ (15ì  ì´ìƒë§Œ)
        if technical_score < 15.0:
            logger.info(f"ğŸ“Š {ticker}: ê¸°ìˆ ì  ì ìˆ˜ {technical_score:.1f}ì  â†’ GPT ìŠ¤í‚µ")
            return False

        # 2. ë¹„ìš© í™•ì¸
        estimated_cost = self.estimate_cost(text_length)
        if not self.check_daily_budget(estimated_cost):
            logger.warning(f"ğŸ’° {ticker}: ì˜ˆì‚° ë¶€ì¡± â†’ GPT ìŠ¤í‚µ")
            return False

        logger.info(f"âœ… {ticker}: ì ìˆ˜ {technical_score:.1f}ì , ë¹„ìš© ${estimated_cost:.4f} â†’ GPT ë¶„ì„ ì§„í–‰")
        return True

class CacheManager:
    """ë¶„ì„ ê²°ê³¼ ìºì‹± ê´€ë¦¬"""

    def __init__(self, db_path: str = "./data/spock_local.db"):
        self.db_path = db_path
        self.memory_cache = {}  # ë©”ëª¨ë¦¬ ìºì‹œ
        self.db_cache_hours = 72  # DB ìºì‹œ 72ì‹œê°„ (3ì¼)

    def get_cache_key(self, ticker: str, date: str) -> str:
        """ìºì‹œ í‚¤ ìƒì„±"""
        return f"{ticker}_{date}"

    def is_cache_valid(self, cached_date: str, max_age_hours: int) -> bool:
        """ìºì‹œ ìœ íš¨ì„± í™•ì¸"""
        try:
            cached_time = datetime.fromisoformat(cached_date.replace('Z', '+00:00'))
            current_time = datetime.now()
            age_hours = (current_time - cached_time).total_seconds() / 3600

            return age_hours <= max_age_hours
        except Exception:
            return False

    def get_cached_analysis(self, ticker: str, max_age_hours: int = 72) -> Optional[GPTAnalysisResult]:
        """ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ"""
        try:
            # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
            today = datetime.now().strftime('%Y-%m-%d')
            cache_key = self.get_cache_key(ticker, today)

            if cache_key in self.memory_cache:
                logger.info(f"ğŸš€ {ticker}: ë©”ëª¨ë¦¬ ìºì‹œ íˆíŠ¸ (ì¦‰ì‹œ ë°˜í™˜, ë¹„ìš© ì ˆì•½)")
                return self.memory_cache[cache_key]

            # 2. DB ìºì‹œ í™•ì¸ - 3ì¼(72ì‹œê°„) ì´ë‚´ ë°ì´í„° ê²€ìƒ‰ìœ¼ë¡œ ë³€ê²½
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # 72ì‹œê°„(3ì¼) ì´ë‚´ ë°ì´í„°ë§Œ ê²€ìƒ‰
            cutoff_time = datetime.now() - timedelta(hours=max_age_hours)
            cutoff_str = cutoff_time.strftime('%Y-%m-%d %H:%M:%S')

            cursor.execute("""
                SELECT * FROM gpt_analysis
                WHERE ticker = ? AND created_at >= ?
                ORDER BY created_at DESC LIMIT 1
            """, (ticker, cutoff_str))

            row = cursor.fetchone()
            conn.close()

            if row:
                cached_time = datetime.fromisoformat(row[16])  # created_at ì»¬ëŸ¼ (ì¸ë±ìŠ¤ 16)
                age_hours = (datetime.now() - cached_time).total_seconds() / 3600
                logger.info(f"ğŸ’¾ {ticker}: DB ìºì‹œ íˆíŠ¸ (ìƒì„±: {age_hours:.1f}ì‹œê°„ ì „, ìœ íš¨ê¸°ê°„: {max_age_hours}ì‹œê°„)")
                result = self._row_to_result(row)
                self.memory_cache[cache_key] = result  # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                return result

            logger.debug(f"ğŸ” {ticker}: ìºì‹œ ì—†ìŒ, ìƒˆë¡œìš´ ë¶„ì„ í•„ìš”")
            return None

        except Exception as e:
            logger.error(f"âŒ {ticker} ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return None

    def save_to_cache(self, result: GPTAnalysisResult):
        """ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥"""
        cache_key = self.get_cache_key(result.ticker, result.analysis_date)
        self.memory_cache[cache_key] = result
        logger.debug(f"ğŸ’¾ {result.ticker}: ë©”ëª¨ë¦¬ ìºì‹œ ì €ì¥")

    def _row_to_result(self, row) -> GPTAnalysisResult:
        """DB rowë¥¼ GPTAnalysisResultë¡œ ë³€í™˜ (Spock - Global Stock Version)"""
        # DB ìŠ¤í‚¤ë§ˆì— ë§ì¶° íŒŒì‹± (ì‹¤ì œ í…Œì´ë¸” êµ¬ì¡° ê¸°ì¤€)
        vcp = VCPAnalysis(
            detected=bool(row[3]),   # vcp_detected
            confidence=row[4],       # vcp_confidence
            stage=row[5],           # vcp_stage
            volatility_ratio=row[6] or 0.0,  # vcp_volatility_ratio
            reasoning="DBì—ì„œ ë¡œë“œ"  # vcp_reasoning ì»¬ëŸ¼ì´ ì—†ìŒ
        )

        cup_handle = CupHandleAnalysis(
            detected=bool(row[7]),   # cup_handle_detected
            confidence=row[8],       # cup_handle_confidence
            cup_depth_ratio=row[9] or 0.0,     # cup_depth_ratio
            handle_duration_days=row[10] or 0,  # handle_duration_days
            reasoning="DBì—ì„œ ë¡œë“œ"   # cup_handle_reasoning ì»¬ëŸ¼ì´ ì—†ìŒ
        )

        # NEW: Stage 2 Analysis (Weinstein Theory) - indices 16-20
        # Note: These columns will be added in database migration (Task 1.3)
        # For now, provide default values to maintain backward compatibility
        try:
            stage2 = Stage2Analysis(
                confirmed=bool(row[16]) if len(row) > 16 else False,       # stage2_confirmed
                confidence=row[17] if len(row) > 17 else 0.0,              # stage2_confidence
                ma_alignment=bool(row[18]) if len(row) > 18 else False,    # stage2_ma_alignment
                volume_surge=bool(row[19]) if len(row) > 19 else False,    # stage2_volume_surge
                reasoning=row[20] if len(row) > 20 else "DB migration pending"  # stage2_reasoning
            )
            position_adj = row[21] if len(row) > 21 else 1.0  # position_adjustment
        except (IndexError, TypeError):
            # Backward compatibility: Old database schema without Stage 2 columns
            stage2 = Stage2Analysis(
                confirmed=False,
                confidence=0.0,
                ma_alignment=False,
                volume_surge=False,
                reasoning="DB migration pending"
            )
            position_adj = 1.0

        return GPTAnalysisResult(
            ticker=row[1],           # ticker
            analysis_date=row[2],    # analysis_date
            vcp_analysis=vcp,
            cup_handle_analysis=cup_handle,
            stage2_analysis=stage2,  # NEW
            recommendation=GPTRecommendation(row[11]),  # gpt_recommendation
            confidence=row[12],      # gpt_confidence
            reasoning=row[13] or "", # gpt_reasoning
            position_adjustment=position_adj,  # NEW
            api_cost_usd=row[14] or 0.0,       # api_cost_usd
            processing_time_ms=row[15] or 0    # processing_time_ms
        )

class StockGPTAnalyzer:
    """
    OpenAI GPT-5-mini ê¸°ë°˜ ì°¨íŠ¸ íŒ¨í„´ ë¶„ì„ê¸° (Spock - Global Stock Version)

    Supports: KR, US, CN, HK, JP, VN stock markets
    Database: data/spock_local.db
    """

    def __init__(self,
                 db_path: str = "./data/spock_local.db",
                 api_key: str = None,
                 enable_gpt: bool = True,
                 daily_cost_limit: float = 0.50):

        self.db_path = db_path
        self.enable_gpt = enable_gpt
        self.cost_manager = CostManager(daily_cost_limit, db_path)
        self.cache_manager = CacheManager(db_path)

        # OpenAI API ì„¤ì • (.env íŒŒì¼ì—ì„œ í‚¤ ë¡œë“œ)
        self.openai_client = None
        if api_key:
            self.openai_client = openai.OpenAI(api_key=api_key)
        elif os.getenv('OPENAI_API_KEY'):
            self.openai_client = openai.OpenAI(api_key=os.getenv('OPENAI_API_KEY'))
            logger.info("âœ… .env íŒŒì¼ì—ì„œ OpenAI API í‚¤ ë¡œë“œ ì™„ë£Œ")
        else:
            logger.warning("âš ï¸ OpenAI API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. GPT ë¶„ì„ì´ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.")
            logger.info("ğŸ’¡ .env íŒŒì¼ì— OPENAI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
            self.enable_gpt = False

        self.init_database()
        logger.info("ğŸ¤– StockGPTAnalyzer ì´ˆê¸°í™” ì™„ë£Œ (Global Stock Support)")

    def init_database(self):
        """gpt_analysis í…Œì´ë¸” ìƒì„±"""
        try:
            # DB ë½ ë°©ì§€ë¥¼ ìœ„í•´ íƒ€ì„ì•„ì›ƒ ì„¤ì •
            conn = sqlite3.connect(self.db_path, timeout=30.0)
            cursor = conn.cursor()

            create_table_sql = """
            CREATE TABLE IF NOT EXISTS gpt_analysis (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                ticker TEXT NOT NULL,
                analysis_date TEXT NOT NULL,

                -- VCP íŒ¨í„´ ë¶„ì„
                vcp_detected BOOLEAN DEFAULT 0,
                vcp_confidence REAL DEFAULT 0.0,
                vcp_stage INTEGER DEFAULT 0,
                vcp_volatility_ratio REAL DEFAULT 0.0,
                vcp_reasoning TEXT DEFAULT '',

                -- Cup & Handle íŒ¨í„´ ë¶„ì„
                cup_handle_detected BOOLEAN DEFAULT 0,
                cup_handle_confidence REAL DEFAULT 0.0,
                cup_depth_ratio REAL DEFAULT 0.0,
                handle_duration_days INTEGER DEFAULT 0,
                cup_handle_reasoning TEXT DEFAULT '',

                -- GPT ì¢…í•© ë¶„ì„
                gpt_recommendation TEXT DEFAULT 'HOLD',
                gpt_confidence REAL DEFAULT 0.0,
                gpt_reasoning TEXT DEFAULT '',
                api_cost_usd REAL DEFAULT 0.0,
                processing_time_ms INTEGER DEFAULT 0,
                created_at TEXT DEFAULT (datetime('now')),

                UNIQUE(ticker, analysis_date)
            );
            """

            cursor.execute(create_table_sql)

            # ì¸ë±ìŠ¤ ìƒì„±
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_gpt_analysis_ticker ON gpt_analysis(ticker);")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_gpt_analysis_date ON gpt_analysis(analysis_date);")

            conn.commit()
            conn.close()

            logger.info("âœ… gpt_analysis í…Œì´ë¸” ì´ˆê¸°í™” ì™„ë£Œ")

        except Exception as e:
            logger.warning(f"âš ï¸ gpt_analysis í…Œì´ë¸” ìƒì„± ìŠ¤í‚µ: {e}")
            # í…Œì´ë¸” ìƒì„± ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰ (ë‹¤ë¥¸ í”„ë¡œì„¸ìŠ¤ì—ì„œ ì´ë¯¸ ìƒì„±í–ˆì„ ìˆ˜ ìˆìŒ)

    def analyze_candidates(self, stage2_candidates: List[Dict]) -> List[Dict]:
        """Stage 2 í›„ë³´ë“¤ì— ëŒ€í•œ GPT íŒ¨í„´ ë¶„ì„"""
        logger.info(f"ğŸ¯ GPT íŒ¨í„´ ë¶„ì„ ì‹œì‘: {len(stage2_candidates)}ê°œ í›„ë³´")

        enhanced_results = []
        gpt_analyzed_count = 0

        for candidate in stage2_candidates:
            ticker = candidate['ticker']
            quality_score = candidate.get('quality_score', 0)

            try:
                # 1. ìºì‹œ í™•ì¸
                cached_result = self.cache_manager.get_cached_analysis(ticker)
                if cached_result:
                    candidate['gpt_analysis'] = cached_result
                    candidate['final_score'] = self._calculate_enhanced_score(candidate, cached_result)
                    enhanced_results.append(candidate)
                    continue

                # 2. GPT ë¶„ì„ ì—¬ë¶€ ê²°ì •
                if not self.enable_gpt or not self.cost_manager.should_use_gpt(ticker, quality_score):
                    candidate['gpt_analysis'] = None
                    candidate['final_score'] = quality_score  # ê¸°ì¡´ ì ìˆ˜ ìœ ì§€
                    enhanced_results.append(candidate)
                    continue

                # 3. GPT ë¶„ì„ ì‹¤í–‰
                gpt_result = self.analyze_ticker(ticker)
                if gpt_result:
                    candidate['gpt_analysis'] = gpt_result
                    candidate['final_score'] = self._calculate_enhanced_score(candidate, gpt_result)
                    gpt_analyzed_count += 1
                else:
                    candidate['gpt_analysis'] = None
                    candidate['final_score'] = quality_score

                enhanced_results.append(candidate)

            except Exception as e:
                logger.error(f"âŒ {ticker} GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
                candidate['gpt_analysis'] = None
                candidate['final_score'] = quality_score
                enhanced_results.append(candidate)

        logger.info(f"âœ… GPT ë¶„ì„ ì™„ë£Œ: {gpt_analyzed_count}ê°œ ì¢…ëª© ë¶„ì„")
        return enhanced_results

    def analyze_ticker(self, ticker: str) -> Optional[GPTAnalysisResult]:
        """ê°œë³„ ì¢…ëª© GPT íŒ¨í„´ ë¶„ì„"""
        start_time = time.time()

        try:
            # 1. ìºì‹œ í™•ì¸ (ì¤‘ìš”: API í˜¸ì¶œ ì „ ë°˜ë“œì‹œ í™•ì¸)
            cached_result = self.cache_manager.get_cached_analysis(ticker)
            if cached_result:
                logger.info(f"ğŸš€ {ticker}: ìºì‹œ íˆíŠ¸! API í˜¸ì¶œ ê±´ë„ˆë›°ê¸° (ë¹„ìš© ì ˆì•½)")
                return cached_result

            # 2. OHLCV ë°ì´í„° ë¡œë“œ
            df = self._get_ohlcv_data(ticker)
            if df.empty:
                logger.warning(f"ğŸ“Š {ticker}: ë°ì´í„° ì—†ìŒ")
                return None

            # 2. ì°¨íŠ¸ ë°ì´í„° í…ìŠ¤íŠ¸ ë³€í™˜
            chart_text = self._prepare_chart_data_for_gpt(df)

            # 3. OpenAI API í˜¸ì¶œ (NEW: Stage 2 analysis included)
            vcp_analysis, cup_handle_analysis, stage2_analysis, recommendation, confidence, reasoning, position_adjustment, cost = self._call_openai_api(chart_text, ticker)

            # 4. ê²°ê³¼ ìƒì„± (NEW: Stage 2 and position_adjustment fields)
            processing_time = int((time.time() - start_time) * 1000)

            result = GPTAnalysisResult(
                ticker=ticker,
                analysis_date=datetime.now().strftime('%Y-%m-%d'),
                vcp_analysis=vcp_analysis,
                cup_handle_analysis=cup_handle_analysis,
                stage2_analysis=stage2_analysis,  # NEW
                recommendation=recommendation,
                confidence=confidence,
                reasoning=reasoning,
                position_adjustment=position_adjustment,  # NEW
                api_cost_usd=cost,
                processing_time_ms=processing_time
            )

            # 5. ì €ì¥ ë° ìºì‹±
            self._save_analysis_result(result)
            self.cache_manager.save_to_cache(result)

            logger.info(f"âœ… {ticker}: GPT ë¶„ì„ ì™„ë£Œ (${cost:.4f}, {processing_time}ms) â†’ 3ì¼ ìºì‹œ ì €ì¥")
            return result

        except Exception as e:
            logger.error(f"âŒ {ticker} GPT ë¶„ì„ ì‹¤íŒ¨: {e}")
            return None

    def _get_ohlcv_data(self, ticker: str, days: int = 120) -> pd.DataFrame:
        """SQLiteì—ì„œ OHLCV ë°ì´í„° ì¡°íšŒ"""
        try:
            conn = sqlite3.connect(self.db_path)

            query = """
            SELECT ticker, date, open, high, low, close, volume,
                   ma5, ma20, ma60, ma120, ma200, rsi_14 as rsi
            FROM ohlcv_data
            WHERE ticker = ?
            ORDER BY date DESC
            LIMIT ?
            """

            df = pd.read_sql_query(query, conn, params=(ticker, days))
            conn.close()

            if df.empty:
                return pd.DataFrame()

            # ë‚ ì§œ ìˆœìœ¼ë¡œ ì •ë ¬ (ì˜¤ë˜ëœ ê²ƒë¶€í„°)
            df = df.sort_values('date').reset_index(drop=True)
            df['date'] = pd.to_datetime(df['date'])

            return df

        except Exception as e:
            logger.error(f"âŒ {ticker} ë°ì´í„° ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return pd.DataFrame()

    def _prepare_chart_data_for_gpt(self, df: pd.DataFrame) -> str:
        """Convert chart data to text format for GPT analysis (Enhanced for Stage 2)"""
        if df.empty:
            return ""

        ticker = df['ticker'].iloc[0]

        # Use only recent 60 days data (token optimization)
        recent_df = df.tail(60)

        # Calculate key statistics
        current_price = recent_df['close'].iloc[-1]

        # NEW: MA5, MA120 added for Stage 2 analysis
        ma5 = recent_df['ma5'].iloc[-1] if 'ma5' in recent_df.columns and pd.notna(recent_df['ma5'].iloc[-1]) else 0
        ma20 = recent_df['ma20'].iloc[-1] if pd.notna(recent_df['ma20'].iloc[-1]) else 0
        ma60 = recent_df['ma60'].iloc[-1] if pd.notna(recent_df['ma60'].iloc[-1]) else 0
        ma120 = recent_df['ma120'].iloc[-1] if 'ma120' in recent_df.columns and pd.notna(recent_df['ma120'].iloc[-1]) else 0

        # NEW: 20-day volume average for Stage 2
        volume_recent = recent_df['volume'].iloc[-1]
        volume_avg_60d = recent_df['volume'].mean()
        volume_avg_20d = recent_df['volume'].tail(20).mean()

        # NEW: Stage 2 Breakout Indicators
        # MA Alignment Check (MA5 > MA20 > MA60 > MA120)
        ma_alignment = False
        if ma5 > 0 and ma20 > 0 and ma60 > 0 and ma120 > 0:
            ma_alignment = (ma5 > ma20 > ma60 > ma120)

        # Volume Surge Check (current > 1.5x 20-day average)
        volume_surge = (volume_recent > 1.5 * volume_avg_20d) if volume_avg_20d > 0 else False

        # Price volatility analysis
        price_changes = recent_df['close'].pct_change().dropna()
        volatility = price_changes.std() * 100

        # High/Low analysis
        high_30d = recent_df['high'].tail(30).max()
        low_30d = recent_df['low'].tail(30).min()
        current_vs_high = ((current_price - high_30d) / high_30d) * 100
        current_vs_low = ((current_price - low_30d) / low_30d) * 100

        # Safe percentage calculation
        ma5_pct = ((current_price-ma5)/ma5)*100 if ma5 > 0 else 0
        ma20_pct = ((current_price-ma20)/ma20)*100 if ma20 > 0 else 0
        ma60_pct = ((current_price-ma60)/ma60)*100 if ma60 > 0 else 0
        ma120_pct = ((current_price-ma120)/ma120)*100 if ma120 > 0 else 0

        chart_text = f"""
{ticker} Global Stock Chart Analysis (Recent 60 Days):

Price Information:
- Current Price: {current_price:,.0f} (currency unit)
- MA5: {ma5:,.0f} ({ma5_pct:+.1f}%)
- MA20: {ma20:,.0f} ({ma20_pct:+.1f}%)
- MA60: {ma60:,.0f} ({ma60_pct:+.1f}%)
- MA120: {ma120:,.0f} ({ma120_pct:+.1f}%)
- 30-Day High: {high_30d:,.0f} ({current_vs_high:+.1f}%)
- 30-Day Low: {low_30d:,.0f} ({current_vs_low:+.1f}%)

Volume Analysis (Enhanced for Stage 2):
- Current Volume: {volume_recent:,.0f}
- 20-Day Average: {volume_avg_20d:,.0f}
- 60-Day Average: {volume_avg_60d:,.0f}
- Volume Ratio (vs 20d avg): {volume_recent/volume_avg_20d:.2f}x
- Volume Surge Detected: {'YES' if volume_surge else 'NO'} (>1.5x threshold)

Stage 2 Breakout Indicators (Weinstein Theory):
- MA Alignment (MA5>MA20>MA60>MA120): {'YES' if ma_alignment else 'NO'}
- Volume Surge (>1.5x 20d avg): {'YES' if volume_surge else 'NO'}
- Price Near 30d High: {current_vs_high:+.1f}%

Volatility:
- Daily Volatility: {volatility:.1f}%

Recent 20-Day Price Movement:
"""

        # Add recent 20 days price data (enhanced with 20d avg volume ratio)
        recent_20 = recent_df.tail(20).reset_index(drop=True)
        for i, row in recent_20.iterrows():
            date = row['date'].strftime('%m/%d')
            close = row['close']
            # Use 20-day average for more accurate volume ratio
            volume_ratio_20d = row['volume'] / volume_avg_20d if volume_avg_20d > 0 else 0
            change = ((close - recent_20['close'].iloc[i-1]) / recent_20['close'].iloc[i-1] * 100) if i > 0 else 0

            chart_text += f"{date}: {close:,.0f} ({change:+.1f}%) Vol:{volume_ratio_20d:.2f}x\n"

        return chart_text

    def _call_openai_api(self, chart_text: str, ticker: str, max_retries: int = 2) -> Tuple[VCPAnalysis, CupHandleAnalysis, Stage2Analysis, GPTRecommendation, float, str, float, float]:
        """OpenAI API í˜¸ì¶œ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)"""

        last_exception = None
        for attempt in range(max_retries):
            try:
                logger.debug(f"ğŸ”„ {ticker} API í˜¸ì¶œ ì‹œë„ {attempt + 1}/{max_retries}")

                # ë¹„ìš© ê³„ì‚°
                estimated_cost = self.cost_manager.estimate_cost(len(chart_text))

                # Enhanced prompt with stronger JSON enforcement
                prompt = f"""
Analyze this global stock market chart data and respond ONLY with valid JSON:

{chart_text}

Required analysis:
1. VCP Pattern (Mark Minervini's Volatility Contraction Pattern)
2. Cup & Handle Pattern (William O'Neil's breakout pattern)
3. Stage 2 Breakout (Stan Weinstein's uptrend confirmation)

CRITICAL: Respond with ONLY this JSON structure (no other text):

{{
"vcp": {{"detected": true, "confidence": 0.75, "stage": 3, "volatility_ratio": 0.15, "reasoning": "Brief VCP analysis"}},
"cup_handle": {{"detected": false, "confidence": 0.3, "cup_depth_ratio": 0.0, "handle_duration_days": 0, "reasoning": "Brief Cup analysis"}},
"stage2": {{"confirmed": true, "confidence": 0.85, "ma_alignment": true, "volume_surge": true, "reasoning": "Brief Stage 2 analysis"}},
"overall": {{"recommendation": "BUY", "confidence": 0.8, "position_adjustment": 1.2, "reasoning": "Brief overall analysis"}}
}}

Requirements:
VCP Pattern:
- detected: boolean (true/false)
- confidence: float (0.0-1.0)
- stage: integer (1-4, contraction stage)
- volatility_ratio: float (0.0-1.0, 10d/30d volatility)
- reasoning: string (under 100 chars)

Cup & Handle Pattern:
- detected: boolean (true/false)
- confidence: float (0.0-1.0)
- cup_depth_ratio: float (0.0-1.0, depth as % of high)
- handle_duration_days: integer (0+)
- reasoning: string (under 100 chars)

Stage 2 Breakout (Weinstein Theory):
- confirmed: boolean (true/false, uptrend breakout)
- confidence: float (0.0-1.0)
- ma_alignment: boolean (MA5 > MA20 > MA60 > MA120)
- volume_surge: boolean (volume > 1.5x average)
- reasoning: string (under 100 chars)

Overall Assessment:
- recommendation: "STRONG_BUY", "BUY", "HOLD", or "AVOID"
- confidence: float (0.0-1.0)
- position_adjustment: float (0.5-1.5, Kelly multiplier for position sizing)
- reasoning: string (under 150 chars)

Position Adjustment Guidelines:
- 0.5-0.7: Weak patterns, reduce position
- 0.8-1.0: Average patterns, maintain position
- 1.1-1.3: Strong patterns, increase position
- 1.4-1.5: Exceptional patterns, maximum confidence

RESPOND ONLY WITH VALID JSON. NO OTHER TEXT.
"""

                # OpenAI API í˜¸ì¶œ (ìƒˆë¡œìš´ API í˜•ì‹)
                if not self.openai_client:
                    raise Exception("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

                response = self.openai_client.chat.completions.create(
                    model="gpt-5-mini",  # GPT-5-mini ì‚¬ìš©
                    messages=[
                        {"role": "system", "content": "You are a professional global stock market technical analyst specializing in Mark Minervini's VCP patterns, William O'Neil's Cup & Handle patterns, and Stan Weinstein's Stage 2 theory. You must respond ONLY in the specified JSON format. Do not include any other text or explanations. Ensure exact JSON format compliance to prevent parsing errors."},
                        {"role": "user", "content": prompt}
                    ],
                    max_completion_tokens=1200,  # Increased for Stage 2 analysis
                    # temperature íŒŒë¼ë¯¸í„° ì œê±° - gpt-5-miniì—ì„œ ì§€ì›í•˜ì§€ ì•ŠìŒ (ê¸°ë³¸ê°’ 1 ì‚¬ìš©)
                )

                # ì‘ë‹µ íŒŒì‹± (JSON ì •í˜•í™” ì²˜ë¦¬)
                response_text = response.choices[0].message.content.strip()

                # ì‘ë‹µ ìƒì„¸ ë””ë²„ê¹…
                logger.debug(f"ğŸ” {ticker} ì›ë³¸ ì‘ë‹µ ê¸¸ì´: {len(response_text)}")
                if len(response_text) == 0:
                    logger.error(f"âŒ {ticker} ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")
                    raise Exception("ë¹ˆ ì‘ë‹µ ìˆ˜ì‹ ")

                # JSON ì¶”ì¶œ (```json ``` ë¸”ë¡ì´ ìˆì„ ê²½ìš° ì²˜ë¦¬)
                if "```json" in response_text:
                    start = response_text.find("```json") + 7
                    end = response_text.find("```", start)
                    if end != -1:
                        response_text = response_text[start:end].strip()
                        logger.debug(f"ğŸ” {ticker} JSON ë¸”ë¡ ì¶”ì¶œ ì™„ë£Œ")
                elif "```" in response_text:
                    start = response_text.find("```") + 3
                    end = response_text.find("```", start)
                    if end != -1:
                        response_text = response_text[start:end].strip()
                        logger.debug(f"ğŸ” {ticker} ì½”ë“œ ë¸”ë¡ ì¶”ì¶œ ì™„ë£Œ")

                # JSON íŒŒì‹± ì „ ìµœì¢… ê²€ì¦
                if not response_text or not response_text.strip():
                    logger.error(f"âŒ {ticker} ì¶”ì¶œëœ JSON í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")
                    raise Exception("ì¶”ì¶œëœ JSON í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŒ")

                try:
                    analysis_data = json.loads(response_text)
                    logger.debug(f"âœ… {ticker} JSON íŒŒì‹± ì„±ê³µ")
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ {ticker} JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    logger.error(f"ì‘ë‹µ ì „ì²´ ë‚´ìš© ({len(response_text)}ì): {repr(response_text)}")
                    logger.error(f"ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {response_text[:500]}...")
                    raise Exception(f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}")

                # VCP ë¶„ì„ ê²°ê³¼ (íƒ€ì… ê²€ì¦ ë° ê¸°ë³¸ê°’ ì²˜ë¦¬)
                vcp_data = analysis_data.get('vcp', {})
                vcp_analysis = VCPAnalysis(
                    detected=bool(vcp_data.get('detected', False)),
                    confidence=float(vcp_data.get('confidence', 0.0)),
                    stage=int(vcp_data.get('stage', 0)),
                    volatility_ratio=float(vcp_data.get('volatility_ratio', 0.0)),
                    reasoning=str(vcp_data.get('reasoning', 'íŒ¨í„´ ê°ì§€ë˜ì§€ ì•ŠìŒ'))
                )

                # Cup & Handle ë¶„ì„ ê²°ê³¼ (íƒ€ì… ê²€ì¦ ë° ê¸°ë³¸ê°’ ì²˜ë¦¬)
                cup_data = analysis_data.get('cup_handle', {})
                cup_handle_analysis = CupHandleAnalysis(
                    detected=bool(cup_data.get('detected', False)),
                    confidence=float(cup_data.get('confidence', 0.0)),
                    cup_depth_ratio=float(cup_data.get('cup_depth_ratio', 0.0)),
                    handle_duration_days=int(cup_data.get('handle_duration_days', 0)),
                    reasoning=str(cup_data.get('reasoning', 'íŒ¨í„´ ê°ì§€ë˜ì§€ ì•ŠìŒ'))
                )

                # NEW: Stage 2 Breakout ë¶„ì„ ê²°ê³¼ (Weinstein Theory)
                stage2_data = analysis_data.get('stage2', {})
                stage2_analysis = Stage2Analysis(
                    confirmed=bool(stage2_data.get('confirmed', False)),
                    confidence=float(stage2_data.get('confidence', 0.0)),
                    ma_alignment=bool(stage2_data.get('ma_alignment', False)),
                    volume_surge=bool(stage2_data.get('volume_surge', False)),
                    reasoning=str(stage2_data.get('reasoning', 'íŒ¨í„´ ê°ì§€ë˜ì§€ ì•ŠìŒ'))
                )

                # ì¢…í•© ë¶„ì„ ê²°ê³¼ (íƒ€ì… ê²€ì¦ ë° ê¸°ë³¸ê°’ ì²˜ë¦¬)
                overall = analysis_data.get('overall', {})
                recommendation_str = overall.get('recommendation', 'HOLD')
                position_adjustment = float(overall.get('position_adjustment', 1.0))

                # ìœ íš¨í•œ ì¶”ì²œ ë“±ê¸‰ í™•ì¸
                valid_recommendations = ['STRONG_BUY', 'BUY', 'HOLD', 'AVOID']
                if recommendation_str not in valid_recommendations:
                    logger.warning(f"âš ï¸ {ticker}: ì˜ëª»ëœ ì¶”ì²œ ë“±ê¸‰ '{recommendation_str}' â†’ 'HOLD'ë¡œ ë³€ê²½")
                    recommendation_str = 'HOLD'

                recommendation = GPTRecommendation(recommendation_str)
                confidence = float(overall.get('confidence', 0.0))
                reasoning = str(overall.get('reasoning', 'ë¶„ì„ ê²°ê³¼ ì—†ìŒ'))

                # ê°’ ë²”ìœ„ ê²€ì¦
                vcp_analysis.confidence = max(0.0, min(1.0, vcp_analysis.confidence))
                vcp_analysis.stage = max(1, min(4, vcp_analysis.stage))
                vcp_analysis.volatility_ratio = max(0.0, min(1.0, vcp_analysis.volatility_ratio))

                cup_handle_analysis.confidence = max(0.0, min(1.0, cup_handle_analysis.confidence))
                cup_handle_analysis.cup_depth_ratio = max(0.0, min(1.0, cup_handle_analysis.cup_depth_ratio))
                cup_handle_analysis.handle_duration_days = max(0, cup_handle_analysis.handle_duration_days)

                # NEW: Stage 2 validation
                stage2_analysis.confidence = max(0.0, min(1.0, stage2_analysis.confidence))

                confidence = max(0.0, min(1.0, confidence))

                # NEW: Position adjustment validation (0.5-1.5 range)
                position_adjustment = max(0.5, min(1.5, position_adjustment))

                logger.info(f"ğŸ¤– {ticker}: GPT-5-mini ë¶„ì„ ì™„ë£Œ - {recommendation.value} ({confidence:.2f}) | Stage2: {stage2_analysis.confirmed} | Position: {position_adjustment:.2f}x")

                return vcp_analysis, cup_handle_analysis, stage2_analysis, recommendation, confidence, reasoning, position_adjustment, estimated_cost

            except Exception as e:
                last_exception = e
                logger.warning(f"âš ï¸ {ticker} API ì‹œë„ {attempt + 1} ì‹¤íŒ¨: {e}")

                if attempt == max_retries - 1:
                    # ëª¨ë“  ì‹œë„ ì‹¤íŒ¨
                    logger.error(f"âŒ {ticker} ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨: {last_exception}")

                    # ê¸°ë³¸ê°’ ë°˜í™˜ (Stage 2 í¬í•¨)
                    vcp_analysis = VCPAnalysis(False, 0.0, 0, 0.0, "API í˜¸ì¶œ ì‹¤íŒ¨")
                    cup_handle_analysis = CupHandleAnalysis(False, 0.0, 0.0, 0, "API í˜¸ì¶œ ì‹¤íŒ¨")
                    stage2_analysis = Stage2Analysis(False, 0.0, False, False, "API í˜¸ì¶œ ì‹¤íŒ¨")
                    return vcp_analysis, cup_handle_analysis, stage2_analysis, GPTRecommendation.HOLD, 0.0, "ë¶„ì„ ì‹¤íŒ¨", 1.0, 0.0
                else:
                    # ë‹¤ìŒ ì‹œë„ë¥¼ ìœ„í•´ ì ì‹œ ëŒ€ê¸°
                    import time
                    time.sleep(1)
                    continue

        # ì´ ë¶€ë¶„ì— ë„ë‹¬í•˜ë©´ ì•ˆ ë¨ (ëª¨ë“  ê²½ë¡œì—ì„œ returnì´ ìˆì–´ì•¼ í•¨)
        logger.error(f"âŒ {ticker} ì˜ˆìƒì¹˜ ëª»í•œ ì½”ë“œ ê²½ë¡œ")
        vcp_analysis = VCPAnalysis(False, 0.0, 0, 0.0, "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
        cup_handle_analysis = CupHandleAnalysis(False, 0.0, 0.0, 0, "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
        stage2_analysis = Stage2Analysis(False, 0.0, False, False, "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜")
        return vcp_analysis, cup_handle_analysis, stage2_analysis, GPTRecommendation.HOLD, 0.0, "ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜", 1.0, 0.0

    def _calculate_enhanced_score(self, technical_result: Dict, gpt_result: GPTAnalysisResult) -> float:
        """ê¸°ìˆ ì  ë¶„ì„ + GPT ë¶„ì„ ì¢…í•© ì ìˆ˜"""
        base_score = technical_result.get('quality_score', 10.0)

        # GPT ì¶”ì²œì— ë”°ë¥¸ ê°€ì¤‘ì¹˜
        if gpt_result.recommendation == GPTRecommendation.STRONG_BUY:
            multiplier = 1.4
        elif gpt_result.recommendation == GPTRecommendation.BUY:
            multiplier = 1.2
        elif gpt_result.recommendation == GPTRecommendation.HOLD:
            multiplier = 1.0
        else:  # AVOID
            multiplier = 0.7

        # GPT ì‹ ë¢°ë„ ë°˜ì˜
        enhanced_score = base_score * multiplier * (0.5 + 0.5 * gpt_result.confidence)

        logger.debug(f"ğŸ“Š ì ìˆ˜ ê³„ì‚°: {base_score:.1f} Ã— {multiplier:.1f} Ã— {gpt_result.confidence:.2f} = {enhanced_score:.1f}")
        return enhanced_score

    def _save_analysis_result(self, result: GPTAnalysisResult):
        """ë¶„ì„ ê²°ê³¼ SQLite ì €ì¥ (Spock - Global Stock Version)"""
        try:
            conn = sqlite3.connect(self.db_path)
            cursor = conn.cursor()

            # NEW: Stage 2 fields included in INSERT statement
            # Note: Database migration (Task 1.3) must be completed before this works
            cursor.execute("""
                INSERT OR REPLACE INTO gpt_analysis (
                    ticker, analysis_date,
                    vcp_detected, vcp_confidence, vcp_stage, vcp_volatility_ratio, vcp_reasoning,
                    cup_handle_detected, cup_handle_confidence, cup_depth_ratio, handle_duration_days, cup_handle_reasoning,
                    stage2_confirmed, stage2_confidence, stage2_ma_alignment, stage2_volume_surge, stage2_reasoning,
                    gpt_recommendation, gpt_confidence, gpt_reasoning,
                    position_adjustment, api_cost_usd, processing_time_ms, created_at
                ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, datetime('now'))
            """, (
                result.ticker, result.analysis_date,
                # VCP Analysis
                result.vcp_analysis.detected, result.vcp_analysis.confidence,
                result.vcp_analysis.stage, result.vcp_analysis.volatility_ratio, result.vcp_analysis.reasoning,
                # Cup & Handle Analysis
                result.cup_handle_analysis.detected, result.cup_handle_analysis.confidence,
                result.cup_handle_analysis.cup_depth_ratio, result.cup_handle_analysis.handle_duration_days,
                result.cup_handle_analysis.reasoning,
                # NEW: Stage 2 Analysis (Weinstein Theory)
                result.stage2_analysis.confirmed, result.stage2_analysis.confidence,
                result.stage2_analysis.ma_alignment, result.stage2_analysis.volume_surge,
                result.stage2_analysis.reasoning,
                # GPT Recommendation
                result.recommendation.value, result.confidence, result.reasoning,
                # NEW: Position Adjustment for Kelly Calculator
                result.position_adjustment,
                # Cost Tracking
                result.api_cost_usd, result.processing_time_ms
            ))

            conn.commit()
            conn.close()

            logger.debug(f"ğŸ’¾ {result.ticker}: GPT ë¶„ì„ ê²°ê³¼ DB ì €ì¥ ì™„ë£Œ (Stage 2 í¬í•¨)")

        except sqlite3.OperationalError as e:
            if "no such column" in str(e):
                logger.error(f"âŒ {result.ticker}: DB ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš” - Stage 2 ì»¬ëŸ¼ ëˆ„ë½")
                logger.info("ğŸ’¡ Task 1.3 (Database Migration)ì„ ë¨¼ì € ì‹¤í–‰í•´ì£¼ì„¸ìš”")
            else:
                logger.error(f"âŒ {result.ticker} GPT ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")
        except Exception as e:
            logger.error(f"âŒ {result.ticker} GPT ë¶„ì„ ê²°ê³¼ ì €ì¥ ì‹¤íŒ¨: {e}")

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (Spock - Global Stock Version)"""
    print("ğŸ§ª Stock GPT Analyzer í…ŒìŠ¤íŠ¸ ì‹œì‘")

    # API í‚¤ ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸
    analyzer = StockGPTAnalyzer(enable_gpt=False)
    print("âœ… StockGPTAnalyzer ì´ˆê¸°í™” ì™„ë£Œ (GPT ë¹„í™œì„±í™”)")

    # í…ŒìŠ¤íŠ¸ í›„ë³´ ë°ì´í„°
    test_candidates = [
        {'ticker': 'KRW-BTC', 'quality_score': 18.5},
        {'ticker': 'KRW-ETH', 'quality_score': 16.2},
        {'ticker': 'KRW-XRP', 'quality_score': 14.1},
    ]

    print(f"ğŸ“Š í…ŒìŠ¤íŠ¸ í›„ë³´: {len(test_candidates)}ê°œ")

    # ë¶„ì„ ì‹¤í–‰ (GPT ì—†ì´)
    results = analyzer.analyze_candidates(test_candidates)

    # ê²°ê³¼ ì¶œë ¥
    print("\nğŸ“‹ ë¶„ì„ ê²°ê³¼:")
    for result in results:
        print(f"\nğŸ“Š {result['ticker']}:")
        print(f"  ê¸°ìˆ ì  ì ìˆ˜: {result.get('quality_score', 0):.1f}")
        print(f"  ìµœì¢… ì ìˆ˜: {result.get('final_score', 0):.1f}")

        gpt_analysis = result.get('gpt_analysis')
        if gpt_analysis:
            print(f"  GPT ì¶”ì²œ: {gpt_analysis.recommendation.value}")
            print(f"  GPT ì‹ ë¢°ë„: {gpt_analysis.confidence:.2f}")
            print(f"  ë¹„ìš©: ${gpt_analysis.api_cost_usd:.4f}")
        else:
            print("  GPT ë¶„ì„: ìŠ¤í‚µë¨ (API í‚¤ ì—†ìŒ ë˜ëŠ” ì ìˆ˜ ë¶€ì¡±)")

    print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

    # ë¹„ìš© ê´€ë¦¬ í…ŒìŠ¤íŠ¸
    cost_manager = CostManager()
    print(f"\nğŸ’° ë¹„ìš© ê´€ë¦¬ í…ŒìŠ¤íŠ¸:")
    print(f"  ì¼ì¼ í•œë„: ${cost_manager.daily_limit:.2f}")
    print(f"  ìƒ˜í”Œ í…ìŠ¤íŠ¸ ë¹„ìš©: ${cost_manager.estimate_cost(1000):.6f}")

    print("\nğŸ¯ GPT Analyzer êµ¬í˜„ ì™„ë£Œ!")
    print("ğŸ“‹ ì£¼ìš” ê¸°ëŠ¥:")
    print("  âœ… VCP íŒ¨í„´ ë¶„ì„ êµ¬ì¡°")
    print("  âœ… Cup & Handle íŒ¨í„´ ë¶„ì„ êµ¬ì¡°")
    print("  âœ… GPT-5-mini API ì—°ë™")
    print("  âœ… ë¹„ìš© ìµœì í™” (ì¼ì¼ $0.50 ì œí•œ)")
    print("  âœ… 3ë‹¨ê³„ ìºì‹± ì‹œìŠ¤í…œ")
    print("  âœ… SQLite í†µí•© ì €ì¥")

if __name__ == "__main__":
    main()